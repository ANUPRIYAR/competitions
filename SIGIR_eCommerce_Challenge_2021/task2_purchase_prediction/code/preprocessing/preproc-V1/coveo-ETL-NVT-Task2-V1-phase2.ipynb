{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The MIT License (MIT)\n",
    "\n",
    "# Copyright (c) 2021, NVIDIA CORPORATION\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B: This preproc-V1 generates interactions and sessions without removing repetitions** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/std.py:725: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import cudf\n",
    "import cupy\n",
    "import json\n",
    "import numpy as np\n",
    "import nvtabular as nvt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data and output paths \n",
    "DATA_FOLDER = \"/workspace/\"\n",
    "FILENAME_PATTERN_BROWSING = 'browsing_train.csv'\n",
    "FILENAME_PATTERN_SEARCH = 'search_train.csv'\n",
    "DATA_PATH_BROWSING = os.path.join(DATA_FOLDER, FILENAME_PATTERN_BROWSING)\n",
    "DATA_PATH_SEARCH = os.path.join(DATA_FOLDER, FILENAME_PATTERN_SEARCH)\n",
    "OUTPUT_DIR = '/workspace/coveo_task2_v1_phase2/sessions_with_repetitions/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The objective of this notebook is to create sequential features for user sessions and generate classification features: \n",
    "    - The product id of first AC event \n",
    "    - The purchase of this AC (binary label)  \n",
    "    - nb_after_add \n",
    "\n",
    "* Four independant sections that create different parquet files : \n",
    "\n",
    "   - Feature engineering with Pandas to merge browsing, search and test data and create purchase and AC features: <a href ='#pandas_proc'> Section 1 </a> \n",
    "\n",
    "   - Preprocess row interactions to encode categoricals and normalize numerical features using NVTabular :  <a href='#row_workflow'> Section 2 </a>\n",
    "   \n",
    "   - Group by interactions to create sessions table using NVTabular:  <a href='#session_workflow'> Section 3 </a>\n",
    "   \n",
    "   - Duplicate sessions in train and validation data by truncating the sequence of interactions to different number of actions (0, 2, 4, 6, 8, 10) after the AC : <a href='#session_duplicate'> Section 4 </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> <a id='pandas_proc'> Section 1 : Create event table </a></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge test and browsing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 47711 unique sessions in Test table\n"
     ]
    }
   ],
   "source": [
    "browsing = pd.read_csv(DATA_PATH_BROWSING, sep=',')\n",
    "# Add columns 'is_search' and 'is_test'\n",
    "browsing['is_search'] = 0 \n",
    "browsing['is_test'] = 0 \n",
    "# Load test data \n",
    "with open('/workspace/intention_test_phase_2.json') as json_file:\n",
    "    # read the test cases from the provided file\n",
    "    test_queries = json.load(json_file)\n",
    "# Add browsing events from test data\n",
    "test_df = pd.json_normalize(test_queries, 'query', 'nb_after_add')\n",
    "test_df['is_test'] = 1\n",
    "print(\"There is %s unique sessions in Test table\" %test_df.session_id_hash.nunique())\n",
    "test_browsing = test_df[['session_id_hash', 'event_type', 'product_action', 'product_sku_hash',\n",
    "       'server_timestamp_epoch_ms', 'hashed_url', 'is_search', 'is_test', 'nb_after_add']]\n",
    "test_browsing = test_browsing[test_browsing.is_search==False]\n",
    "# Concat train test browsing data to create event table \n",
    "event_df = pd.concat([browsing, test_browsing])\n",
    "event_df.reset_index(drop=True, inplace=True)\n",
    "del browsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Process duplicated events: which are defined as interactions that occur in the same session and at the same time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = event_df[(event_df.event_type == 'pageview') & (event_df.duplicated(['session_id_hash' , 'server_timestamp_epoch_ms']))]\n",
    "event_df.drop(tmp.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keep the mapping of test sessions to their nb_after_add before merging with search table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session_mapping= dict(zip(test_df.session_id_hash, test_df.nb_after_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate search table from train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# helper function to convert string to list object\n",
    "def convert_str_to_list(x): \n",
    "    if pd.isnull(x): \n",
    "        return x\n",
    "    return ast.literal_eval(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 819393/819393 [00:33<00:00, 24499.01it/s]\n",
      "100%|██████████| 819393/819393 [00:04<00:00, 164598.00it/s]\n",
      "100%|██████████| 819393/819393 [02:46<00:00, 4909.77it/s]\n",
      "100%|██████████| 834938/834938 [00:28<00:00, 29056.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load search data\n",
    "search = pd.read_csv(\"/workspace/search_train.csv\", sep=',')\n",
    "# Add column event_type \n",
    "search['event_type'] = 'search'\n",
    "# Add column 'is_search'\n",
    "search['is_search'] = 1\n",
    "search['is_test'] = 0\n",
    "# Drop 123 rows where: (clicked_skus_hash != NaN) and (product_skus_hash == NaN)\n",
    "condition = (search['product_skus_hash'].isnull()) & (~search['clicked_skus_hash'].isnull())\n",
    "search = search.loc[~condition]\n",
    "# Convert strings to list object \n",
    "for col in ['product_skus_hash', 'clicked_skus_hash', 'query_vector']: \n",
    "    search[col] = search[col].progress_apply(convert_str_to_list)\n",
    "# Add search events from test data\n",
    "test_search = test_df[['session_id_hash', 'query_vector', 'clicked_skus_hash',\n",
    "       'product_skus_hash', 'server_timestamp_epoch_ms', 'event_type',\n",
    "       'is_search', 'is_test']]\n",
    "test_search = test_search[test_search.is_search==True]\n",
    "# Concat test and train search data\n",
    "search = pd.concat([search, test_search])\n",
    "search.reset_index(inplace=True)\n",
    "# Compute number of returned and clicked items \n",
    "search['impression_size'] = search.product_skus_hash.str.len().fillna(0)\n",
    "search['clicks_size'] = search.clicked_skus_hash.str.len().fillna(0)\n",
    "# Compute number of search queries per session \n",
    "tmp = search.groupby('session_id_hash').size().reset_index()\n",
    "tmp.columns = ['session_id_hash', 'nb_queries']\n",
    "search = search.merge(tmp, on='session_id_hash', how='left')\n",
    "# Update list of impressions by the clicked item when it is missing\n",
    "def add_clicked(x): \n",
    "    if isinstance(x.clicked_skus_hash, list) and isinstance(x.product_skus_hash, list):\n",
    "        return list(set(x.product_skus_hash).union(set(x.clicked_skus_hash)))\n",
    "    return x.product_skus_hash\n",
    "search['updated_product_skus_hash'] = search.progress_apply(add_clicked, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 834938/834938 [00:31<00:00, 26235.30it/s]\n"
     ]
    }
   ],
   "source": [
    "def add_clicked(x): \n",
    "    if isinstance(x.clicked_skus_hash, list) and isinstance(x.product_skus_hash, list):\n",
    "        return list(set(x.product_skus_hash).union(set(x.clicked_skus_hash)))\n",
    "    return x.product_skus_hash\n",
    "search['updated_product_skus_hash'] = search.progress_apply(add_clicked, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the session search as a sequence of search queries and the  interacted items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 560394/560394 [00:58<00:00, 9543.72it/s] \n"
     ]
    }
   ],
   "source": [
    "def all_products(x): \n",
    "    t =[]\n",
    "    for products in x.dropna(): \n",
    "        t += products\n",
    "    if len(t)==0:\n",
    "        return ['missing']\n",
    "    return t\n",
    "\n",
    "session_search = search.sort_values(['session_id_hash',\n",
    "                                     'server_timestamp_epoch_ms']).groupby('session_id_hash').agg({'query_vector': lambda x: list(np.concatenate(x.values)),\n",
    "                                                                                                                    'updated_product_skus_hash': all_products,\n",
    "                                                                                                                    'clicked_skus_hash': all_products,\n",
    "                                                                                                                    'impression_size': list,\n",
    "                                                                                                                    'clicks_size': list,\n",
    "                                                                                                                    'nb_queries': 'last'\n",
    "                                                                                                                  })\n",
    "session_search.columns = ['flat_query_vector', 'flat_product_skus_hash', 'flat_clicked_skus_hash', 'impressions_size', 'clicks_size', 'nb_queries']\n",
    "session_search['clicked-flag'] = session_search.progress_apply(lambda x: [int(e in x['flat_clicked_skus_hash']) for e in x['flat_product_skus_hash']], axis=1)\n",
    "session_search = session_search.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save search tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_search.to_parquet(os.path.join(OUTPUT_DIR, \"session_search.parquet\"))\n",
    "search.to_parquet(os.path.join(OUTPUT_DIR, \"search.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add search clicks as an additional product_action in the event_table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 157493 search sessions that generate a click\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pageview         20967984\n",
       "event_product    10671295\n",
       "search             402589\n",
       "Name: event_type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select search events with clicks\n",
    "use_cols = ['session_id_hash', 'clicked_skus_hash',\n",
    "            'server_timestamp_epoch_ms', 'event_type',\n",
    "            'is_search']\n",
    "search_clicks = search[search.clicks_size>0][use_cols]\n",
    "print(\"There are %s search sessions that generate a click\" %search_clicks.session_id_hash.nunique())\n",
    "# Create new event-type and product-action\n",
    "search_clicks['event_type'] = 'search'\n",
    "search_clicks['product_action'] = 'click'\n",
    "search_clicks['is_test'] = search_clicks['session_id_hash'].isin(test_df.session_id_hash.unique()).astype(int)\n",
    "# Unstack the list of clicked items to multiple rows : each row is a single clicked item \n",
    "lst_col = 'clicked_skus_hash'\n",
    "search_clicks = pd.DataFrame({\n",
    "    col:np.repeat(search_clicks[col].values, search_clicks[lst_col].str.len()) for col in search_clicks.columns.difference([lst_col])}).assign(\n",
    "    **{lst_col:np.concatenate(search_clicks[lst_col].values)})[search_clicks.columns.tolist()]\n",
    "search_clicks.columns = ['session_id_hash', 'product_sku_hash', 'server_timestamp_epoch_ms',\n",
    "                         'event_type', 'is_search', 'product_action', 'is_test']\n",
    "# add nb_after_add for click events from the task mapping \n",
    "search_clicks['nb_after_add'] = search_clicks.session_id_hash.map(test_session_mapping)\n",
    "# Add search clicks to event table \n",
    "event_df = pd.concat([event_df, search_clicks])\n",
    "event_df.event_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fill missing product ids of pageview events with the url of the page : new column 'product_url_hash' is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df['product_url_hash'] = event_df['product_sku_hash'].fillna(event_df['hashed_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Keep sessions with at least one 'add' product_action "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4982436/4982436 [06:46<00:00, 12242.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " There are 262395 sessions with at least one add-to-cart (AC) event\n"
     ]
    }
   ],
   "source": [
    "sessions_with_add_mask = event_df.groupby('session_id_hash').progress_apply(lambda x: 'add' in x.product_action.values)\n",
    "print(\" \\n There are %s sessions with at least one add-to-cart (AC) event\" %sessions_with_add_mask.sum())\n",
    "sessions_with_add = sessions_with_add_mask[sessions_with_add_mask == True].index.tolist()\n",
    "event_df =event_df[event_df.session_id_hash.isin(sessions_with_add)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Add product information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66386/66386 [00:00<00:00, 439230.37it/s]\n"
     ]
    }
   ],
   "source": [
    "product_info = pd.read_csv('/workspace/sku_to_content.csv')\n",
    "def product_main_category(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    return x.split('/')[0]\n",
    "\n",
    "# Extract product main category\n",
    "product_info['main_category'] = product_info['category_hash'].progress_apply(product_main_category)\n",
    "\n",
    "# Compute average price of main and hierarchy category\n",
    "main_price = product_info.groupby('main_category')['price_bucket'].mean().reset_index()\n",
    "main_price.columns = ['main_category', 'mean_price_main']\n",
    "hierarchy_price = product_info.groupby('category_hash')['price_bucket'].mean().reset_index()\n",
    "hierarchy_price.columns = ['category_hash', 'mean_price_hierarchy']\n",
    "product_info = product_info.merge(main_price, on=['main_category'], how='left')\n",
    "product_info = product_info.merge(hierarchy_price, on=['category_hash'], how='left')\n",
    "\n",
    "# Merge the event table with product information \n",
    "event_df = event_df.merge(product_info[['product_sku_hash', 'main_category', 'category_hash',\n",
    "                                        'price_bucket', 'mean_price_hierarchy', 'mean_price_main' ]], \n",
    "                          on='product_sku_hash', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create features related to the first purchase event within a session : \n",
    "             'first_purchase_id', 'first_purchase_position', 'is_purchased', 'purchase_timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262395/262395 [00:48<00:00, 5410.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 46138 purchase events\n"
     ]
    }
   ],
   "source": [
    "def get_purchase_index(x): \n",
    "    if 'purchase' not in x.product_action.values: \n",
    "        return ['no_purchase', len(x), 0, x.server_timestamp_epoch_ms.values.max()]\n",
    "    position =  x.product_action.values.tolist().index('purchase')\n",
    "    purchase_id = x.product_sku_hash.values.tolist()[position]\n",
    "    is_purchased = 1 \n",
    "    purchase_timestamp = x.server_timestamp_epoch_ms.values.tolist()[position]\n",
    "    return (purchase_id, position, is_purchased, purchase_timestamp)\n",
    "purchase_event = event_df.groupby('session_id_hash').progress_apply(get_purchase_index)\n",
    "purchase_event.columns = ['session_id_hash', 'purchase_features']\n",
    "purchase_event = pd.DataFrame(purchase_event.tolist(), index= purchase_event.index).reset_index()\n",
    "purchase_event.columns = ['session_id_hash', 'first_purchase_id',\n",
    "                          'first_purchase_position', 'is_purchased',\n",
    "                          'purchase_timestamp']\n",
    "# merge purchase features and event table \n",
    "event_df = event_df.merge(purchase_event, on='session_id_hash', how='left')\n",
    "print(\"There are %s purchase events\" %event_df.drop_duplicates('session_id_hash').is_purchased.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Keep only the interactions that happened before the first purchase events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = event_df[event_df['server_timestamp_epoch_ms'] <= event_df['purchase_timestamp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop sessions that lost the AC event after filtering out interactions happening after the first puchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262395/262395 [00:23<00:00, 10962.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " We keep 262296 sessions with at least one add-to-cart (AC) event before purchase\n"
     ]
    }
   ],
   "source": [
    "sessions_with_add_mask = event_df.groupby('session_id_hash').progress_apply(lambda x: 'add' in x.product_action.values)\n",
    "print(\" \\n We keep %s sessions with at least one add-to-cart (AC) event before purchase\" %sessions_with_add_mask.sum())\n",
    "sessions_with_add = sessions_with_add_mask[sessions_with_add_mask == True].index.tolist()\n",
    "event_df =event_df[event_df.session_id_hash.isin(sessions_with_add)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create features related to the first AC event : \n",
    "            'AC_position', 'first_AC_id', 'original_nb_after_add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262296/262296 [00:47<00:00, 5551.90it/s]\n"
     ]
    }
   ],
   "source": [
    "def first_ac_product(x):\n",
    "    add_index = x.product_action.values.tolist().index('add')\n",
    "    product_id = x['product_sku_hash'].values.tolist()[add_index]\n",
    "    nb_after = len(x[add_index+1:])\n",
    "    return [product_id, nb_after]\n",
    "add_event = event_df.sort_values(['session_id_hash',\n",
    "                                  'server_timestamp_epoch_ms']).groupby('session_id_hash').progress_apply(first_ac_product)\n",
    "add_event = pd.DataFrame(add_event.tolist(), index= add_event.index).reset_index()\n",
    "add_event.columns = ['session_id_hash', 'first_AC_id', 'original_nb_after_add']\n",
    "event_df = event_df.merge(add_event, on='session_id_hash', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fill missing actions with 'view'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df.product_action = event_df.product_action.fillna('view')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The final event table is : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>server_timestamp_epoch_ms</th>\n",
       "      <th>hashed_url</th>\n",
       "      <th>is_search</th>\n",
       "      <th>is_test</th>\n",
       "      <th>nb_after_add</th>\n",
       "      <th>product_url_hash</th>\n",
       "      <th>main_category</th>\n",
       "      <th>category_hash</th>\n",
       "      <th>price_bucket</th>\n",
       "      <th>mean_price_hierarchy</th>\n",
       "      <th>mean_price_main</th>\n",
       "      <th>first_purchase_id</th>\n",
       "      <th>first_purchase_position</th>\n",
       "      <th>is_purchased</th>\n",
       "      <th>purchase_timestamp</th>\n",
       "      <th>first_AC_id</th>\n",
       "      <th>original_nb_after_add</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8256e7aaf7ade5e68787f3118077de97ae8eec18f47f97...</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>293231f99098fc9552a19111d8ed7b6188bf0721b1a501...</td>\n",
       "      <td>1551545503415</td>\n",
       "      <td>4e8321996f16f2734a5af4b4c780b4c4669fb316cf24ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>293231f99098fc9552a19111d8ed7b6188bf0721b1a501...</td>\n",
       "      <td>115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...</td>\n",
       "      <td>115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.621057</td>\n",
       "      <td>6.258815</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1551546521904</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8256e7aaf7ade5e68787f3118077de97ae8eec18f47f97...</td>\n",
       "      <td>pageview</td>\n",
       "      <td>view</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1551545510494</td>\n",
       "      <td>744ac6435f90719fdec0276541a5c481138cc1f2f51106...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>744ac6435f90719fdec0276541a5c481138cc1f2f51106...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1551546521904</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8256e7aaf7ade5e68787f3118077de97ae8eec18f47f97...</td>\n",
       "      <td>pageview</td>\n",
       "      <td>view</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1551545514312</td>\n",
       "      <td>15c3f072fa3c3caa710d9cc114fa017f37deb117ec158c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15c3f072fa3c3caa710d9cc114fa017f37deb117ec158c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1551546521904</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8256e7aaf7ade5e68787f3118077de97ae8eec18f47f97...</td>\n",
       "      <td>event_product</td>\n",
       "      <td>detail</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>1551545514312</td>\n",
       "      <td>15c3f072fa3c3caa710d9cc114fa017f37deb117ec158c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>06fa312761d4b39e2f649781514ac69a4c1505c221fc46...</td>\n",
       "      <td>06fa312761d4b39e2f649781514ac69a4c1505c221fc46...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.859416</td>\n",
       "      <td>5.692630</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1551546521904</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8256e7aaf7ade5e68787f3118077de97ae8eec18f47f97...</td>\n",
       "      <td>event_product</td>\n",
       "      <td>add</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>1551545686640</td>\n",
       "      <td>83b4fdad686c1be4eba335f70d23ae202b84b6153e109e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>06fa312761d4b39e2f649781514ac69a4c1505c221fc46...</td>\n",
       "      <td>06fa312761d4b39e2f649781514ac69a4c1505c221fc46...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.859416</td>\n",
       "      <td>5.692630</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1551546521904</td>\n",
       "      <td>36e8246f800db10613eef89c81513df909ec8171a875f0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830489</th>\n",
       "      <td>ffe097c27c9dc7714be4170e5e4ed614b5ec7d5e2d2256...</td>\n",
       "      <td>search</td>\n",
       "      <td>click</td>\n",
       "      <td>ad3e11b11865f20a9bcc672698e01b3e961d4776229503...</td>\n",
       "      <td>1556580676511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>ad3e11b11865f20a9bcc672698e01b3e961d4776229503...</td>\n",
       "      <td>115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...</td>\n",
       "      <td>115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.621057</td>\n",
       "      <td>6.258815</td>\n",
       "      <td>no_purchase</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1556582292621</td>\n",
       "      <td>ad3e11b11865f20a9bcc672698e01b3e961d4776229503...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830490</th>\n",
       "      <td>ffecd521a45cf3a43952a5f4cc2f5d2f1a95b3e30befcc...</td>\n",
       "      <td>search</td>\n",
       "      <td>click</td>\n",
       "      <td>237bd4d65e9a9ae281b4994767e6897fd6e8a14e9e6184...</td>\n",
       "      <td>1557449040003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>237bd4d65e9a9ae281b4994767e6897fd6e8a14e9e6184...</td>\n",
       "      <td>06fa312761d4b39e2f649781514ac69a4c1505c221fc46...</td>\n",
       "      <td>06fa312761d4b39e2f649781514ac69a4c1505c221fc46...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.247863</td>\n",
       "      <td>5.692630</td>\n",
       "      <td>no_purchase</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1557449386923</td>\n",
       "      <td>e2d05c62db7057b26232d57e49645d53f397a031ee09ff...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830491</th>\n",
       "      <td>fff39b2d9e9595285f3fe5578c863881b0bdfb78b8e5f6...</td>\n",
       "      <td>search</td>\n",
       "      <td>click</td>\n",
       "      <td>046cf76660fe7d9f2a47272112c42d1adc642e76a60dfd...</td>\n",
       "      <td>1557697901706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>046cf76660fe7d9f2a47272112c42d1adc642e76a60dfd...</td>\n",
       "      <td>0665a81d19c89281cc00e7f7d779ded2ed42c933838602...</td>\n",
       "      <td>0665a81d19c89281cc00e7f7d779ded2ed42c933838602...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.009017</td>\n",
       "      <td>5.009099</td>\n",
       "      <td>no_purchase</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1557697912685</td>\n",
       "      <td>046cf76660fe7d9f2a47272112c42d1adc642e76a60dfd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830492</th>\n",
       "      <td>fff637fac2778b4cc545d1ab7af42596f85bf652c49ce9...</td>\n",
       "      <td>search</td>\n",
       "      <td>click</td>\n",
       "      <td>4d4b50e8de27416fb2cdce41fdd7be611fd7b0fcf2e333...</td>\n",
       "      <td>1557403643669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4d4b50e8de27416fb2cdce41fdd7be611fd7b0fcf2e333...</td>\n",
       "      <td>115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...</td>\n",
       "      <td>115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.621057</td>\n",
       "      <td>6.258815</td>\n",
       "      <td>no_purchase</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1557403716699</td>\n",
       "      <td>b082c9fb875817897d7250a95810ee1519157968b269d7...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830493</th>\n",
       "      <td>fffe1df2533a84033cb7df51e4e019282e8bab530ba53b...</td>\n",
       "      <td>search</td>\n",
       "      <td>click</td>\n",
       "      <td>ba942bf95109b5753aad1454a24fddc4e96f5912390d79...</td>\n",
       "      <td>1557526486324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ba942bf95109b5753aad1454a24fddc4e96f5912390d79...</td>\n",
       "      <td>115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...</td>\n",
       "      <td>115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.621057</td>\n",
       "      <td>6.258815</td>\n",
       "      <td>no_purchase</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1557526530087</td>\n",
       "      <td>ba942bf95109b5753aad1454a24fddc4e96f5912390d79...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5830494 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           session_id_hash     event_type  \\\n",
       "0        8256e7aaf7ade5e68787f3118077de97ae8eec18f47f97...  event_product   \n",
       "1        8256e7aaf7ade5e68787f3118077de97ae8eec18f47f97...       pageview   \n",
       "2        8256e7aaf7ade5e68787f3118077de97ae8eec18f47f97...       pageview   \n",
       "3        8256e7aaf7ade5e68787f3118077de97ae8eec18f47f97...  event_product   \n",
       "4        8256e7aaf7ade5e68787f3118077de97ae8eec18f47f97...  event_product   \n",
       "...                                                    ...            ...   \n",
       "5830489  ffe097c27c9dc7714be4170e5e4ed614b5ec7d5e2d2256...         search   \n",
       "5830490  ffecd521a45cf3a43952a5f4cc2f5d2f1a95b3e30befcc...         search   \n",
       "5830491  fff39b2d9e9595285f3fe5578c863881b0bdfb78b8e5f6...         search   \n",
       "5830492  fff637fac2778b4cc545d1ab7af42596f85bf652c49ce9...         search   \n",
       "5830493  fffe1df2533a84033cb7df51e4e019282e8bab530ba53b...         search   \n",
       "\n",
       "        product_action                                   product_sku_hash  \\\n",
       "0               detail  293231f99098fc9552a19111d8ed7b6188bf0721b1a501...   \n",
       "1                 view                                                NaN   \n",
       "2                 view                                                NaN   \n",
       "3               detail  36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "4                  add  36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "...                ...                                                ...   \n",
       "5830489          click  ad3e11b11865f20a9bcc672698e01b3e961d4776229503...   \n",
       "5830490          click  237bd4d65e9a9ae281b4994767e6897fd6e8a14e9e6184...   \n",
       "5830491          click  046cf76660fe7d9f2a47272112c42d1adc642e76a60dfd...   \n",
       "5830492          click  4d4b50e8de27416fb2cdce41fdd7be611fd7b0fcf2e333...   \n",
       "5830493          click  ba942bf95109b5753aad1454a24fddc4e96f5912390d79...   \n",
       "\n",
       "         server_timestamp_epoch_ms  \\\n",
       "0                    1551545503415   \n",
       "1                    1551545510494   \n",
       "2                    1551545514312   \n",
       "3                    1551545514312   \n",
       "4                    1551545686640   \n",
       "...                            ...   \n",
       "5830489              1556580676511   \n",
       "5830490              1557449040003   \n",
       "5830491              1557697901706   \n",
       "5830492              1557403643669   \n",
       "5830493              1557526486324   \n",
       "\n",
       "                                                hashed_url  is_search  \\\n",
       "0        4e8321996f16f2734a5af4b4c780b4c4669fb316cf24ad...          0   \n",
       "1        744ac6435f90719fdec0276541a5c481138cc1f2f51106...          0   \n",
       "2        15c3f072fa3c3caa710d9cc114fa017f37deb117ec158c...          0   \n",
       "3        15c3f072fa3c3caa710d9cc114fa017f37deb117ec158c...          0   \n",
       "4        83b4fdad686c1be4eba335f70d23ae202b84b6153e109e...          0   \n",
       "...                                                    ...        ...   \n",
       "5830489                                                NaN          1   \n",
       "5830490                                                NaN          1   \n",
       "5830491                                                NaN          1   \n",
       "5830492                                                NaN          1   \n",
       "5830493                                                NaN          1   \n",
       "\n",
       "         is_test nb_after_add  \\\n",
       "0              0          NaN   \n",
       "1              0          NaN   \n",
       "2              0          NaN   \n",
       "3              0          NaN   \n",
       "4              0          NaN   \n",
       "...          ...          ...   \n",
       "5830489        1            8   \n",
       "5830490        1            2   \n",
       "5830491        1            0   \n",
       "5830492        1            0   \n",
       "5830493        1            0   \n",
       "\n",
       "                                          product_url_hash  \\\n",
       "0        293231f99098fc9552a19111d8ed7b6188bf0721b1a501...   \n",
       "1        744ac6435f90719fdec0276541a5c481138cc1f2f51106...   \n",
       "2        15c3f072fa3c3caa710d9cc114fa017f37deb117ec158c...   \n",
       "3        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "4        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "...                                                    ...   \n",
       "5830489  ad3e11b11865f20a9bcc672698e01b3e961d4776229503...   \n",
       "5830490  237bd4d65e9a9ae281b4994767e6897fd6e8a14e9e6184...   \n",
       "5830491  046cf76660fe7d9f2a47272112c42d1adc642e76a60dfd...   \n",
       "5830492  4d4b50e8de27416fb2cdce41fdd7be611fd7b0fcf2e333...   \n",
       "5830493  ba942bf95109b5753aad1454a24fddc4e96f5912390d79...   \n",
       "\n",
       "                                             main_category  \\\n",
       "0        115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...   \n",
       "1                                                      NaN   \n",
       "2                                                      NaN   \n",
       "3        06fa312761d4b39e2f649781514ac69a4c1505c221fc46...   \n",
       "4        06fa312761d4b39e2f649781514ac69a4c1505c221fc46...   \n",
       "...                                                    ...   \n",
       "5830489  115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...   \n",
       "5830490  06fa312761d4b39e2f649781514ac69a4c1505c221fc46...   \n",
       "5830491  0665a81d19c89281cc00e7f7d779ded2ed42c933838602...   \n",
       "5830492  115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...   \n",
       "5830493  115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...   \n",
       "\n",
       "                                             category_hash  price_bucket  \\\n",
       "0        115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...           7.0   \n",
       "1                                                      NaN           NaN   \n",
       "2                                                      NaN           NaN   \n",
       "3        06fa312761d4b39e2f649781514ac69a4c1505c221fc46...           8.0   \n",
       "4        06fa312761d4b39e2f649781514ac69a4c1505c221fc46...           8.0   \n",
       "...                                                    ...           ...   \n",
       "5830489  115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...           9.0   \n",
       "5830490  06fa312761d4b39e2f649781514ac69a4c1505c221fc46...           3.0   \n",
       "5830491  0665a81d19c89281cc00e7f7d779ded2ed42c933838602...           4.0   \n",
       "5830492  115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...           4.0   \n",
       "5830493  115a6a7017ee55752b8487c77dfde92b0d501d10a2e69c...           8.0   \n",
       "\n",
       "         mean_price_hierarchy  mean_price_main  \\\n",
       "0                    6.621057         6.258815   \n",
       "1                         NaN              NaN   \n",
       "2                         NaN              NaN   \n",
       "3                    7.859416         5.692630   \n",
       "4                    7.859416         5.692630   \n",
       "...                       ...              ...   \n",
       "5830489              6.621057         6.258815   \n",
       "5830490              3.247863         5.692630   \n",
       "5830491              5.009017         5.009099   \n",
       "5830492              6.621057         6.258815   \n",
       "5830493              6.621057         6.258815   \n",
       "\n",
       "                                         first_purchase_id  \\\n",
       "0        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "1        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "2        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "3        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "4        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "...                                                    ...   \n",
       "5830489                                        no_purchase   \n",
       "5830490                                        no_purchase   \n",
       "5830491                                        no_purchase   \n",
       "5830492                                        no_purchase   \n",
       "5830493                                        no_purchase   \n",
       "\n",
       "         first_purchase_position  is_purchased  purchase_timestamp  \\\n",
       "0                              8             1       1551546521904   \n",
       "1                              8             1       1551546521904   \n",
       "2                              8             1       1551546521904   \n",
       "3                              8             1       1551546521904   \n",
       "4                              8             1       1551546521904   \n",
       "...                          ...           ...                 ...   \n",
       "5830489                       17             0       1556582292621   \n",
       "5830490                       12             0       1557449386923   \n",
       "5830491                        8             0       1557697912685   \n",
       "5830492                        6             0       1557403716699   \n",
       "5830493                       11             0       1557526530087   \n",
       "\n",
       "                                               first_AC_id  \\\n",
       "0        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "1        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "2        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "3        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "4        36e8246f800db10613eef89c81513df909ec8171a875f0...   \n",
       "...                                                    ...   \n",
       "5830489  ad3e11b11865f20a9bcc672698e01b3e961d4776229503...   \n",
       "5830490  e2d05c62db7057b26232d57e49645d53f397a031ee09ff...   \n",
       "5830491  046cf76660fe7d9f2a47272112c42d1adc642e76a60dfd...   \n",
       "5830492  b082c9fb875817897d7250a95810ee1519157968b269d7...   \n",
       "5830493  ba942bf95109b5753aad1454a24fddc4e96f5912390d79...   \n",
       "\n",
       "         original_nb_after_add  \n",
       "0                            4  \n",
       "1                            4  \n",
       "2                            4  \n",
       "3                            4  \n",
       "4                            4  \n",
       "...                        ...  \n",
       "5830489                      8  \n",
       "5830490                      2  \n",
       "5830491                      0  \n",
       "5830492                      0  \n",
       "5830493                      0  \n",
       "\n",
       "[5830494 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(event_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save to parquet file with 10 partitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df['parquet_split'] =  np.random.randint(0, 10, size=event_df.shape[0])\n",
    "event_df.to_parquet(os.path.join(OUTPUT_DIR, \"event_table\"), partition_cols=['parquet_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del event_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> <a id='row_workflow'> Define the preprocessed row interactions table </a> </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(OUTPUT_DIR + '/event_table/parquet_split*/*.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Workflow: Fill missing values, encode categorical variables and normalize numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data \n",
    "df_event = nvt.Dataset(files, part_size=\"1GB\") \n",
    "\n",
    "# convert timestamp to datetime object\n",
    "to_datetime = [\"server_timestamp_epoch_ms\"] >> nvt.ops.LambdaOp(lambda col: cudf.to_datetime(col, unit='ms')) >> nvt.ops.Rename( f = lambda x: 'timestamp')\n",
    "\n",
    "# fill missing product ids before categorify to keep id '0' for padding \n",
    "missing_ids = ['product_sku_hash','hashed_url'] >> nvt.ops.FillMissing(fill_val='missing')\n",
    "cat_product_ids = missing_ids >> nvt.ops.Categorify()\n",
    "\n",
    "#joint encode product url pruchase_event and add_event ids\n",
    "cat_joint_product_ids = [['product_url_hash', 'first_purchase_id', 'first_AC_id']] >> nvt.ops.Categorify()\n",
    "\n",
    "# Encode the categorical features\n",
    "categ_feats = ['session_id_hash', 'product_action',  'event_type', 'price_bucket', 'main_category', 'category_hash']\n",
    "cat_feats = categ_feats >> nvt.ops.Categorify()\n",
    "\n",
    "# Fill and normalize numerical features \n",
    "cont_feats = ['mean_price_hierarchy', 'mean_price_main'] >> nvt.ops.FillMedian()\n",
    "continuous_feats = cont_feats >> nvt.ops.Normalize()\n",
    "\n",
    "# Keep original value of the remaining features \n",
    "other_feats =   ['is_purchased', 'purchase_timestamp', 'original_nb_after_add']\n",
    "\n",
    "# Define and fit the workflow\n",
    "workflow = nvt.Workflow(['nb_after_add', 'is_search', 'is_test'] + cat_feats  + cat_product_ids + cat_joint_product_ids + \\\n",
    "                        other_feats + to_datetime  + continuous_feats)\n",
    "workflow.fit(df_event)\n",
    "\n",
    "# Transform event table \n",
    "new_gdf = workflow.transform(df_event).to_ddf().compute()\n",
    "\n",
    "# Include the item first time seen feature (for recency calculation) : Using product_url_hash column \n",
    "items_first_ts_df = new_gdf.groupby('product_url_hash').agg({'timestamp': 'min'}).reset_index().rename(columns={'timestamp': 'itemid_ts_first'})\n",
    "interactions_merged_df = new_gdf.merge(items_first_ts_df, on=['product_url_hash'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>hashed_url</th>\n",
       "      <th>product_url_hash</th>\n",
       "      <th>main_category</th>\n",
       "      <th>category_hash</th>\n",
       "      <th>price_bucket</th>\n",
       "      <th>mean_price_hierarchy</th>\n",
       "      <th>mean_price_main</th>\n",
       "      <th>itemid_ts_first</th>\n",
       "      <th>first_AC_id</th>\n",
       "      <th>first_purchase_id</th>\n",
       "      <th>is_purchased</th>\n",
       "      <th>purchase_timestamp</th>\n",
       "      <th>nb_after_add</th>\n",
       "      <th>original_nb_after_add</th>\n",
       "      <th>is_search</th>\n",
       "      <th>is_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64241</td>\n",
       "      <td>2019-02-26 23:54:37.013</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46528</td>\n",
       "      <td>172162</td>\n",
       "      <td>146875</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2.292797</td>\n",
       "      <td>-2.520677</td>\n",
       "      <td>2019-01-15 20:02:55.620</td>\n",
       "      <td>146875</td>\n",
       "      <td>176371</td>\n",
       "      <td>0</td>\n",
       "      <td>1551226394839</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64241</td>\n",
       "      <td>2019-02-27 00:07:05.406</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>55897</td>\n",
       "      <td>172162</td>\n",
       "      <td>170452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>0.023351</td>\n",
       "      <td>2019-01-15 19:24:01.522</td>\n",
       "      <td>146875</td>\n",
       "      <td>176371</td>\n",
       "      <td>0</td>\n",
       "      <td>1551226394839</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64241</td>\n",
       "      <td>2019-02-27 00:07:05.406</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46528</td>\n",
       "      <td>172162</td>\n",
       "      <td>146875</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2.292797</td>\n",
       "      <td>-2.520677</td>\n",
       "      <td>2019-01-15 20:02:55.620</td>\n",
       "      <td>146875</td>\n",
       "      <td>176371</td>\n",
       "      <td>0</td>\n",
       "      <td>1551226394839</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id_hash               timestamp  event_type  product_action  \\\n",
       "0            64241 2019-02-26 23:54:37.013           1               3   \n",
       "1            64241 2019-02-27 00:07:05.406           2               6   \n",
       "2            64241 2019-02-27 00:07:05.406           1               3   \n",
       "\n",
       "   product_sku_hash  hashed_url  product_url_hash  main_category  \\\n",
       "0             46528      172162            146875              1   \n",
       "1             55897      172162            170452              0   \n",
       "2             46528      172162            146875              1   \n",
       "\n",
       "   category_hash  price_bucket  mean_price_hierarchy  mean_price_main  \\\n",
       "0              4             9              2.292797        -2.520677   \n",
       "1              0             0              0.010558         0.023351   \n",
       "2              4             9              2.292797        -2.520677   \n",
       "\n",
       "          itemid_ts_first  first_AC_id  first_purchase_id  is_purchased  \\\n",
       "0 2019-01-15 20:02:55.620       146875             176371             0   \n",
       "1 2019-01-15 19:24:01.522       146875             176371             0   \n",
       "2 2019-01-15 20:02:55.620       146875             176371             0   \n",
       "\n",
       "   purchase_timestamp nb_after_add  original_nb_after_add  is_search  is_test  \n",
       "0       1551226394839         <NA>                      6          0        0  \n",
       "1       1551226394839         <NA>                      6          0        0  \n",
       "2       1551226394839         <NA>                      6          0        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cols = ['session_id_hash', 'timestamp',  'event_type', 'product_action',\n",
    "            \n",
    "            'product_sku_hash', 'hashed_url', 'product_url_hash',\n",
    "            \n",
    "            'main_category', 'category_hash', 'price_bucket', 'mean_price_hierarchy', 'mean_price_main', \n",
    "            \n",
    "            'itemid_ts_first',  \n",
    "            \n",
    "            'first_AC_id', \n",
    "            \n",
    "            'first_purchase_id', 'is_purchased', 'purchase_timestamp',\n",
    "            \n",
    "            'nb_after_add', 'original_nb_after_add', 'is_search', 'is_test'] \n",
    "\n",
    "interactions_merged_df[use_cols].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save resulting table and nvtabular workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the workflow : \n",
    "workflow.save(os.path.join(OUTPUT_DIR, \"categorify_workflow\"))\n",
    "\n",
    "# Save the parquet table \n",
    "interactions_merged_df[use_cols].to_parquet(os.path.join(OUTPUT_DIR , 'row_interactions_task2_preproc_v2.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> <a id='session_workflow'>Preprocessing of session table  </a> </center></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feats = ['mean_price_hierarchy', 'mean_price_main'] \n",
    "purchase_feat = ['first_AC_id', 'first_purchase_id', 'is_purchased', 'purchase_timestamp']\n",
    "data_info = ['is_search', 'is_test'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_merged_df = pd.read_parquet(os.path.join(OUTPUT_DIR , 'row_interactions_task2_preproc_v2.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_action</th>\n",
       "      <th>product_sku_hash</th>\n",
       "      <th>hashed_url</th>\n",
       "      <th>product_url_hash</th>\n",
       "      <th>main_category</th>\n",
       "      <th>category_hash</th>\n",
       "      <th>price_bucket</th>\n",
       "      <th>mean_price_hierarchy</th>\n",
       "      <th>mean_price_main</th>\n",
       "      <th>itemid_ts_first</th>\n",
       "      <th>first_AC_id</th>\n",
       "      <th>first_purchase_id</th>\n",
       "      <th>is_purchased</th>\n",
       "      <th>purchase_timestamp</th>\n",
       "      <th>nb_after_add</th>\n",
       "      <th>original_nb_after_add</th>\n",
       "      <th>is_search</th>\n",
       "      <th>is_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64241</td>\n",
       "      <td>2019-02-26 23:54:37.013</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46528</td>\n",
       "      <td>172162</td>\n",
       "      <td>146875</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2.292797</td>\n",
       "      <td>-2.520677</td>\n",
       "      <td>2019-01-15 20:02:55.620</td>\n",
       "      <td>146875</td>\n",
       "      <td>176371</td>\n",
       "      <td>0</td>\n",
       "      <td>1551226394839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64241</td>\n",
       "      <td>2019-02-27 00:07:05.406</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>55897</td>\n",
       "      <td>172162</td>\n",
       "      <td>170452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>0.023351</td>\n",
       "      <td>2019-01-15 19:24:01.522</td>\n",
       "      <td>146875</td>\n",
       "      <td>176371</td>\n",
       "      <td>0</td>\n",
       "      <td>1551226394839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64241</td>\n",
       "      <td>2019-02-27 00:07:05.406</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46528</td>\n",
       "      <td>172162</td>\n",
       "      <td>146875</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2.292797</td>\n",
       "      <td>-2.520677</td>\n",
       "      <td>2019-01-15 20:02:55.620</td>\n",
       "      <td>146875</td>\n",
       "      <td>176371</td>\n",
       "      <td>0</td>\n",
       "      <td>1551226394839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id_hash               timestamp  event_type  product_action  \\\n",
       "0            64241 2019-02-26 23:54:37.013           1               3   \n",
       "1            64241 2019-02-27 00:07:05.406           2               6   \n",
       "2            64241 2019-02-27 00:07:05.406           1               3   \n",
       "\n",
       "   product_sku_hash  hashed_url  product_url_hash  main_category  \\\n",
       "0             46528      172162            146875              1   \n",
       "1             55897      172162            170452              0   \n",
       "2             46528      172162            146875              1   \n",
       "\n",
       "   category_hash  price_bucket  mean_price_hierarchy  mean_price_main  \\\n",
       "0              4             9              2.292797        -2.520677   \n",
       "1              0             0              0.010558         0.023351   \n",
       "2              4             9              2.292797        -2.520677   \n",
       "\n",
       "          itemid_ts_first  first_AC_id  first_purchase_id  is_purchased  \\\n",
       "0 2019-01-15 20:02:55.620       146875             176371             0   \n",
       "1 2019-01-15 19:24:01.522       146875             176371             0   \n",
       "2 2019-01-15 20:02:55.620       146875             176371             0   \n",
       "\n",
       "   purchase_timestamp  nb_after_add  original_nb_after_add  is_search  is_test  \n",
       "0       1551226394839           NaN                      6          0        0  \n",
       "1       1551226394839           NaN                      6          0        0  \n",
       "2       1551226394839           NaN                      6          0        0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_merged_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert booleans to int \n",
    "interactions_merged_df[data_info ] = interactions_merged_df[ data_info ].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_merged_df[interactions_merged_df.is_test==1].nb_after_add.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time features\n",
    "sessionTime = ['timestamp']\n",
    "\n",
    "sessionTime_hour = (\n",
    "    sessionTime >> \n",
    "    #nvt.ops.LambdaOp(lambda col: cudf.to_datetime(col, unit='ms').dt.hour) >> \n",
    "    nvt.ops.LambdaOp(lambda col: col.dt.hour) >> \n",
    "    nvt.ops.Rename(postfix = '_hour')\n",
    ")\n",
    "sessionTime_weekday = (\n",
    "    sessionTime >> \n",
    "    #nvt.ops.LambdaOp(lambda col: cudf.to_datetime(col, unit='ms').dt.weekday) >> \n",
    "    nvt.ops.LambdaOp(lambda col: col.dt.weekday) >> \n",
    "    nvt.ops.Rename(postfix = '_wd')\n",
    ")\n",
    "sessionTime_day = (\n",
    "    sessionTime >> \n",
    "    nvt.ops.LambdaOp(lambda col: col.dt.day) >> \n",
    "    nvt.ops.Rename(postfix=\"_day\")\n",
    ")\n",
    "\n",
    "sessionTime_timestamp = (\n",
    "    sessionTime >> \n",
    "    nvt.ops.LambdaOp(lambda col: (col.astype(int) / 1e6).astype(int)) >> \n",
    "    nvt.ops.Rename(f = lambda col: \"ts\")\n",
    ")\n",
    "\n",
    "# compute cycled features \n",
    "def get_cycled_feature_value_sin(col, max_value):\n",
    "    value_scaled = (col + 0.000001) / max_value\n",
    "    value_sin = np.sin(2*np.pi*value_scaled)\n",
    "    return value_sin\n",
    "\n",
    "def get_cycled_feature_value_cos(col, max_value):\n",
    "    value_scaled = (col + 0.000001) / max_value\n",
    "    value_cos = np.cos(2*np.pi*value_scaled)\n",
    "    return value_cos\n",
    "hour_sin = sessionTime_hour >> (lambda col: get_cycled_feature_value_sin(col, 24)) >> nvt.ops.Rename(postfix = '_sin')\n",
    "hour_cos = sessionTime_hour >> (lambda col: get_cycled_feature_value_cos(col, 24)) >> nvt.ops.Rename(postfix = '_cos')\n",
    "weekday_sin = sessionTime_weekday >> (lambda col: get_cycled_feature_value_sin(col+1, 7)) >> nvt.ops.Rename(postfix = '_sin')\n",
    "weekday_cos= sessionTime_weekday >> (lambda col: get_cycled_feature_value_cos(col+1, 7)) >> nvt.ops.Rename(postfix = '_cos')\n",
    "cycled_features = hour_sin + hour_cos + weekday_sin + weekday_cos\n",
    "\n",
    "\n",
    "# calculate item recency \n",
    "from nvtabular.ops import Operator\n",
    "class ItemRecency(Operator):\n",
    "    def transform(self, columns, gdf):\n",
    "        for column in columns:\n",
    "            col = gdf[column]\n",
    "            #col.loc[col == \"\"] = None\n",
    "            item_first_timestamp = gdf['itemid_ts_first']\n",
    "            delta_days = (col - item_first_timestamp).dt.days\n",
    "            gdf[column + \"_age_days\"] = delta_days * (delta_days >=0)\n",
    "        return gdf\n",
    "            \n",
    "    def output_column_names(self, columns):\n",
    "        return [column + \"_age_days\" for column in columns]\n",
    "            \n",
    "    def dependencies(self):\n",
    "        return [\"itemid_ts_first\"]\n",
    "recency_features = [\"timestamp\"] >> ItemRecency() \n",
    "recency_features_norm = recency_features >> nvt.ops.LogOp() >> nvt.ops.Normalize() >> nvt.ops.Rename(postfix = '_norm')\n",
    "\n",
    "time_features = (\n",
    "    sessionTime_timestamp +\n",
    "    sessionTime + \n",
    "    sessionTime_hour +\n",
    "    sessionTime_day + \n",
    "    sessionTime_weekday +\n",
    "    recency_features +\n",
    "    recency_features_norm + \n",
    "    cycled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ts',\n",
       " 'timestamp',\n",
       " 'timestamp_hour',\n",
       " 'timestamp_day',\n",
       " 'timestamp_wd',\n",
       " 'timestamp_age_days',\n",
       " 'timestamp_age_days_norm',\n",
       " 'timestamp_hour_sin',\n",
       " 'timestamp_hour_cos',\n",
       " 'timestamp_wd_sin',\n",
       " 'timestamp_wd_cos']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grouping interactions into sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Groupby Workflow: search columns are not used\n",
    "# N.B: Add the op ListSlice when upgrading nvt 0.5.1 to 0.6 \n",
    "filter_nan_products = (interactions_merged_df.columns >> nvt.ops.Filter(f=lambda df: df['product_sku_hash'] != 0))\n",
    "\n",
    "groupby_only_product = filter_nan_products - ['timestamp']  + time_features  >> nvt.ops.Groupby(\n",
    "    groupby_cols=[\"session_id_hash\"], \n",
    "    sort_cols=[\"ts\"],\n",
    "    aggs={\n",
    "       \"product_sku_hash\": [\"list\", \"count\"], \n",
    "    }\n",
    ")\n",
    "    \n",
    "groupby_product_url = ['session_id_hash', 'product_url_hash']  + time_features >> nvt.ops.Groupby(\n",
    "    groupby_cols=[\"session_id_hash\"], \n",
    "    sort_cols=[\"ts\"],\n",
    "    aggs={\n",
    "       \"product_url_hash\": [\"list\", \"count\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "groupby_other_features = ['session_id_hash', 'product_action', 'event_type', 'first_AC_id', 'original_nb_after_add',\n",
    "                          'price_bucket', 'category_hash', 'main_category', 'nb_after_add' ] + data_info  + purchase_feat + cont_feats + time_features >> \\\n",
    "    nvt.ops.Groupby(\n",
    "    groupby_cols=[\"session_id_hash\"], \n",
    "    sort_cols=[\"ts\"],\n",
    "    aggs={\n",
    "        \"product_action\": [\"list\"],     \n",
    "        \"event_type\": [\"list\"],    \n",
    "        \"price_bucket\": [\"list\"],\n",
    "        'main_category': [\"list\"],\n",
    "        \"category_hash\": [\"list\"],\n",
    "        'mean_price_hierarchy':[\"list\"],\n",
    "        'mean_price_main':[\"list\"],\n",
    "        \"ts\": [\"list\", \"first\", \"last\"],\n",
    "        \"is_test\": [\"last\"],\n",
    "        \"is_search\": [\"last\"],\n",
    "        'nb_after_add': [\"last\"],\n",
    "        \"original_nb_after_add\": [\"last\"],\n",
    "        \n",
    "        'first_AC_id': [\"last\"],\n",
    "        'is_purchased': [\"last\"],\n",
    "        'purchase_timestamp':[\"last\"],\n",
    "\n",
    "        \"timestamp\": [\"first\"],\n",
    "        'timestamp_day': [\"list\"],\n",
    "        'timestamp_hour': [\"list\"],\n",
    "        'timestamp_month': [\"list\"],\n",
    "        'timestamp_wd': [\"list\"],\n",
    "        'timestamp_age_days': [\"list\"],\n",
    "        'timestamp_age_days_norm': [\"list\"],\n",
    "        'timestamp_hour_sin': [\"list\"],\n",
    "        'timestamp_hour_sin_norm': [\"list\"],\n",
    "        'timestamp_hour_cos': [\"list\"],\n",
    "        'timestamp_hour_cos_norm': [\"list\"],\n",
    "        'timestamp_wd_sin': [\"list\"],\n",
    "        'timestamp_wd_sin_norm': [\"list\"],\n",
    "        'timestamp_wd_cos': [\"list\"],\n",
    "        'timestamp_wd_cos_norm': [\"list\"],   \n",
    "        \n",
    "        },\n",
    "    name_sep=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- workflow 1 : group other features that user interactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_columns = [x for x in groupby_other_features.columns if x!= 'timestamp-first']\n",
    "day_index = ((groupby_other_features - remaining_columns)  >> \n",
    "    nvt.ops.LambdaOp(lambda col: (col.max() - col).dt.days + 1) >> \n",
    "    nvt.ops.Rename(f = lambda col: \"day_index\")\n",
    ")              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262296"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = nvt.Workflow(groupby_other_features + day_index)\n",
    "dataset = nvt.Dataset(interactions_merged_df, cpu=False)\n",
    "workflow.fit(dataset)\n",
    "new_gdf_other = workflow.transform(dataset).to_ddf().compute()\n",
    "len(new_gdf_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_hour-list</th>\n",
       "      <th>first_AC_id-last</th>\n",
       "      <th>ts-last</th>\n",
       "      <th>timestamp_age_days-list</th>\n",
       "      <th>timestamp_hour_cos-list</th>\n",
       "      <th>timestamp_wd_cos-list</th>\n",
       "      <th>ts-first</th>\n",
       "      <th>timestamp-first</th>\n",
       "      <th>timestamp_day-list</th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>category_hash-list</th>\n",
       "      <th>main_category-list</th>\n",
       "      <th>is_test-last</th>\n",
       "      <th>mean_price_main-list</th>\n",
       "      <th>is_purchased-last</th>\n",
       "      <th>event_type-list</th>\n",
       "      <th>timestamp_hour_sin-list</th>\n",
       "      <th>timestamp_wd_sin-list</th>\n",
       "      <th>purchase_timestamp-last</th>\n",
       "      <th>is_search-last</th>\n",
       "      <th>price_bucket-list</th>\n",
       "      <th>timestamp_wd-list</th>\n",
       "      <th>original_nb_after_add-last</th>\n",
       "      <th>product_action-list</th>\n",
       "      <th>ts-list</th>\n",
       "      <th>mean_price_hierarchy-list</th>\n",
       "      <th>timestamp_age_days_norm-list</th>\n",
       "      <th>nb_after_add-last</th>\n",
       "      <th>day_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 2...</td>\n",
       "      <td>143199</td>\n",
       "      <td>1552426869735</td>\n",
       "      <td>[52, 52, 52, 52, 52, 52, 56, 56, 56, 56, 56, 5...</td>\n",
       "      <td>[0.5000007, 0.5000007, 0.5000007, 0.5000007, 0...</td>\n",
       "      <td>[-0.22252177, -0.22252177, -0.22252177, -0.222...</td>\n",
       "      <td>1552423391039</td>\n",
       "      <td>2019-03-12 20:43:11.039</td>\n",
       "      <td>[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>[86, 0, 86, 0, 86, 86, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.02335137, 0.02335137, 0.02335137, 0.0233513...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[-0.866025, -0.866025, -0.866025, -0.866025, -...</td>\n",
       "      <td>[0.9749277, 0.9749277, 0.9749277, 0.9749277, 0...</td>\n",
       "      <td>1552426869735</td>\n",
       "      <td>0</td>\n",
       "      <td>[10, 0, 10, 0, 10, 10, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[3, 0, 3, 6, 1, 1, 6, 0, 0, 6, 6, 0, 0, 6, 0, ...</td>\n",
       "      <td>[1552423391039, 1552423391039, 1552423391039, ...</td>\n",
       "      <td>[2.6224637, 0.010557701, 2.6224637, 0.01055770...</td>\n",
       "      <td>[0.66833013, 0.66833013, 0.66833013, 0.6683301...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[16, 16, 16, 16, 16, 16]</td>\n",
       "      <td>77197</td>\n",
       "      <td>1557247744887</td>\n",
       "      <td>[112, 112, 111, 111, 111, 111]</td>\n",
       "      <td>[-0.4999995, -0.4999995, -0.4999995, -0.499999...</td>\n",
       "      <td>[-0.22252177, -0.22252177, -0.22252177, -0.222...</td>\n",
       "      <td>1557247655055</td>\n",
       "      <td>2019-05-07 16:47:35.055</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7]</td>\n",
       "      <td>2</td>\n",
       "      <td>[60, 60, 60, 60, 60, 60]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.02335137, 0.02335137, 0.02335137, 0.0233513...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[-0.8660257, -0.8660257, -0.8660257, -0.866025...</td>\n",
       "      <td>[0.9749277, 0.9749277, 0.9749277, 0.9749277, 0...</td>\n",
       "      <td>1557247744887</td>\n",
       "      <td>0</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 3, 3, 3, 1, 1]</td>\n",
       "      <td>[1557247655055, 1557247655055, 1557247660313, ...</td>\n",
       "      <td>[1.1459051, 1.1459051, 1.1459051, 1.1459051, 1...</td>\n",
       "      <td>[1.2716198, 1.2716198, 1.2645365, 1.2645365, 1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 timestamp_hour-list  first_AC_id-last  \\\n",
       "0  [20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 2...            143199   \n",
       "1                           [16, 16, 16, 16, 16, 16]             77197   \n",
       "\n",
       "         ts-last                            timestamp_age_days-list  \\\n",
       "0  1552426869735  [52, 52, 52, 52, 52, 52, 56, 56, 56, 56, 56, 5...   \n",
       "1  1557247744887                     [112, 112, 111, 111, 111, 111]   \n",
       "\n",
       "                             timestamp_hour_cos-list  \\\n",
       "0  [0.5000007, 0.5000007, 0.5000007, 0.5000007, 0...   \n",
       "1  [-0.4999995, -0.4999995, -0.4999995, -0.499999...   \n",
       "\n",
       "                               timestamp_wd_cos-list       ts-first  \\\n",
       "0  [-0.22252177, -0.22252177, -0.22252177, -0.222...  1552423391039   \n",
       "1  [-0.22252177, -0.22252177, -0.22252177, -0.222...  1557247655055   \n",
       "\n",
       "          timestamp-first                                 timestamp_day-list  \\\n",
       "0 2019-03-12 20:43:11.039  [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...   \n",
       "1 2019-05-07 16:47:35.055                                 [7, 7, 7, 7, 7, 7]   \n",
       "\n",
       "   session_id_hash                                 category_hash-list  \\\n",
       "0                1  [86, 0, 86, 0, 86, 86, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1                2                           [60, 60, 60, 60, 60, 60]   \n",
       "\n",
       "                                  main_category-list  is_test-last  \\\n",
       "0  [2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...             0   \n",
       "1                                 [2, 2, 2, 2, 2, 2]             1   \n",
       "\n",
       "                                mean_price_main-list  is_purchased-last  \\\n",
       "0  [0.02335137, 0.02335137, 0.02335137, 0.0233513...                  0   \n",
       "1  [0.02335137, 0.02335137, 0.02335137, 0.0233513...                  0   \n",
       "\n",
       "                                     event_type-list  \\\n",
       "0  [1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "1                                 [1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                             timestamp_hour_sin-list  \\\n",
       "0  [-0.866025, -0.866025, -0.866025, -0.866025, -...   \n",
       "1  [-0.8660257, -0.8660257, -0.8660257, -0.866025...   \n",
       "\n",
       "                               timestamp_wd_sin-list  purchase_timestamp-last  \\\n",
       "0  [0.9749277, 0.9749277, 0.9749277, 0.9749277, 0...            1552426869735   \n",
       "1  [0.9749277, 0.9749277, 0.9749277, 0.9749277, 0...            1557247744887   \n",
       "\n",
       "   is_search-last                                  price_bucket-list  \\\n",
       "0               0  [10, 0, 10, 0, 10, 10, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1               0                                 [8, 8, 8, 8, 8, 8]   \n",
       "\n",
       "                                   timestamp_wd-list  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1                                 [1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "   original_nb_after_add-last  \\\n",
       "0                          13   \n",
       "1                           0   \n",
       "\n",
       "                                 product_action-list  \\\n",
       "0  [3, 0, 3, 6, 1, 1, 6, 0, 0, 6, 6, 0, 0, 6, 0, ...   \n",
       "1                                 [3, 3, 3, 3, 1, 1]   \n",
       "\n",
       "                                             ts-list  \\\n",
       "0  [1552423391039, 1552423391039, 1552423391039, ...   \n",
       "1  [1557247655055, 1557247655055, 1557247660313, ...   \n",
       "\n",
       "                           mean_price_hierarchy-list  \\\n",
       "0  [2.6224637, 0.010557701, 2.6224637, 0.01055770...   \n",
       "1  [1.1459051, 1.1459051, 1.1459051, 1.1459051, 1...   \n",
       "\n",
       "                        timestamp_age_days_norm-list nb_after_add-last  \\\n",
       "0  [0.66833013, 0.66833013, 0.66833013, 0.6683301...              <NA>   \n",
       "1  [1.2716198, 1.2716198, 1.2645365, 1.2645365, 1...               0.0   \n",
       "\n",
       "   day_index  \n",
       "0         63  \n",
       "1          7  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gdf_other.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- workflow 2 : create the sequence of product interactions and pageviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262296"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = nvt.Workflow(groupby_product_url)\n",
    "dataset = nvt.Dataset(interactions_merged_df, cpu=False)\n",
    "workflow.fit(dataset)\n",
    "new_gdf_sku_url = workflow.transform(dataset).to_ddf().compute()\n",
    "len(new_gdf_sku_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_url_hash_list</th>\n",
       "      <th>product_url_hash_count</th>\n",
       "      <th>session_id_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[143199, 7298, 143199, 7298, 143199, 143199, 7...</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[130669, 130669, 77197, 77197, 77197, 77197]</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[53641, 53641, 91938, 91938, 165669, 165669, 1...</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[170620, 170620, 170620, 170620, 107009, 10700...</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[46772, 46772, 121609, 121609, 123318, 63033, ...</td>\n",
       "      <td>244</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               product_url_hash_list  product_url_hash_count  \\\n",
       "0  [143199, 7298, 143199, 7298, 143199, 143199, 7...                      32   \n",
       "1       [130669, 130669, 77197, 77197, 77197, 77197]                       6   \n",
       "2  [53641, 53641, 91938, 91938, 165669, 165669, 1...                     136   \n",
       "3  [170620, 170620, 170620, 170620, 107009, 10700...                      22   \n",
       "4  [46772, 46772, 121609, 121609, 123318, 63033, ...                     244   \n",
       "\n",
       "   session_id_hash  \n",
       "0                1  \n",
       "1                2  \n",
       "2                3  \n",
       "3                4  \n",
       "4                5  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gdf_sku_url.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- workflow 3 : create sequence with only product interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262296"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = nvt.Workflow(groupby_only_product)\n",
    "dataset = nvt.Dataset(interactions_merged_df, cpu=False)\n",
    "workflow.fit(dataset)\n",
    "new_gdf_prod_only = workflow.transform(dataset).to_ddf().compute()\n",
    "len(new_gdf_prod_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge the three resulting frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_gdf = new_gdf_sku_url.merge(new_gdf_other, on='session_id_hash',  how='inner')\n",
    "sessions_gdf = sessions_gdf.merge(new_gdf_prod_only,  on='session_id_hash',  how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262296, 33)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_url_hash_list', 'product_url_hash_count', 'session_id_hash',\n",
       "       'timestamp_hour-list', 'first_AC_id-last', 'ts-last',\n",
       "       'timestamp_age_days-list', 'timestamp_hour_cos-list',\n",
       "       'timestamp_wd_cos-list', 'ts-first', 'timestamp-first',\n",
       "       'timestamp_day-list', 'category_hash-list', 'main_category-list',\n",
       "       'is_test-last', 'mean_price_main-list', 'is_purchased-last',\n",
       "       'event_type-list', 'timestamp_hour_sin-list', 'timestamp_wd_sin-list',\n",
       "       'purchase_timestamp-last', 'is_search-last', 'price_bucket-list',\n",
       "       'timestamp_wd-list', 'original_nb_after_add-last',\n",
       "       'product_action-list', 'ts-list', 'mean_price_hierarchy-list',\n",
       "       'timestamp_age_days_norm-list', 'nb_after_add-last', 'day_index',\n",
       "       'product_sku_hash_count', 'product_sku_hash_list'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display resulting session table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id_hash</th>\n",
       "      <th>day_index</th>\n",
       "      <th>product_url_hash_list</th>\n",
       "      <th>event_type-list</th>\n",
       "      <th>product_action-list</th>\n",
       "      <th>category_hash-list</th>\n",
       "      <th>main_category-list</th>\n",
       "      <th>price_bucket-list</th>\n",
       "      <th>mean_price_hierarchy-list</th>\n",
       "      <th>mean_price_main-list</th>\n",
       "      <th>product_sku_hash_count</th>\n",
       "      <th>product_sku_hash_list</th>\n",
       "      <th>product_url_hash_count</th>\n",
       "      <th>ts-first</th>\n",
       "      <th>ts-last</th>\n",
       "      <th>ts-list</th>\n",
       "      <th>timestamp_hour_cos-list</th>\n",
       "      <th>timestamp_hour_sin-list</th>\n",
       "      <th>timestamp_wd_sin-list</th>\n",
       "      <th>timestamp_wd_cos-list</th>\n",
       "      <th>timestamp_age_days-list</th>\n",
       "      <th>timestamp_age_days_norm-list</th>\n",
       "      <th>first_AC_id-last</th>\n",
       "      <th>is_purchased-last</th>\n",
       "      <th>purchase_timestamp-last</th>\n",
       "      <th>nb_after_add-last</th>\n",
       "      <th>is_search-last</th>\n",
       "      <th>is_test-last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262294</th>\n",
       "      <td>250375</td>\n",
       "      <td>64</td>\n",
       "      <td>[46772, 46772, 45686, 45686, 122704, 122704, 4...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 6, 0, 6, 6, 0, 6, 0, 6, 0, 0, 6, 0, 6, 6, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.010557701, 0.010557701, 0.010557701, 0.0105...</td>\n",
       "      <td>[0.02335137, 0.02335137, 0.02335137, 0.0233513...</td>\n",
       "      <td>24</td>\n",
       "      <td>[55897, 55897, 55897, 55897, 55897, 55897, 558...</td>\n",
       "      <td>24</td>\n",
       "      <td>1552353672164</td>\n",
       "      <td>1552354551465</td>\n",
       "      <td>[1552353672164, 1552353672164, 1552353688549, ...</td>\n",
       "      <td>[0.96592575, 0.96592575, 0.96592575, 0.9659257...</td>\n",
       "      <td>[0.25881928, 0.25881928, 0.25881928, 0.2588192...</td>\n",
       "      <td>[0.9749277, 0.9749277, 0.9749277, 0.9749277, 0...</td>\n",
       "      <td>[-0.22252177, -0.22252177, -0.22252177, -0.222...</td>\n",
       "      <td>[55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 5...</td>\n",
       "      <td>[0.7122043, 0.7122043, 0.7122043, 0.7122043, 0...</td>\n",
       "      <td>111417</td>\n",
       "      <td>0</td>\n",
       "      <td>1552354551465</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262295</th>\n",
       "      <td>250376</td>\n",
       "      <td>103</td>\n",
       "      <td>[155647, 155647, 170790, 170790, 170790, 170790]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[3, 3, 3, 3, 1, 1]</td>\n",
       "      <td>[46, 46, 46, 46, 46, 46]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[7, 7, 8, 8, 8, 8]</td>\n",
       "      <td>[0.72179425, 0.72179425, 0.72179425, 0.7217942...</td>\n",
       "      <td>[0.02335137, 0.02335137, 0.02335137, 0.0233513...</td>\n",
       "      <td>6</td>\n",
       "      <td>[49338, 49338, 54109, 54109, 54109, 54109]</td>\n",
       "      <td>6</td>\n",
       "      <td>1548970153891</td>\n",
       "      <td>1548970245921</td>\n",
       "      <td>[1548970153891, 1548970153891, 1548970168089, ...</td>\n",
       "      <td>[0.707107, 0.707107, 0.707107, 0.707107, 0.707...</td>\n",
       "      <td>[-0.70710653, -0.70710653, -0.70710653, -0.707...</td>\n",
       "      <td>[-0.43388462, -0.43388462, -0.43388462, -0.433...</td>\n",
       "      <td>[-0.90096843, -0.90096843, -0.90096843, -0.900...</td>\n",
       "      <td>[16, 16, 16, 16, 16, 16]</td>\n",
       "      <td>[-0.23774733, -0.23774733, -0.23774733, -0.237...</td>\n",
       "      <td>170790</td>\n",
       "      <td>0</td>\n",
       "      <td>1548970245922</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id_hash  day_index  \\\n",
       "262294           250375         64   \n",
       "262295           250376        103   \n",
       "\n",
       "                                    product_url_hash_list  \\\n",
       "262294  [46772, 46772, 45686, 45686, 122704, 122704, 4...   \n",
       "262295   [155647, 155647, 170790, 170790, 170790, 170790]   \n",
       "\n",
       "                                          event_type-list  \\\n",
       "262294  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "262295                                 [1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                      product_action-list  \\\n",
       "262294  [0, 6, 0, 6, 6, 0, 6, 0, 6, 0, 0, 6, 0, 6, 6, ...   \n",
       "262295                                 [3, 3, 3, 3, 1, 1]   \n",
       "\n",
       "                                       category_hash-list  \\\n",
       "262294  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "262295                           [46, 46, 46, 46, 46, 46]   \n",
       "\n",
       "                                       main_category-list  \\\n",
       "262294  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "262295                                 [2, 2, 2, 2, 2, 2]   \n",
       "\n",
       "                                        price_bucket-list  \\\n",
       "262294  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "262295                                 [7, 7, 8, 8, 8, 8]   \n",
       "\n",
       "                                mean_price_hierarchy-list  \\\n",
       "262294  [0.010557701, 0.010557701, 0.010557701, 0.0105...   \n",
       "262295  [0.72179425, 0.72179425, 0.72179425, 0.7217942...   \n",
       "\n",
       "                                     mean_price_main-list  \\\n",
       "262294  [0.02335137, 0.02335137, 0.02335137, 0.0233513...   \n",
       "262295  [0.02335137, 0.02335137, 0.02335137, 0.0233513...   \n",
       "\n",
       "        product_sku_hash_count  \\\n",
       "262294                      24   \n",
       "262295                       6   \n",
       "\n",
       "                                    product_sku_hash_list  \\\n",
       "262294  [55897, 55897, 55897, 55897, 55897, 55897, 558...   \n",
       "262295         [49338, 49338, 54109, 54109, 54109, 54109]   \n",
       "\n",
       "        product_url_hash_count       ts-first        ts-last  \\\n",
       "262294                      24  1552353672164  1552354551465   \n",
       "262295                       6  1548970153891  1548970245921   \n",
       "\n",
       "                                                  ts-list  \\\n",
       "262294  [1552353672164, 1552353672164, 1552353688549, ...   \n",
       "262295  [1548970153891, 1548970153891, 1548970168089, ...   \n",
       "\n",
       "                                  timestamp_hour_cos-list  \\\n",
       "262294  [0.96592575, 0.96592575, 0.96592575, 0.9659257...   \n",
       "262295  [0.707107, 0.707107, 0.707107, 0.707107, 0.707...   \n",
       "\n",
       "                                  timestamp_hour_sin-list  \\\n",
       "262294  [0.25881928, 0.25881928, 0.25881928, 0.2588192...   \n",
       "262295  [-0.70710653, -0.70710653, -0.70710653, -0.707...   \n",
       "\n",
       "                                    timestamp_wd_sin-list  \\\n",
       "262294  [0.9749277, 0.9749277, 0.9749277, 0.9749277, 0...   \n",
       "262295  [-0.43388462, -0.43388462, -0.43388462, -0.433...   \n",
       "\n",
       "                                    timestamp_wd_cos-list  \\\n",
       "262294  [-0.22252177, -0.22252177, -0.22252177, -0.222...   \n",
       "262295  [-0.90096843, -0.90096843, -0.90096843, -0.900...   \n",
       "\n",
       "                                  timestamp_age_days-list  \\\n",
       "262294  [55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 5...   \n",
       "262295                           [16, 16, 16, 16, 16, 16]   \n",
       "\n",
       "                             timestamp_age_days_norm-list  first_AC_id-last  \\\n",
       "262294  [0.7122043, 0.7122043, 0.7122043, 0.7122043, 0...            111417   \n",
       "262295  [-0.23774733, -0.23774733, -0.23774733, -0.237...            170790   \n",
       "\n",
       "        is_purchased-last  purchase_timestamp-last nb_after_add-last  \\\n",
       "262294                  0            1552354551465              <NA>   \n",
       "262295                  0            1548970245922              <NA>   \n",
       "\n",
       "        is_search-last  is_test-last  \n",
       "262294               0             0  \n",
       "262295               0             0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SELECTED_COLS = ['session_id_hash', 'day_index', 'product_url_hash_list',\n",
    "                 'event_type-list', 'product_action-list', \n",
    "                \n",
    "                'category_hash-list', 'main_category-list',\n",
    "                'price_bucket-list', 'mean_price_hierarchy-list', 'mean_price_main-list',\n",
    "                \n",
    "                'product_sku_hash_count',  'product_sku_hash_list',\n",
    "                'product_url_hash_count',\n",
    "                \n",
    "                 'ts-first', 'ts-last',  'ts-list',\n",
    "                 'timestamp_hour_cos-list', 'timestamp_hour_sin-list', 'timestamp_wd_sin-list', 'timestamp_wd_cos-list',\n",
    "                 'timestamp_age_days-list', 'timestamp_age_days_norm-list', \n",
    "                \n",
    "                 'first_AC_id-last', 'is_purchased-last', 'purchase_timestamp-last', 'nb_after_add-last',\n",
    "                 'is_search-last' ,'is_test-last',\n",
    "                ] \n",
    "         \n",
    "\n",
    "sessions_gdf = sessions_gdf[SELECTED_COLS]\n",
    "sessions_gdf.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Un-hash session id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_map = cudf.read_parquet(OUTPUT_DIR + '/categorify_workflow/categories/unique.session_id_hash.parquet').reset_index()\n",
    "session_map.columns = ['session_id_hash', 'original_session_id_hash']\n",
    "sessions_gdf = sessions_gdf.merge(session_map, on=['session_id_hash'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get index of AC product in the session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_gdf = sessions_gdf.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262296/262296 [00:06<00:00, 39551.86it/s]\n"
     ]
    }
   ],
   "source": [
    "sessions_gdf['first_add_index'] = sessions_gdf.progress_apply(lambda x: x['product_url_hash_list'].tolist().index(x['first_AC_id-last']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute actual number of non repeated interactions after add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262296/262296 [00:04<00:00, 60838.29it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_nb_after_add(x): \n",
    "    add_index =  x['first_add_index']\n",
    "    nb_after_last_add = len(x['product_url_hash_list']) - add_index - 1\n",
    "    return nb_after_last_add\n",
    "sessions_gdf['original_nb_after_add'] = sessions_gdf.progress_apply(get_nb_after_add, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute artificially designed `nb_after_add` for train and validation session : By selecting nb_after_add in (0, 2, 4, 6, 8, 10) closest to the given value of actual number of events after the first AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 214585/214585 [00:00<00:00, 304277.85it/s]\n"
     ]
    }
   ],
   "source": [
    "NB_AFTER_ADD = [0, 2, 4, 6, 8, 10]\n",
    "sessions_gdf.loc[sessions_gdf['is_test-last']==0, 'nb_after_add-last'] = \\\n",
    "sessions_gdf.loc[sessions_gdf['is_test-last']==0, 'original_nb_after_add'].progress_apply(\n",
    "    lambda z: min(NB_AFTER_ADD, key=lambda x:abs(x-z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create cross-validation folds : \n",
    "     - Define random 5 folds column \n",
    "     - Reserve the 3 last weeks for validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "sessions_gdf['fold'] = np.random.randint(1,6, sessions_gdf.shape[0]) \n",
    "sessions_gdf['is_valid'] = 0 \n",
    "sessions_gdf.loc[((sessions_gdf['is_test-last']==0) & (sessions_gdf['day_index']<=50)), 'is_valid'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save session table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the whole session table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_gdf.to_parquet(os.path.join(OUTPUT_DIR, 'session_interactions_task2_preproc2.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Save unique product sku mapping from updated product_url_hash encoded column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55898 unique product\n"
     ]
    }
   ],
   "source": [
    "urls_ids = interactions_merged_df[interactions_merged_df.event_type==2]['product_url_hash'].unique()\n",
    "mapping = pd.read_parquet(OUTPUT_DIR + '/categorify_workflow/categories/unique.product_url_hash_first_purchase_id_first_AC_id.parquet')\n",
    "mask = mapping.reset_index()['index'].isin(urls_ids)\n",
    "mapping_prod = mapping[~mask].reset_index()\n",
    "mapping_prod.columns =  ['encoded_product_sku', 'original_product_sku']\n",
    "print(\"There are %s unique product\" %mapping_prod.shape[0])\n",
    "mapping_prod.to_parquet(OUTPUT_DIR +'/mapping_product_sku_without_urls_task2_v2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save products embedding matrices based on their encoded ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66386/66386 [00:06<00:00, 11021.03it/s]\n",
      "100%|██████████| 66386/66386 [00:05<00:00, 12523.92it/s]\n"
     ]
    }
   ],
   "source": [
    "product_info = pd.read_csv('/workspace/sku_to_content.csv', usecols=['product_sku_hash', \n",
    "                                                                     'description_vector', \n",
    "                                                                     'image_vector'])\n",
    "# convert strings to list object \n",
    "import ast\n",
    "def convert_str_to_list(x): \n",
    "    if pd.isnull(x): \n",
    "        return x\n",
    "    return ast.literal_eval(x)\n",
    "for col in ['description_vector', 'image_vector']: \n",
    "    product_info[col] = product_info[col].progress_apply(convert_str_to_list)\n",
    "product_info.columns = ['original_product_sku', 'description_vector', 'image_vector']\n",
    "\n",
    "### Merge product embeddings and mapping_prod\n",
    "embeddings_table = mapping_prod.merge(product_info, on=['original_product_sku'], how='left')\n",
    "\n",
    "# Fill missing embeddings with vector of zeros \n",
    "embeddings_table.loc[embeddings_table.description_vector.isnull(),\n",
    "                         'description_vector'] = pd.Series([np.zeros(50)] * embeddings_table.description_vector.isnull().sum()).values\n",
    "\n",
    "embeddings_table.loc[embeddings_table.image_vector.isnull(),\n",
    "                         'image_vector'] = pd.Series([np.zeros(50)] * embeddings_table.image_vector.isnull().sum()).values\n",
    "\n",
    "# Create Numpy matrix with the image vectors of the products\n",
    "image_matrix = np.concatenate(embeddings_table.image_vector.values).reshape(-1, 50)\n",
    "# Create Numpy matrix with the description vectors of the products\n",
    "desc_matrix = np.concatenate(embeddings_table.description_vector.values).reshape(-1, 50)\n",
    "# Define a dictionary to map the encoded product_sku to the position in the embedding matrices\n",
    "mapping_id_sku_emb_position = dict(zip(embeddings_table.encoded_product_sku, embeddings_table.index))\n",
    "# Saving the objects:\n",
    "import pickle\n",
    "with open(OUTPUT_DIR+'/embedding_data_v2.pkl', 'wb') as f:  \n",
    "    pickle.dump([desc_matrix, image_matrix, mapping_id_sku_emb_position], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <center> <a id='session_duplicate'>  Duplicated train sessions with different split points after the AC event </a></center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load session browsing data \n",
    "data = pd.read_parquet(os.path.join(OUTPUT_DIR, \"session_interactions_task2_preproc2.parquet\"))\n",
    "#load product embeddings \n",
    "desc_matrix, image_matrix, mapping_id_sku_emb_position = pickle.load(open(OUTPUT_DIR + \"/embedding_data_v2.pkl\", \"rb\"))\n",
    "#load encoded product-ids\n",
    "mapping = pd.read_parquet(os.path.join(OUTPUT_DIR,\n",
    "                                       \"categorify_workflow/categories/unique.product_url_hash_first_purchase_id_first_AC_id.parquet\"))\n",
    "#load session search data \n",
    "search_session = pd.read_parquet(os.path.join(OUTPUT_DIR, \"session_search.parquet\"))\n",
    "search_session.columns = ['original_session_id_hash', 'flat_query_vector', 'flat_product_skus_hash',\n",
    "       'flat_clicked_skus_hash', 'impressions_size', 'clicks_size',\n",
    "       'nb_queries', 'clicked-flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Repeat rows of sessions with different number of actions after the AC event : Only for train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 214585/214585 [01:44<00:00, 2046.38it/s]\n"
     ]
    }
   ],
   "source": [
    "def truncate_at_different_position(x, feature_list): \n",
    "    product_id =  x['first_AC_id-last']\n",
    "    nb_after_add = x['nb_after_add-last']\n",
    "    add_index = x['product_action-list'].tolist().index(1)\n",
    "    general_feat = []\n",
    "    if nb_after_add == 0: \n",
    "        general_feat.append([x[col][:int(add_index+nb_after_add+1)] for col in feature_list])\n",
    "    \n",
    "    else:\n",
    "        for i in range(0, int(nb_after_add)+2, 2) : \n",
    "            general_feat.append([x[col][0:int(add_index+i+1)] for col in feature_list])\n",
    "    return general_feat\n",
    "\n",
    "feature_list = [col for col in data.columns if 'list' in col]\n",
    "non_list_features = [col for col in data.columns if 'list' not in col]\n",
    "\n",
    "list_frame = data[data['is_test-last'] == 0][non_list_features].copy()\n",
    "list_frame['dynamic_truncated_lists'] = data[data['is_test-last'] == 0].progress_apply(partial(truncate_at_different_position,\n",
    "                                                                                               feature_list=feature_list), axis=1)\n",
    "# Unstack the list of clicked items to multiple rows : each row is a single clicked item \n",
    "lst_col = 'dynamic_truncated_lists'\n",
    "duplicated_sessions = pd.DataFrame({\n",
    "    col:np.repeat(list_frame[col].values,\n",
    "                  list_frame[lst_col].str.len()) for col in list_frame.columns.difference([lst_col])}).assign(\n",
    "    **{lst_col:[item for sublist in list_frame[lst_col].values for item in sublist]})[list_frame.columns.tolist()]\n",
    "# Unstack truncated lists to 22 feature)list columns \n",
    "t = pd.DataFrame(duplicated_sessions[lst_col].to_list(), columns=feature_list)\n",
    "duplicated_frame = pd.concat([duplicated_sessions, t], axis=1)\n",
    "duplicated_frame.drop(lst_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Update nb_after_add-last column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1173855/1173855 [00:30<00:00, 38105.89it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_nb_after_add(x): \n",
    "    product_id =  x['first_AC_id-last']\n",
    "    add_index = x['product_url_hash_list'].tolist().index(product_id)\n",
    "    nb_after_last_add = len(x['product_url_hash_list']) - add_index - 1\n",
    "    return nb_after_last_add\n",
    "duplicated_frame['updated_original_nb_after_add'] = duplicated_frame.progress_apply(get_nb_after_add, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1173855/1173855 [00:03<00:00, 342219.81it/s]\n"
     ]
    }
   ],
   "source": [
    "NB_AFTER_ADD = [0, 2, 4, 6, 8, 10]\n",
    "duplicated_frame.loc[duplicated_frame['is_test-last']==0, 'nb_after_add-last'] = \\\n",
    "duplicated_frame.loc[duplicated_frame['is_test-last']==0, 'updated_original_nb_after_add'].progress_apply(\n",
    "    lambda z: min(NB_AFTER_ADD, key=lambda x:abs(x-z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge back with test sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_frame = pd.concat([data[data['is_test-last']==1],duplicated_frame])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_frame.to_parquet(os.path.join(OUTPUT_DIR, 'duplicated_sessions_with_different_nb_after_add_cuts.parquet'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c47d106ac78ce38a91b980f6e93d54b8debc81758e991dc6d6ecbd1a520b3c1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
