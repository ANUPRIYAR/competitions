{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA CORPORATION\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08de3e8e-f1f3-4844-b8e2-33a0686956e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]='1'\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf\n",
    "import cupy\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "from util import compute_rce_fast\n",
    "\n",
    "DP = len(os.environ[\"CUDA_VISIBLE_DEVICES\"].split(','))>1\n",
    "DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ebd93d-2073-45ce-ba0a-e054620f4c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1+cu101'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.loader.torch import TorchAsyncItr, DLDataLoader\n",
    "from nvtabular.framework_utils.torch.models import Model\n",
    "from nvtabular.framework_utils.torch.utils import process_epoch\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142d0ca-20ef-4588-8f78-1c1cc0bed872",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c5357a2-1e6d-4544-8229-a664bb92af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatenatedEmbeddings(torch.nn.Module):\n",
    "    \"\"\"Map multiple categorical variables to concatenated embeddings.\n",
    "    Args:\n",
    "        embedding_table_shapes: A dictionary mapping column names to\n",
    "            (cardinality, embedding_size) tuples.\n",
    "        dropout: A float.\n",
    "    Inputs:\n",
    "        x: An int64 Tensor with shape [batch_size, num_variables].\n",
    "    Outputs:\n",
    "        A Float Tensor with shape [batch_size, embedding_size_after_concat].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_table_shapes, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.embedding_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                torch.nn.Embedding(cat_size, emb_size, sparse=(cat_size > 1e5))\n",
    "                for cat_size, emb_size in embedding_table_shapes.values()\n",
    "            ]\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "            \n",
    "        # first two cat columns (a_user and b_user) share same emb table            \n",
    "        x = [self.embedding_layers[0](x[:,0])] + [layer(x[:, i+1]) for i, layer in enumerate(self.embedding_layers)] \n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dbc381f-e5c0-40c8-ba0f-a4081f042fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "class Swish(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "        sigmoid_i = sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "\n",
    "class Swish_Module(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return Swish.apply(x)\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "bert_type = 'distilbert-base-multilingual-cased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_type)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features, layers, embedding_table_shapes, dropout=0.2, bert_type=None, gru_dim=128, emb_dim=768):\n",
    "        super(Net, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.initial_cat_layer = ConcatenatedEmbeddings(embedding_table_shapes, dropout=dropout)\n",
    "        embedding_size = sum(emb_size for _, emb_size in embedding_table_shapes.values())\n",
    "        layers = [layers] if type(layers) is int else layers\n",
    "        layers = [num_features + gru_dim + embedding_size + 128 + 128] + layers\n",
    "        self.use_bert = True\n",
    "        self.embed = AutoModel.from_pretrained(bert_type).embeddings.word_embeddings  \n",
    "        assert emb_dim == self.embed.embedding_dim\n",
    "#             self.reduce_dim = nn.Linear(self.embed.embedding_dim, 256)\n",
    "#             self.embed = nn.Embedding(119547, emb_dim)\n",
    "#         layers[0] += gru_dim\n",
    "        self.lstm = nn.GRU(emb_dim, gru_dim, batch_first=True, bidirectional=False)    \n",
    "#             self.lstm = nn.Linear(self.embed.embedding_dim, gru_dim)\n",
    "\n",
    "        self.fn_layers = nn.ModuleList(\n",
    "                            nn.Sequential(\n",
    "                                nn.Dropout(p=dropout),\n",
    "                                nn.Linear(layers[i], layers[i+1]),\n",
    "                                nn.BatchNorm1d(layers[i+1]),\n",
    "                                Swish_Module(),\n",
    "                            )  for i in range(len(layers) -1)\n",
    "                         )        \n",
    "        self.fn_last = nn.Linear(layers[-1],4)\n",
    "        \n",
    "    def forward(self, x_cat, x_cont, bert_tok):\n",
    "        a_emb = self.initial_cat_layer.embedding_layers[0](x_cat[:,0])\n",
    "        b_emb = self.initial_cat_layer.embedding_layers[0](x_cat[:,1])\n",
    "        mf = a_emb * b_emb        \n",
    "        \n",
    "        x_cat = self.initial_cat_layer(x_cat)\n",
    "        bert_tok = self.embed(bert_tok)#.mean(dim=1)\n",
    "#             bert_tok = self.reduce_dim(bert_tok)\n",
    "        lstm_out = self.lstm(bert_tok)[0][:,-1]\n",
    "        output = torch.cat([x_cont, lstm_out, x_cat, mf],dim=1)\n",
    "        for layer in self.fn_layers:\n",
    "            output = layer(output)\n",
    "        logit = self.fn_last(output)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffdaf6f-5b69-4271-a6fd-6469f4209e8e",
   "metadata": {},
   "source": [
    "## scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae1318b-1d72-4949-b739-65aeb46886f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e6868-78c9-4c24-b9af-f21d163f1e00",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4fcf98-08b0-4857-a152-b452e9bc1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_epoch(model, loader, optimizer, scaler, optimizer2):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader)\n",
    "    for batch in bar:\n",
    "        x_cat, x_cont, text_tok, targets = batch\n",
    "        \n",
    "        x_cat = x_cat.cuda()\n",
    "        x_cont = x_cont.cuda()\n",
    "        text_tok = text_tok.cuda()\n",
    "        targets = targets.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        if use_torch_amp:\n",
    "            with amp.autocast():\n",
    "                logits = model(x_cat, x_cont, text_tok)\n",
    "#                 logits = model(data)\n",
    "            loss = criterion(logits, targets)       \n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # You can choose which optimizers receive explicit unscaling, if you\n",
    "            # want to inspect or modify the gradients of the params they own.\n",
    "            scaler.unscale_(optimizer)\n",
    "            scaler.unscale_(optimizer2)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.step(optimizer2)\n",
    "\n",
    "            scaler.update()            \n",
    "            \n",
    "        elif use_amp:\n",
    "            logits = model(x_cat, x_cont, text_tok)\n",
    "#             logits = model(data)\n",
    "            loss = criterion(logits, targets)\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            logits = model(x_cat, x_cont, text_tok)\n",
    "#             logits = model(data)\n",
    "            loss = criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_np = loss.item()\n",
    "        train_loss.append(loss_np)\n",
    "        smooth_loss = sum(train_loss[-50:]) / min(len(train_loss), 50)\n",
    "        bar.set_description('loss: %.4f, smth: %.4f' % (loss_np, smooth_loss))\n",
    "\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def valid_epoch(model, loader):\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    LOGITS = []\n",
    "    TARGETS = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            x_cat, x_cont, text_tok, targets = batch\n",
    "\n",
    "            x_cat = x_cat.cuda()\n",
    "            x_cont = x_cont.cuda()\n",
    "            text_tok = text_tok.cuda()\n",
    "            targets = targets.cuda()\n",
    "        \n",
    "            logits = model(x_cat, x_cont, text_tok)\n",
    "#             logits = model(data)\n",
    "            loss = criterion(logits, targets)\n",
    "            val_loss.append(loss.item())\n",
    "            LOGITS.append(logits.cpu())\n",
    "            TARGETS.append(targets.cpu())\n",
    "            \n",
    "    LOGITS = torch.cat(LOGITS)\n",
    "    TARGETS = torch.cat(TARGETS)\n",
    "    rce = {}\n",
    "    for i in range(4):\n",
    "        rce[label_names[i]] = compute_rce_fast(cp.asarray(LOGITS[:,i].sigmoid()),cp.asarray(TARGETS[:,i])).get()            \n",
    "    mean_rce = np.mean([v for k,v in rce.items()])\n",
    "            \n",
    "    val_loss = np.mean(val_loss)\n",
    "\n",
    "    return val_loss, rce, mean_rce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c66106-c3f9-47b2-b2c9-e618a51aab2e",
   "metadata": {},
   "source": [
    "# NVT loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3e27c51-d7f4-4f6d-b892-2d0e8fecc0ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = sorted(['reply', 'retweet', 'retweet_comment', 'like'])\n",
    "CAT_COLUMNS = ['a_user_id','b_user_id','language','media','tweet_type']\n",
    "NUMERIC_COLUMNS = ['a_follower_count',\n",
    "                     'a_following_count',\n",
    "                     'a_is_verified',\n",
    "                     'b_follower_count',\n",
    "                     'b_following_count',\n",
    "                     'b_is_verified',\n",
    "                     'b_follows_a',\n",
    "                     'tw_len_media',\n",
    "                     'tw_len_photo',\n",
    "                     'tw_len_video',\n",
    "                     'tw_len_gif',\n",
    "                     'tw_len_quest',\n",
    "                     'tw_len_token',\n",
    "                     'tw_count_capital_words',\n",
    "                     'tw_count_excl_quest_marks',\n",
    "                     'tw_count_special1',\n",
    "                     'tw_count_hash',\n",
    "                     'tw_last_quest',\n",
    "                     'tw_len_retweet',\n",
    "                     'tw_len_rt',\n",
    "                     'tw_count_at',\n",
    "                     'tw_count_words',\n",
    "                     'tw_count_char',\n",
    "                     'tw_rt_count_words',\n",
    "                     'tw_rt_count_char',\n",
    "                     'len_hashtags',\n",
    "                     'len_links',\n",
    "                     'len_domains',\n",
    "                     'a_ff_rate',\n",
    "                     'b_ff_rate',\n",
    "                     'ab_fing_rate',\n",
    "                     'ab_fer_rate',\n",
    "                     'a_age',\n",
    "                     'b_age',\n",
    "                     'ab_age_dff',\n",
    "                     'ab_age_rate']\n",
    "len(NUMERIC_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abeb8553-a64f-4c6e-a444-7cc2e01a793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_norm_merge(path, split='train'):\n",
    "    ddf = pd.read_parquet(path)\n",
    "\n",
    "    ddf['quantile'] = 0\n",
    "    quantiles = [92, 216, 442, 1064]\n",
    "    for i, quant in enumerate(quantiles):\n",
    "        ddf['quantile'] = (ddf['quantile']+(ddf['a_follower_count']>quant).astype('int8')).astype('int8')\n",
    "\n",
    "    ddf['date'] = pd.to_datetime(ddf['timestamp'], unit='s')\n",
    "    \n",
    "    VALID_DOW = '2021-02-18'\n",
    "    if split=='train':\n",
    "        ddf = ddf[ddf['date']<pd.to_datetime(VALID_DOW)].reset_index(drop=True)\n",
    "    elif split=='valid':\n",
    "        ddf = ddf[ddf['date']>=pd.to_datetime(VALID_DOW)].reset_index(drop=True)    \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    ddf['a_ff_rate'] = (ddf['a_following_count'] / ddf['a_follower_count']).astype('float32')\n",
    "    ddf['b_ff_rate'] = (ddf['b_follower_count']  / ddf['b_following_count']).astype('float32')\n",
    "    ddf['ab_fing_rate'] = (ddf['a_following_count'] / ddf['b_following_count']).astype('float32')\n",
    "    ddf['ab_fer_rate'] = (ddf['a_follower_count'] / (1+ddf['b_follower_count'])).astype('float32')\n",
    "    ddf['a_age'] = ddf['a_account_creation'].astype('int16') + 128\n",
    "    ddf['b_age'] = ddf['b_account_creation'].astype('int16') + 128\n",
    "    ddf['ab_age_dff'] = ddf['b_age'] - ddf['a_age']\n",
    "    ddf['ab_age_rate'] = ddf['a_age']/(1+ddf['b_age'])\n",
    "\n",
    "    ## Normalize\n",
    "    for col in NUMERIC_COLUMNS:\n",
    "        if col == 'tw_len_quest':\n",
    "            ddf[col] = np.clip(ddf[col].values,0,None)\n",
    "        if ddf[col].dtype == 'uint16':\n",
    "            ddf[col].astype('int32')\n",
    "\n",
    "        if col == 'ab_age_dff':\n",
    "            ddf[col] = ddf[col] / 256.            \n",
    "        elif 'int' in str(ddf[col].dtype) or 'float' in str(ddf[col].dtype):    \n",
    "            ddf[col] = np.log1p(ddf[col])\n",
    "\n",
    "        if ddf[col].dtype == 'float64':\n",
    "            ddf[col] = ddf[col].astype('float32') \n",
    "\n",
    "    ## get categorical embedding id        \n",
    "    for col in CAT_COLUMNS:\n",
    "        ddf[col] = ddf[col].astype('float')\n",
    "        if col in ['a_user_id','b_user_id']:\n",
    "            mapping_col = 'a_user_id_b_user_id'\n",
    "        else:\n",
    "            mapping_col = col\n",
    "        mapping = pd.read_parquet(f'/raid/recsys_pre_TE_w_tok/workflow_232parts_joint_thr3_pos/categories/unique.{mapping_col}.parquet').reset_index()\n",
    "        mapping.columns = ['index',col]\n",
    "        ddf = ddf.merge(mapping, how='left', on=col).drop(columns=[col]).rename(columns={'index':col})\n",
    "        ddf[col] = ddf[col].fillna(0).astype('int')        \n",
    "\n",
    "    label_names = ['reply', 'retweet', 'retweet_comment', 'like']\n",
    "    DONT_USE = ['timestamp','a_account_creation','b_account_creation','engage_time',\n",
    "                'fold', 'dt_dow', 'a_account_creation', \n",
    "                'b_account_creation', 'elapsed_time', 'links','domains','hashtags','id', 'date', 'is_train', \n",
    "                'tw_hash0', 'tw_hash1', 'tw_hash2', 'tw_http0', 'tw_uhash', 'tw_hash', 'tw_word0', \n",
    "                'tw_word1', 'tw_word2', 'tw_word3', 'tw_word4', 'dt_minute', 'dt_second',\n",
    "               'dt_day', 'group', 'text', 'tweet_id', 'tw_original_user0', 'tw_original_user1', 'tw_original_user2',\n",
    "                'tw_rt_user0', 'tw_original_http0', 'tw_tweet',]\n",
    "    DONT_USE = [c for c in ddf.columns if c in DONT_USE]\n",
    "    gc.collect(); gc.collect()\n",
    "    \n",
    "    return ddf.drop(columns=DONT_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6a8e481-23df-415c-ade3-299add4cdf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATHS = sorted(glob.glob('/raid/recsys/train_proc3/*.parquet'))\n",
    "len(PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59f81865-e61a-4565-9d87-24eb576825c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for col in NUMERIC_COLUMNS:\n",
    "#     print(col)\n",
    "#     plt.hist(train[col].values, bins=50)\n",
    "#     plt.title(col)\n",
    "# #     print(ddf[col].describe())\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecbabe9b-0254-4619-9f36-bcf30c32da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class AllDataset(Dataset):\n",
    "    def __init__(self, df, max_len_txt, NUMERIC_COLUMNS, CAT_COLUMNS):\n",
    "        self.X = df[NUMERIC_COLUMNS].values\n",
    "        self.X_cat = df[CAT_COLUMNS].values\n",
    "        self.labels = df[label_names].values\n",
    "        self.text_tokens = df.text_tokens.values\n",
    "        self.max_len_txt = max_len_txt\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    def __getitem__(self, index):        \n",
    "#         text = tokenizer.decode([int(token_id) for token_id in self.text_tokens[index][4:-4].split('\\t')]) # [4:-4] is to remove [CLS] and [SEP]\n",
    "#         inputs = tokenizer(text, truncation=True, padding='max_length', max_length=max_len_txt, return_tensors='pt')['input_ids'].squeeze()\n",
    "        inputs = [int(token_id) for token_id in self.text_tokens[index].split('\\t')][:self.max_len_txt]\n",
    "        if len(inputs) < self.max_len_txt:\n",
    "            inputs += [0]*(self.max_len_txt-len(inputs))\n",
    "        return self.X_cat[index], self.X[index].astype(np.float32), torch.tensor(inputs), self.labels[index].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666aa658-d2f1-424e-8a6d-46b04d4fe7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_dim=128\n",
    "max_len_txt=48\n",
    "emb_dim=768\n",
    "lr = 1e-2\n",
    "lr2= 1e-4\n",
    "ep = 46   \n",
    "BATCH_SIZE = 1024\n",
    "num_workers = 16\n",
    "use_torch_amp = True\n",
    "import torch.cuda.amp as amp\n",
    "use_amp = False\n",
    "\n",
    "model_name = 'load_thr3_pos_1e-2_1e-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8234130-ef5e-431a-82b4-20d069e97a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NUMERIC_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7e34ad1-7f5e-4c9f-b906-77c1cb3c8a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 46s, sys: 1min 8s, total: 9min 55s\n",
      "Wall time: 9min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10324907, 47), 10083)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_lst = []\n",
    "for path in PATHS[:10]:\n",
    "    train_lst.append(read_norm_merge(path, 'valid'))\n",
    "valid = pd.concat(train_lst)\n",
    "gc.collect()\n",
    "\n",
    "valid_dataset = AllDataset(valid, max_len_txt, NUMERIC_COLUMNS, CAT_COLUMNS)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers) \n",
    "valid.shape, len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ae69d2c-d12c-4e75-ab23-e4673ff37dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 46, 111, 208, 230,   3,  22, 227, 153,  78,  52,  20, 185,   6,\n",
       "        130, 177,  83,  97, 194,  24, 187,  93,  59, 217, 180, 129,  62,\n",
       "          1,  43, 229, 102, 196,  50,   4,  12, 114,  70,  18,  91,  71,\n",
       "        190, 174,  23,  63,  89, 188,  16, 104,  67,  39, 225, 176,  28,\n",
       "        198,   2,  76, 166, 216, 116, 199, 113, 107, 201,  64, 115,   8,\n",
       "        171,  44, 218, 158, 181,  79,  47, 155, 159, 164, 109,  56, 106,\n",
       "        122, 203, 144,  14, 163, 124, 110, 126,  80,  77,  94, 135,  33,\n",
       "        134, 224, 145, 172, 191,  60, 148, 215, 212, 219,  35, 167,  37,\n",
       "        132, 182, 228,  75,  87, 156, 137,  74,  29,  95, 118,  90, 222,\n",
       "         19,  57, 162, 105, 223, 210, 140,  10,  72, 152, 183, 170,  51,\n",
       "         82, 117,  13, 211, 120,  81, 160,  27, 200, 128, 169, 213, 179,\n",
       "         42,  11, 143,  15, 209, 151,  48, 207, 112, 119, 231, 175,   0,\n",
       "        146, 154,  68, 197,  21, 206, 125, 192,  31,  86, 138,  36, 108,\n",
       "        103,  58, 142,  54,  98,  99, 127, 214,   7,  92, 121, 202, 141,\n",
       "        150,  88,  53,  38, 139, 147, 131,  66,  40,  26, 123,  73, 100,\n",
       "        165, 186, 149, 205,   5, 189,  25,  32, 133, 101, 204, 178, 193,\n",
       "        136,  84, 161,  30, 221,  65,  85,  41,  17,  61,  45, 173, 195,\n",
       "          9, 184,  55,  49, 168,  69,  34,  96, 157, 226, 220]),\n",
       " (232,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_parts_order = np.concatenate([np.random.permutation(232)])\n",
    "train_parts_order = np.array([ 46, 111, 208, 230,   3,  22, 227, 153,  78,  52,  20, 185,   6,\n",
    "        130, 177,  83,  97, 194,  24, 187,  93,  59, 217, 180, 129,  62,\n",
    "          1,  43, 229, 102, 196,  50,   4,  12, 114,  70,  18,  91,  71,\n",
    "        190, 174,  23,  63,  89, 188,  16, 104,  67,  39, 225, 176,  28,\n",
    "        198,   2,  76, 166, 216, 116, 199, 113, 107, 201,  64, 115,   8,\n",
    "        171,  44, 218, 158, 181,  79,  47, 155, 159, 164, 109,  56, 106,\n",
    "        122, 203, 144,  14, 163, 124, 110, 126,  80,  77,  94, 135,  33,\n",
    "        134, 224, 145, 172, 191,  60, 148, 215, 212, 219,  35, 167,  37,\n",
    "        132, 182, 228,  75,  87, 156, 137,  74,  29,  95, 118,  90, 222,\n",
    "         19,  57, 162, 105, 223, 210, 140,  10,  72, 152, 183, 170,  51,\n",
    "         82, 117,  13, 211, 120,  81, 160,  27, 200, 128, 169, 213, 179,\n",
    "         42,  11, 143,  15, 209, 151,  48, 207, 112, 119, 231, 175,   0,\n",
    "        146, 154,  68, 197,  21, 206, 125, 192,  31,  86, 138,  36, 108,\n",
    "        103,  58, 142,  54,  98,  99, 127, 214,   7,  92, 121, 202, 141,\n",
    "        150,  88,  53,  38, 139, 147, 131,  66,  40,  26, 123,  73, 100,\n",
    "        165, 186, 149, 205,   5, 189,  25,  32, 133, 101, 204, 178, 193,\n",
    "        136,  84, 161,  30, 221,  65,  85,  41,  17,  61,  45, 173, 195,\n",
    "          9, 184,  55,  49, 168,  69,  34,  96, 157, 226, 220])\n",
    "train_parts_order, train_parts_order.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c75fba5-0a0b-4512-8edf-d57b61755a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (initial_cat_layer): ConcatenatedEmbeddings(\n",
       "    (embedding_layers): ModuleList(\n",
       "      (0): Embedding(19688213, 128, sparse=True)\n",
       "      (1): Embedding(67, 16)\n",
       "      (2): Embedding(15, 16)\n",
       "      (3): Embedding(4, 16)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (embed): Embedding(119547, 768, padding_idx=0)\n",
       "  (lstm): GRU(768, 128, batch_first=True)\n",
       "  (fn_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=596, out_features=1024, bias=True)\n",
       "      (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Swish_Module()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Swish_Module()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Swish_Module()\n",
       "    )\n",
       "  )\n",
       "  (fn_last): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(len(NUMERIC_COLUMNS), layers=[1024,256,64], \n",
    "            embedding_table_shapes={'a_user_id_b_user_id': (19688213, 128), 'language': (67, 16), 'media': (15, 16), 'tweet_type': (4, 16)},\n",
    "            bert_type=bert_type).cuda()\n",
    "\n",
    "for param in model.embed.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec651c84-c9d8-4d66-b73c-3c4b6a1201cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['initial_cat_layer.embedding_layers.0.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = torch.load(f'../models/two_opt_lr3_load_len48_joint_thr10_3e-3_1e-4_best.pth',map_location='cpu')\n",
    "sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "del sd['initial_cat_layer.embedding_layers.0.weight']\n",
    "model.load_state_dict(sd, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4b1c59a-cc04-42cc-aad3-872acd35d8af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SparseAdam(list(model.parameters())[:1], lr=lr)\n",
    "optimizer2 = optim.AdamW(list(model.parameters())[1:], lr=lr2)\n",
    "scaler = amp.GradScaler() if use_torch_amp else None\n",
    "\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, ep-1)\n",
    "scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n",
    "\n",
    "scheduler_cosine2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer2, ep-1)\n",
    "scheduler_warmup2 = GradualWarmupSchedulerV2(optimizer2, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine2)\n",
    "\n",
    "rce_best = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce433137-534f-42bf-9c7b-553eb86743c8",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8456096-07c1-4af1-928e-d4a94cb793be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_thr3_pos_1e-2_1e-4\n"
     ]
    }
   ],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a5c46a5-37b6-46ec-937d-ae5f843327df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 11:11:07 2021 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:43<00:00, 68.80s/it]\n",
      "loss: 0.2394, smth: 0.2333: 100%|██████████| 12298/12298 [08:56<00:00, 22.92it/s]\n",
      "100%|██████████| 10083/10083 [02:04<00:00, 81.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 11:27:58 2021 Epoch 1, lr: 0.0100000, 0.0001000, train loss: 0.2404, valid loss: 0.2342, mean_rce: 14.77, retweet: 17.89, reply: 16.44, like: 18.48, retweet_comment: 6.26\n",
      "rce_best increased (0.000000 --> 14.766256).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 11:35:03 2021 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:06<00:00, 73.32s/it]\n",
      "loss: 0.2220, smth: 0.2249: 100%|██████████| 13575/13575 [09:53<00:00, 22.88it/s]\n",
      "100%|██████████| 10083/10083 [02:06<00:00, 79.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 11:53:21 2021 Epoch 2, lr: 0.1000000, 0.0010000, train loss: 0.2268, valid loss: 0.2222, mean_rce: 18.61, retweet: 22.99, reply: 19.35, like: 22.57, retweet_comment: 9.52\n",
      "rce_best increased (14.766256 --> 18.606373).  Saving model ...\n",
      "Thu Jun 10 12:00:29 2021 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:10<00:00, 74.15s/it]\n",
      "loss: 0.2233, smth: 0.2198: 100%|██████████| 13671/13671 [09:52<00:00, 23.07it/s]\n",
      "100%|██████████| 10083/10083 [02:06<00:00, 79.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 12:18:47 2021 Epoch 3, lr: 0.1000000, 0.0010000, train loss: 0.2196, valid loss: 0.2188, mean_rce: 19.81, retweet: 24.78, reply: 20.21, like: 23.62, retweet_comment: 10.63\n",
      "rce_best increased (18.606373 --> 19.811167).  Saving model ...\n",
      "Thu Jun 10 12:26:01 2021 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:28<00:00, 77.66s/it]\n",
      "loss: 0.2101, smth: 0.2141: 100%|██████████| 14636/14636 [10:34<00:00, 23.08it/s]\n",
      "100%|██████████| 10083/10083 [02:06<00:00, 79.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 12:45:22 2021 Epoch 4, lr: 0.0995134, 0.0009951, train loss: 0.2162, valid loss: 0.2140, mean_rce: 21.43, retweet: 26.11, reply: 22.21, like: 25.37, retweet_comment: 12.02\n",
      "rce_best increased (19.811167 --> 21.429255).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 12:52:23 2021 Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:22<00:00, 76.41s/it]\n",
      "loss: 0.2123, smth: 0.2121: 100%|██████████| 14331/14331 [10:20<00:00, 23.09it/s]\n",
      "100%|██████████| 10083/10083 [02:06<00:00, 79.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 13:11:32 2021 Epoch 5, lr: 0.0989074, 0.0009891, train loss: 0.2136, valid loss: 0.2111, mean_rce: 22.45, retweet: 27.24, reply: 23.11, like: 26.42, retweet_comment: 13.04\n",
      "rce_best increased (21.429255 --> 22.453396).  Saving model ...\n",
      "Thu Jun 10 13:18:29 2021 Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:52<00:00, 70.58s/it]\n",
      "loss: 0.2047, smth: 0.2106: 100%|██████████| 12543/12543 [09:07<00:00, 22.89it/s]\n",
      "100%|██████████| 10083/10083 [02:04<00:00, 81.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 13:35:44 2021 Epoch 6, lr: 0.0980631, 0.0009806, train loss: 0.2115, valid loss: 0.2089, mean_rce: 23.20, retweet: 28.01, reply: 23.84, like: 27.16, retweet_comment: 13.80\n",
      "rce_best increased (22.453396 --> 23.202980).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 13:42:53 2021 Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:22<00:00, 76.57s/it]\n",
      "loss: 0.2038, smth: 0.2116: 100%|██████████| 13903/13903 [10:05<00:00, 22.94it/s]\n",
      "100%|██████████| 10083/10083 [02:07<00:00, 79.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 14:01:45 2021 Epoch 7, lr: 0.0969846, 0.0009698, train loss: 0.2100, valid loss: 0.2074, mean_rce: 23.75, retweet: 28.50, reply: 24.45, like: 27.71, retweet_comment: 14.34\n",
      "rce_best increased (23.202980 --> 23.750500).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 14:08:29 2021 Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:27<00:00, 77.45s/it]\n",
      "loss: 0.1998, smth: 0.2077: 100%|██████████| 14638/14638 [10:41<00:00, 22.84it/s]\n",
      "100%|██████████| 10083/10083 [02:07<00:00, 79.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 14:27:56 2021 Epoch 8, lr: 0.0956773, 0.0009568, train loss: 0.2086, valid loss: 0.2059, mean_rce: 24.26, retweet: 29.17, reply: 24.86, like: 28.21, retweet_comment: 14.80\n",
      "rce_best increased (23.750500 --> 24.257999).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 14:35:18 2021 Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:37<00:00, 79.52s/it]\n",
      "loss: 0.2072, smth: 0.2061: 100%|██████████| 14635/14635 [10:48<00:00, 22.56it/s]\n",
      "100%|██████████| 10083/10083 [02:05<00:00, 80.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 14:55:04 2021 Epoch 9, lr: 0.0941474, 0.0009415, train loss: 0.2074, valid loss: 0.2043, mean_rce: 24.85, retweet: 29.74, reply: 25.42, like: 28.74, retweet_comment: 15.50\n",
      "rce_best increased (24.257999 --> 24.851948).  Saving model ...\n",
      "Thu Jun 10 15:02:17 2021 Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:10<00:00, 74.20s/it]\n",
      "loss: 0.2023, smth: 0.2057: 100%|██████████| 13865/13865 [09:58<00:00, 23.18it/s]\n",
      "100%|██████████| 10083/10083 [02:07<00:00, 79.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 15:20:43 2021 Epoch 10, lr: 0.0924024, 0.0009240, train loss: 0.2063, valid loss: 0.2029, mean_rce: 25.29, retweet: 30.22, reply: 25.85, like: 29.26, retweet_comment: 15.83\n",
      "rce_best increased (24.851948 --> 25.290001).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 15:27:52 2021 Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:11<00:00, 74.20s/it]\n",
      "loss: 0.1890, smth: 0.2032: 100%|██████████| 13673/13673 [09:51<00:00, 23.11it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 15:46:12 2021 Epoch 11, lr: 0.0904508, 0.0009045, train loss: 0.2050, valid loss: 0.2020, mean_rce: 25.67, retweet: 30.61, reply: 26.30, like: 29.54, retweet_comment: 16.24\n",
      "rce_best increased (25.290001 --> 25.671610).  Saving model ...\n",
      "Thu Jun 10 15:53:32 2021 Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:25<00:00, 77.10s/it]\n",
      "loss: 0.2079, smth: 0.2037: 100%|██████████| 14359/14359 [10:28<00:00, 22.83it/s]\n",
      "100%|██████████| 10083/10083 [02:07<00:00, 79.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 16:12:55 2021 Epoch 12, lr: 0.0883022, 0.0008830, train loss: 0.2045, valid loss: 0.2006, mean_rce: 26.17, retweet: 31.14, reply: 26.93, like: 29.99, retweet_comment: 16.63\n",
      "rce_best increased (25.671610 --> 26.171452).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 16:19:59 2021 Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:15<00:00, 75.00s/it]\n",
      "loss: 0.1947, smth: 0.2033: 100%|██████████| 13714/13714 [10:00<00:00, 22.84it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 16:38:56 2021 Epoch 13, lr: 0.0859670, 0.0008597, train loss: 0.2036, valid loss: 0.1995, mean_rce: 26.53, retweet: 31.46, reply: 27.04, like: 30.43, retweet_comment: 17.18\n",
      "rce_best increased (26.171452 --> 26.527067).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 16:45:25 2021 Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:17<00:00, 75.40s/it]\n",
      "loss: 0.1864, smth: 0.2016: 100%|██████████| 14312/14312 [10:20<00:00, 23.05it/s]\n",
      "100%|██████████| 10083/10083 [02:07<00:00, 79.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 17:04:42 2021 Epoch 14, lr: 0.0834565, 0.0008346, train loss: 0.2029, valid loss: 0.1989, mean_rce: 26.83, retweet: 31.67, reply: 27.67, like: 30.58, retweet_comment: 17.40\n",
      "rce_best increased (26.527067 --> 26.829527).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 17:10:59 2021 Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:30<00:00, 78.05s/it]\n",
      "loss: 0.2114, smth: 0.2002: 100%|██████████| 14636/14636 [10:42<00:00, 22.77it/s]\n",
      "100%|██████████| 10083/10083 [02:10<00:00, 77.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 17:31:09 2021 Epoch 15, lr: 0.0807831, 0.0008078, train loss: 0.2021, valid loss: 0.1973, mean_rce: 27.27, retweet: 32.13, reply: 28.04, like: 31.26, retweet_comment: 17.66\n",
      "rce_best increased (26.829527 --> 27.269592).  Saving model ...\n",
      "Thu Jun 10 17:37:23 2021 Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:17<00:00, 75.46s/it]\n",
      "loss: 0.1965, smth: 0.2020: 100%|██████████| 14522/14522 [10:32<00:00, 22.95it/s]\n",
      "100%|██████████| 10083/10083 [02:09<00:00, 77.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 17:56:36 2021 Epoch 16, lr: 0.0779596, 0.0007796, train loss: 0.2015, valid loss: 0.1967, mean_rce: 27.50, retweet: 32.42, reply: 28.18, like: 31.41, retweet_comment: 17.98\n",
      "rce_best increased (27.269592 --> 27.497391).  Saving model ...\n",
      "Thu Jun 10 18:03:23 2021 Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:28<00:00, 77.73s/it]\n",
      "loss: 0.2037, smth: 0.2008: 100%|██████████| 14856/14856 [10:53<00:00, 22.72it/s]\n",
      "100%|██████████| 10083/10083 [02:06<00:00, 79.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 18:23:05 2021 Epoch 17, lr: 0.0750000, 0.0007500, train loss: 0.2008, valid loss: 0.1958, mean_rce: 27.82, retweet: 32.56, reply: 28.60, like: 31.77, retweet_comment: 18.35\n",
      "rce_best increased (27.497391 --> 27.820614).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 18:29:27 2021 Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:42<00:00, 80.41s/it]\n",
      "loss: 0.1868, smth: 0.1990: 100%|██████████| 14637/14637 [10:40<00:00, 22.84it/s]\n",
      "100%|██████████| 10083/10083 [02:09<00:00, 78.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 18:49:33 2021 Epoch 18, lr: 0.0719186, 0.0007192, train loss: 0.2002, valid loss: 0.1952, mean_rce: 28.15, retweet: 33.01, reply: 28.92, like: 31.87, retweet_comment: 18.80\n",
      "rce_best increased (27.820614 --> 28.147221).  Saving model ...\n",
      "Thu Jun 10 18:55:18 2021 Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:16<00:00, 75.24s/it]\n",
      "loss: 0.2204, smth: 0.1977: 100%|██████████| 13821/13821 [10:01<00:00, 22.98it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 19:14:19 2021 Epoch 19, lr: 0.0687303, 0.0006873, train loss: 0.1986, valid loss: 0.1937, mean_rce: 28.51, retweet: 33.26, reply: 29.15, like: 32.61, retweet_comment: 19.03\n",
      "rce_best increased (28.147221 --> 28.511463).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 19:19:49 2021 Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:17<00:00, 75.47s/it]\n",
      "loss: 0.2101, smth: 0.1990: 100%|██████████| 14182/14182 [10:16<00:00, 22.99it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 19:39:12 2021 Epoch 20, lr: 0.0654508, 0.0006545, train loss: 0.1992, valid loss: 0.1932, mean_rce: 28.68, retweet: 33.43, reply: 29.39, like: 32.76, retweet_comment: 19.16\n",
      "rce_best increased (28.511463 --> 28.684906).  Saving model ...\n",
      "Thu Jun 10 19:44:52 2021 Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:54<00:00, 82.92s/it]\n",
      "loss: 0.1962, smth: 0.2007: 100%|██████████| 14296/14296 [10:19<00:00, 23.07it/s]\n",
      "100%|██████████| 10083/10083 [02:07<00:00, 78.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 20:04:41 2021 Epoch 21, lr: 0.0620961, 0.0006210, train loss: 0.1987, valid loss: 0.1929, mean_rce: 28.83, retweet: 33.60, reply: 29.50, like: 32.80, retweet_comment: 19.43\n",
      "rce_best increased (28.684906 --> 28.832020).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 20:10:10 2021 Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:16<00:00, 75.31s/it]\n",
      "loss: 0.1888, smth: 0.1975: 100%|██████████| 13550/13550 [09:45<00:00, 23.15it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 20:28:49 2021 Epoch 22, lr: 0.0586824, 0.0005868, train loss: 0.1983, valid loss: 0.1921, mean_rce: 29.15, retweet: 33.91, reply: 29.92, like: 33.06, retweet_comment: 19.71\n",
      "rce_best increased (28.832020 --> 29.149475).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 20:34:29 2021 Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:47<00:00, 81.45s/it]\n",
      "loss: 0.1969, smth: 0.1982: 100%|██████████| 14635/14635 [10:36<00:00, 22.99it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 20:54:33 2021 Epoch 23, lr: 0.0552264, 0.0005523, train loss: 0.1978, valid loss: 0.1918, mean_rce: 29.28, retweet: 33.91, reply: 30.13, like: 33.16, retweet_comment: 19.90\n",
      "rce_best increased (29.149475 --> 29.275816).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 21:00:01 2021 Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [07:36<00:00, 91.33s/it]\n",
      "loss: 0.2044, smth: 0.1965: 100%|██████████| 14180/14180 [10:11<00:00, 23.19it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 21:20:24 2021 Epoch 24, lr: 0.0517450, 0.0005174, train loss: 0.1973, valid loss: 0.1910, mean_rce: 29.55, retweet: 34.42, reply: 30.37, like: 33.40, retweet_comment: 19.99\n",
      "rce_best increased (29.275816 --> 29.547853).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 21:25:54 2021 Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:07<00:00, 73.48s/it]\n",
      "loss: 0.2042, smth: 0.1971: 100%|██████████| 13862/13862 [10:02<00:00, 23.02it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 21:44:25 2021 Epoch 25, lr: 0.0482550, 0.0004826, train loss: 0.1970, valid loss: 0.1903, mean_rce: 29.74, retweet: 34.35, reply: 30.53, like: 33.77, retweet_comment: 20.31\n",
      "rce_best increased (29.547853 --> 29.740671).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 21:49:50 2021 Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:16<00:00, 75.26s/it]\n",
      "loss: 0.1845, smth: 0.1971: 100%|██████████| 14634/14634 [10:34<00:00, 23.05it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 22:09:03 2021 Epoch 26, lr: 0.0447736, 0.0004477, train loss: 0.1967, valid loss: 0.1898, mean_rce: 29.89, retweet: 34.62, reply: 30.50, like: 33.96, retweet_comment: 20.46\n",
      "rce_best increased (29.740671 --> 29.885460).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 22:14:37 2021 Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:26<00:00, 77.30s/it]\n",
      "loss: 0.1801, smth: 0.1958: 100%|██████████| 14671/14671 [10:32<00:00, 23.18it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 22:34:00 2021 Epoch 27, lr: 0.0413176, 0.0004132, train loss: 0.1963, valid loss: 0.1897, mean_rce: 29.98, retweet: 34.77, reply: 30.52, like: 33.96, retweet_comment: 20.69\n",
      "rce_best increased (29.885460 --> 29.984455).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 22:39:28 2021 Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:20<00:00, 76.02s/it]\n",
      "loss: 0.1929, smth: 0.1942: 100%|██████████| 14626/14626 [10:31<00:00, 23.16it/s]\n",
      "100%|██████████| 10083/10083 [02:09<00:00, 78.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 22:58:37 2021 Epoch 28, lr: 0.0379039, 0.0003790, train loss: 0.1958, valid loss: 0.1887, mean_rce: 30.30, retweet: 34.94, reply: 31.09, like: 34.35, retweet_comment: 20.82\n",
      "rce_best increased (29.984455 --> 30.300800).  Saving model ...\n",
      "Thu Jun 10 23:04:07 2021 Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:20<00:00, 76.04s/it]\n",
      "loss: 0.1886, smth: 0.1968: 100%|██████████| 14668/14668 [10:35<00:00, 23.09it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 23:23:19 2021 Epoch 29, lr: 0.0345492, 0.0003455, train loss: 0.1956, valid loss: 0.1885, mean_rce: 30.38, retweet: 35.05, reply: 31.12, like: 34.42, retweet_comment: 20.94\n",
      "rce_best increased (30.300800 --> 30.380356).  Saving model ...\n",
      "Thu Jun 10 23:28:48 2021 Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:19<00:00, 75.94s/it]\n",
      "loss: 0.1890, smth: 0.1957: 100%|██████████| 14645/14645 [10:36<00:00, 23.01it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 23:48:01 2021 Epoch 30, lr: 0.0312697, 0.0003127, train loss: 0.1953, valid loss: 0.1880, mean_rce: 30.55, retweet: 35.23, reply: 31.24, like: 34.61, retweet_comment: 21.12\n",
      "rce_best increased (30.380356 --> 30.551567).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 23:53:29 2021 Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:58<00:00, 71.76s/it]\n",
      "loss: 0.1879, smth: 0.1957: 100%|██████████| 13018/13018 [09:22<00:00, 23.14it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 00:11:06 2021 Epoch 31, lr: 0.0280814, 0.0002808, train loss: 0.1949, valid loss: 0.1877, mean_rce: 30.65, retweet: 35.29, reply: 31.31, like: 34.72, retweet_comment: 21.28\n",
      "rce_best increased (30.551567 --> 30.645824).  Saving model ...\n",
      "Fri Jun 11 00:16:34 2021 Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:26<00:00, 77.24s/it]\n",
      "loss: 0.1955, smth: 0.1931: 100%|██████████| 13865/13865 [09:58<00:00, 23.17it/s]\n",
      "100%|██████████| 10083/10083 [02:09<00:00, 78.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 00:35:22 2021 Epoch 32, lr: 0.0250000, 0.0002500, train loss: 0.1934, valid loss: 0.1869, mean_rce: 31.00, retweet: 35.65, reply: 31.86, like: 34.92, retweet_comment: 21.55\n",
      "rce_best increased (30.645824 --> 30.996300).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 00:40:50 2021 Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:49<00:00, 81.81s/it]\n",
      "loss: 0.1985, smth: 0.1948: 100%|██████████| 14470/14470 [10:22<00:00, 23.23it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 01:00:23 2021 Epoch 33, lr: 0.0220404, 0.0002204, train loss: 0.1944, valid loss: 0.1866, mean_rce: 31.01, retweet: 35.59, reply: 31.72, like: 35.13, retweet_comment: 21.61\n",
      "rce_best increased (30.996300 --> 31.011581).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 01:05:53 2021 Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:27<00:00, 77.46s/it]\n",
      "loss: 0.2125, smth: 0.1938: 100%|██████████| 14637/14637 [10:32<00:00, 23.15it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 01:25:09 2021 Epoch 34, lr: 0.0192169, 0.0001922, train loss: 0.1943, valid loss: 0.1864, mean_rce: 31.10, retweet: 35.71, reply: 31.83, like: 35.17, retweet_comment: 21.70\n",
      "rce_best increased (31.011581 --> 31.102623).  Saving model ...\n",
      "Fri Jun 11 01:30:37 2021 Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:21<00:00, 76.37s/it]\n",
      "loss: 0.1897, smth: 0.1944: 100%|██████████| 14635/14635 [10:32<00:00, 23.15it/s]\n",
      "100%|██████████| 10083/10083 [02:09<00:00, 77.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 01:49:49 2021 Epoch 35, lr: 0.0165435, 0.0001654, train loss: 0.1940, valid loss: 0.1865, mean_rce: 31.11, retweet: 35.75, reply: 31.76, like: 35.11, retweet_comment: 21.81\n",
      "rce_best increased (31.102623 --> 31.105156).  Saving model ...\n",
      "Fri Jun 11 01:55:12 2021 Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:05<00:00, 73.12s/it]\n",
      "loss: 0.1920, smth: 0.1931: 100%|██████████| 13586/13586 [09:46<00:00, 23.15it/s]\n",
      "100%|██████████| 10083/10083 [02:07<00:00, 78.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 02:13:26 2021 Epoch 36, lr: 0.0140330, 0.0001403, train loss: 0.1937, valid loss: 0.1862, mean_rce: 31.20, retweet: 35.84, reply: 31.88, like: 35.22, retweet_comment: 21.87\n",
      "rce_best increased (31.105156 --> 31.201717).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 02:18:52 2021 Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:50<00:00, 82.17s/it]\n",
      "loss: 0.1896, smth: 0.1930: 100%|██████████| 14526/14526 [10:34<00:00, 22.89it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 02:38:34 2021 Epoch 37, lr: 0.0116978, 0.0001170, train loss: 0.1936, valid loss: 0.1860, mean_rce: 31.26, retweet: 35.90, reply: 31.95, like: 35.27, retweet_comment: 21.92\n",
      "rce_best increased (31.201717 --> 31.259350).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 02:44:04 2021 Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:18<00:00, 75.74s/it]\n",
      "loss: 0.1923, smth: 0.1928: 100%|██████████| 14636/14636 [10:29<00:00, 23.27it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 03:03:12 2021 Epoch 38, lr: 0.0095492, 0.0000955, train loss: 0.1935, valid loss: 0.1856, mean_rce: 31.38, retweet: 35.94, reply: 32.10, like: 35.47, retweet_comment: 22.00\n",
      "rce_best increased (31.259350 --> 31.378683).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 03:08:45 2021 Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:18<00:00, 75.63s/it]\n",
      "loss: 0.1938, smth: 0.1924: 100%|██████████| 14637/14637 [10:30<00:00, 23.22it/s]\n",
      "100%|██████████| 10083/10083 [02:09<00:00, 78.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 03:27:51 2021 Epoch 39, lr: 0.0075976, 0.0000760, train loss: 0.1935, valid loss: 0.1857, mean_rce: 31.38, retweet: 35.98, reply: 32.07, like: 35.42, retweet_comment: 22.05\n",
      "rce_best increased (31.378683 --> 31.382784).  Saving model ...\n",
      "Fri Jun 11 03:33:14 2021 Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:06<00:00, 73.27s/it]\n",
      "loss: 0.1852, smth: 0.1908: 100%|██████████| 13508/13508 [09:43<00:00, 23.15it/s]\n",
      "100%|██████████| 10083/10083 [02:09<00:00, 77.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 03:51:22 2021 Epoch 40, lr: 0.0058526, 0.0000585, train loss: 0.1920, valid loss: 0.1848, mean_rce: 31.62, retweet: 36.11, reply: 32.34, like: 35.81, retweet_comment: 22.21\n",
      "rce_best increased (31.382784 --> 31.618502).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 03:56:46 2021 Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:49<00:00, 81.84s/it]\n",
      "loss: 0.1909, smth: 0.1929: 100%|██████████| 14637/14637 [10:30<00:00, 23.20it/s]\n",
      "100%|██████████| 10083/10083 [02:11<00:00, 76.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 04:16:30 2021 Epoch 41, lr: 0.0043227, 0.0000432, train loss: 0.1932, valid loss: 0.1852, mean_rce: 31.53, retweet: 36.09, reply: 32.25, like: 35.60, retweet_comment: 22.16\n",
      "Fri Jun 11 04:20:32 2021 Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:38<00:00, 79.70s/it]\n",
      "loss: 0.1925, smth: 0.1939: 100%|██████████| 14473/14473 [10:23<00:00, 23.21it/s]\n",
      "100%|██████████| 10083/10083 [02:07<00:00, 78.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 04:39:55 2021 Epoch 42, lr: 0.0030154, 0.0000302, train loss: 0.1931, valid loss: 0.1850, mean_rce: 31.59, retweet: 36.14, reply: 32.29, like: 35.72, retweet_comment: 22.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 04:44:03 2021 Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:50<00:00, 82.01s/it]\n",
      "loss: 0.1824, smth: 0.1912: 100%|██████████| 14187/14187 [10:08<00:00, 23.31it/s]\n",
      "100%|██████████| 10083/10083 [02:08<00:00, 78.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 05:03:23 2021 Epoch 43, lr: 0.0019369, 0.0000194, train loss: 0.1930, valid loss: 0.1851, mean_rce: 31.55, retweet: 36.08, reply: 32.24, like: 35.65, retweet_comment: 22.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 05:07:18 2021 Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [07:08<00:00, 85.72s/it]\n",
      "loss: 0.1821, smth: 0.1947: 100%|██████████| 14784/14784 [10:46<00:00, 22.86it/s]\n",
      "100%|██████████| 10083/10083 [02:09<00:00, 77.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 05:27:52 2021 Epoch 44, lr: 0.0010926, 0.0000109, train loss: 0.1930, valid loss: 0.1851, mean_rce: 31.58, retweet: 36.13, reply: 32.36, like: 35.66, retweet_comment: 22.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 05:31:57 2021 Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:53<00:00, 82.63s/it]\n",
      "loss: 0.1905, smth: 0.1939: 100%|██████████| 13823/13823 [09:59<00:00, 23.05it/s]\n",
      "100%|██████████| 10083/10083 [02:09<00:00, 77.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 05:51:34 2021 Epoch 45, lr: 0.0004866, 0.0000049, train loss: 0.1928, valid loss: 0.1851, mean_rce: 31.57, retweet: 36.12, reply: 32.31, like: 35.63, retweet_comment: 22.22\n",
      "Fri Jun 11 05:55:37 2021 Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:18<00:00, 75.67s/it]\n",
      "loss: 0.2006, smth: 0.1915: 100%|██████████| 14635/14635 [10:31<00:00, 23.16it/s]\n",
      "100%|██████████| 10083/10083 [02:07<00:00, 78.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 11 06:14:47 2021 Epoch 46, lr: 0.0001218, 0.0000012, train loss: 0.1929, valid loss: 0.1851, mean_rce: 31.59, retweet: 36.14, reply: 32.32, like: 35.65, retweet_comment: 22.22\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, ep+1):\n",
    "    print(time.ctime(), 'Epoch:', epoch)\n",
    "    scheduler_warmup.step(epoch-1) \n",
    "    scheduler_warmup2.step(epoch-1) \n",
    "    \n",
    "    # 5 parts per epoch\n",
    "    idx_this_ep = train_parts_order[(epoch*5-5):epoch*5]\n",
    "    \n",
    "    train_lst = []\n",
    "    for idx in tqdm(idx_this_ep):\n",
    "        train_lst.append(read_norm_merge(PATHS[idx], 'train' if idx<10 else 'both'))\n",
    "    train = pd.concat(train_lst)\n",
    " \n",
    "    gc.collect();gc.collect();\n",
    "    \n",
    "    train_dataset = AllDataset(train, max_len_txt, NUMERIC_COLUMNS, CAT_COLUMNS)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, drop_last=True) \n",
    "    \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, optimizer2)\n",
    "    valid_loss,rce,mean_rce = valid_epoch(model, valid_loader)\n",
    "   \n",
    "    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, {optimizer2.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.4f}, valid loss: {valid_loss:.4f}, mean_rce: {mean_rce:.2f}'\n",
    "    for col in ['retweet', 'reply',  'like', 'retweet_comment']:\n",
    "        content += f', {col}: {rce[col]:.2f}'\n",
    "        \n",
    "    print(content)\n",
    "    \n",
    "    if mean_rce > rce_best:\n",
    "        print('rce_best increased ({:.6f} --> {:.6f}).  Saving model ...'.format(rce_best, mean_rce))\n",
    "        rce_best = mean_rce\n",
    "                \n",
    "        torch.save(model.state_dict(), f'../models/{model_name}_best.pth')\n",
    "        \n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "            'optimizer_state_dict2': optimizer2.state_dict(),\n",
    "            'rce_best': rce_best,\n",
    "        },\n",
    "        f'../models/{model_name}_last.pth'\n",
    "    )            \n",
    "        \n",
    "torch.save(model.state_dict(), f'../models/{model_name}_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c9a3e-ee2d-404f-a51a-7f8e02220ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e79b7-63aa-47a3-a895-d8b8b2a5a8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cdd2029-03bf-4e13-8890-9864f99130f6",
   "metadata": {},
   "source": [
    "## load best ep and inference LB valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cafbbc62-fc67-41f4-a564-dc95afd0f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_norm_merge(ddf):\n",
    "\n",
    "    ddf['quantile'] = 0\n",
    "    quantiles = [ 240,  588, 1331, 3996]\n",
    "    for i, quant in enumerate(quantiles):\n",
    "        ddf['quantile'] = (ddf['quantile']+(ddf['a_follower_count']>quant).astype('int8')).astype('int8')\n",
    "\n",
    "    ddf['date'] = cudf.to_datetime(ddf['timestamp'], unit='s')\n",
    "       \n",
    "    ddf['a_ff_rate'] = (ddf['a_following_count'] / ddf['a_follower_count']).astype('float32')\n",
    "    ddf['b_ff_rate'] = (ddf['b_follower_count']  / ddf['b_following_count']).astype('float32')\n",
    "    ddf['ab_fing_rate'] = (ddf['a_following_count'] / ddf['b_following_count']).astype('float32')\n",
    "    ddf['ab_fer_rate'] = (ddf['a_follower_count'] / (1+ddf['b_follower_count'])).astype('float32')\n",
    "    ddf['a_age'] = ddf['a_account_creation'].astype('int16') + 128\n",
    "    ddf['b_age'] = ddf['b_account_creation'].astype('int16') + 128\n",
    "    ddf['ab_age_dff'] = ddf['b_age'] - ddf['a_age']\n",
    "    ddf['ab_age_rate'] = ddf['a_age']/(1+ddf['b_age'])\n",
    "\n",
    "    ## Normalize\n",
    "    for col in NUMERIC_COLUMNS:\n",
    "        if col == 'tw_len_quest':\n",
    "            ddf[col] = np.clip(ddf[col].values.get(),0,None)\n",
    "        if ddf[col].dtype == 'uint16':\n",
    "            ddf[col].astype('int32')\n",
    "\n",
    "        if col == 'ab_age_dff':\n",
    "            ddf[col] = ddf[col] / 256.            \n",
    "        elif 'int' in str(ddf[col].dtype) or 'float' in str(ddf[col].dtype):    \n",
    "            ddf[col] = np.log1p(ddf[col])\n",
    "\n",
    "        if ddf[col].dtype == 'float64':\n",
    "            ddf[col] = ddf[col].astype('float32') \n",
    "            \n",
    "    ddf['b_user_id_hash'] = ddf['b_user_id'].copy()\n",
    "\n",
    "    ## get categorical embedding id        \n",
    "    for col in CAT_COLUMNS:\n",
    "        ddf[col] = ddf[col].astype('float')\n",
    "        if col in ['a_user_id','b_user_id']:\n",
    "            mapping_col = 'a_user_id_b_user_id'\n",
    "        else:\n",
    "            mapping_col = col\n",
    "        mapping = cudf.read_parquet(f'/raid/recsys_pre_TE_w_tok/workflow_232parts_joint_thr3_pos/categories/unique.{mapping_col}.parquet').reset_index()\n",
    "        mapping.columns = ['index',col]\n",
    "        ddf = ddf.merge(mapping, how='left', on=col).drop(columns=[col]).rename(columns={'index':col})\n",
    "        ddf[col] = ddf[col].fillna(0).astype('int')        \n",
    "\n",
    "    label_names = ['reply', 'retweet', 'retweet_comment', 'like']\n",
    "    DONT_USE = ['timestamp','a_account_creation','b_account_creation','engage_time',\n",
    "                'fold', 'dt_dow', 'a_account_creation', \n",
    "                'b_account_creation', 'elapsed_time', 'links','domains','hashtags','id', 'date', 'is_train', \n",
    "                'tw_hash0', 'tw_hash1', 'tw_hash2', 'tw_http0', 'tw_uhash', 'tw_hash', 'tw_word0', \n",
    "                'tw_word1', 'tw_word2', 'tw_word3', 'tw_word4', 'dt_minute', 'dt_second',\n",
    "               'dt_day', 'group', 'text', 'tw_original_user0', 'tw_original_user1', 'tw_original_user2',\n",
    "                'tw_rt_user0', 'tw_original_http0', 'tw_tweet',]\n",
    "    DONT_USE = [c for c in ddf.columns if c in DONT_USE]\n",
    "    gc.collect(); gc.collect()\n",
    "    \n",
    "    return ddf.drop(columns=DONT_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8f8ec02-7db9-4873-9857-d7f0fa126166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.1 s, sys: 11.4 s, total: 28.5 s\n",
      "Wall time: 34.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14461760, 49)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = cudf.read_parquet('/raid/recsys_valid/valid_proc.parquet',num_rows=7_000_000)\n",
    "df = read_norm_merge(df).to_pandas()\n",
    "\n",
    "df2 = cudf.read_parquet('/raid/recsys_valid/valid_proc.parquet',skiprows=7_000_000)\n",
    "df2 = read_norm_merge(df2).to_pandas()\n",
    "\n",
    "valid = pd.concat([df,df2])\n",
    "del df,df2\n",
    "gc.collect()\n",
    "\n",
    "valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9911f51f-1f29-4e44-845c-c67a29cf27c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14123"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = AllDataset(valid, max_len_txt, NUMERIC_COLUMNS, CAT_COLUMNS)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers) \n",
    "\n",
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3abfd-eb67-4f31-800d-0b571e63b449",
   "metadata": {},
   "source": [
    "## make fp16 ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "176b976e-20ed-4d55-84eb-7535d90b55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd = torch.load(f'../models/{model_name}_best.pth')\n",
    "# sd['initial_cat_layer.embedding_layers.0.weight'] = sd['initial_cat_layer.embedding_layers.0.weight'].half()\n",
    "# torch.save(sd, f'../models/{model_name}_best_fp16.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b91ba191-faeb-49d4-8b93-43f580f3abc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 bo bo 9.8G Jun 11 03:52 ../models/load_thr3_pos_1e-2_1e-4_best.pth\n",
      "-rw-rw-r-- 1 bo bo 5.1G Jun 11 09:35 ../models/load_thr3_pos_1e-2_1e-4_best_fp16.pth\n"
     ]
    }
   ],
   "source": [
    "!ls -lrth ../models/{model_name}_best*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7127c693-f9a9-45b5-b27c-c6c285e7ddc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = torch.load(f'../models/{model_name}_best_fp16.pth')\n",
    "# sd = torch.load('/home/bo/kaggle/recsys/recsysChallenge2021/bo/sub/v11_len48_thr25_joint_MF/MF_len48_joint_thr25_3weeks_best.pth')\n",
    "sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "model.load_state_dict(sd, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9e24177-e874-40e7-be56-b1625c5bca25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like', 'reply', 'retweet', 'retweet_comment']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = sorted(label_names)\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0f486b1-44b8-4925-8437-8c6671791c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14123/14123 [02:48<00:00, 83.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.035736"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "val_loss = []\n",
    "LOGITS = []\n",
    "TARGETS = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(valid_loader):\n",
    "        x_cat, x_cont, text_tok, targets = batch\n",
    "        x_cat = x_cat.cuda()     \n",
    "        x_cont = x_cont.cuda()\n",
    "        text_tok = text_tok.cuda()\n",
    "        targets = targets.cuda()            \n",
    "        logits = model(x_cat, x_cont, text_tok)\n",
    "        loss = criterion(logits, targets)\n",
    "        val_loss.append(loss.item())\n",
    "        LOGITS.append(logits.cpu())\n",
    "        TARGETS.append(targets.cpu())\n",
    "\n",
    "LOGITS = torch.cat(LOGITS)\n",
    "TARGETS = torch.cat(TARGETS)\n",
    "rce = {}\n",
    "for i in range(4):\n",
    "    rce[label_names[i]] = compute_rce_fast(cp.asarray(LOGITS[:,i].sigmoid()),cp.asarray(TARGETS[:,i])).get()            \n",
    "mean_rce = np.mean([v for k,v in rce.items()])\n",
    "mean_rce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74bbe2a4-4de3-495c-9ce1-4613ab6ad1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_quantile = pd.concat([pd.read_parquet(path)[['quantile']] for path in VALID_PATHS]).reset_index(drop=True)\n",
    "# df_quantile = df_quantile.apply(np.expm1).round().astype(int)\n",
    "df_quantile = valid[['quantile']].copy().reset_index(drop=True)\n",
    "df_quantile.shape\n",
    "\n",
    "yquantile = cupy.asarray(df_quantile.values)\n",
    "oof = cupy.asarray(LOGITS.sigmoid())\n",
    "yvalid = cupy.asarray(TARGETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0519fb1d-1494-4a0e-b9cd-e7e4ffada418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import compute_prauc, average_precision_score,display_score\n",
    "\n",
    "rce_output = {}\n",
    "ap_output = {}\n",
    "for i in range(4):\n",
    "    prauc_out = []\n",
    "    rce_out = []\n",
    "    ap_out = []\n",
    "    for j in range(5):\n",
    "        this_quantile_idx = (df_quantile == j)['quantile'].values\n",
    "        yvalid_tmp = yvalid[this_quantile_idx][:, i]\n",
    "        oof_tmp = oof[this_quantile_idx][:, i]\n",
    "        prauc = compute_prauc(oof_tmp, yvalid_tmp)\n",
    "        rce   = compute_rce_fast(oof_tmp, yvalid_tmp).item()\n",
    "        ap    = average_precision_score(cupy.asnumpy(yvalid_tmp),cupy.asnumpy(oof_tmp))\n",
    "        prauc_out.append(prauc)\n",
    "        rce_out.append(rce)\n",
    "        ap_out.append(ap)\n",
    "    rce_output[label_names[i]] = rce_out\n",
    "    ap_output[label_names[i]] = ap_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb1c6b89-3bd9-4bd6-b3ec-2c141a8b0414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_thr3_pos_1e-2_1e-4\n",
      "Quantile Group|AP Retweet|RCE Retweet|  AP Reply|  RCE Reply|   AP Like|   RCE Like|AP RT comment|RCE RT comment\n",
      "        0          0.3656     18.9687     0.1869     17.8583     0.5934      5.3910     0.0427      9.5393\n",
      "        1          0.3521     19.3371     0.1945     19.0993     0.5752      4.7853     0.0391      9.6176\n",
      "        2          0.3492     19.6940     0.2157     20.3177     0.5668      5.4737     0.0376      9.7294\n",
      "        3          0.3658     20.4278     0.2408     22.2145     0.5809      7.3677     0.0415     10.8575\n",
      "        4          0.3518     20.7003     0.1502     17.2623     0.6484     10.4704     0.0409     11.5956\n",
      "     Average       0.3569     19.8256     0.1976     19.3504     0.5929      6.6976     0.0404     10.2679\n"
     ]
    }
   ],
   "source": [
    "# public test Epoch 40, fp16\n",
    "print(model_name)\n",
    "display_score(rce_output, ap_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e84b741-2cd5-414e-988f-4129ce2cb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGITS = LOGITS.sigmoid().numpy()\n",
    "\n",
    "for i,label in enumerate(label_names):\n",
    "    valid[label] = LOGITS[:,i]\n",
    "\n",
    "valid[['tweet_id', \n",
    "    'b_user_id_hash', \n",
    "    'reply', \n",
    "    'retweet', \n",
    "    'retweet_comment', \n",
    "    'like']].to_csv(f'../results_{model_name}.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de64204d-48cc-4c4e-ad1b-496f2a811832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_opt_lr3_load_len48_joint_thr10_3e-3_1e-4\n",
      "Quantile Group|AP Retweet|RCE Retweet|  AP Reply|  RCE Reply|   AP Like|   RCE Like|AP RT comment|RCE RT comment\n",
      "        0          0.3667     19.4164     0.1833     18.0032     0.5944      7.9084     0.0368      8.7007\n",
      "        1          0.3531     19.3318     0.1900     18.8197     0.5731      6.3514     0.0338      8.8032\n",
      "        2          0.3493     19.4528     0.2107     19.9319     0.5639      6.5367     0.0329      8.7347\n",
      "        3          0.3646     19.9658     0.2337     21.5662     0.5770      8.0349     0.0360      9.5802\n",
      "        4          0.3461     19.8541     0.1425     16.2127     0.6488     11.7476     0.0364     10.5095\n",
      "     Average       0.3560     19.6042     0.1920     18.9068     0.5915      8.1158     0.0352      9.2656\n"
     ]
    }
   ],
   "source": [
    "# public test Epoch 40\n",
    "print(model_name)\n",
    "display_score(rce_output, ap_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e9b6dc2-574d-4515-971c-b3baab9049c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_opt_lr3_load_len48_joint_thr10_3e-3_1e-4\n",
      "Quantile Group|AP Retweet|RCE Retweet|  AP Reply|  RCE Reply|   AP Like|   RCE Like|AP RT comment|RCE RT comment\n",
      "        0          0.3640     19.2808     0.1825     17.8791     0.5927      7.8090     0.0359      8.4515\n",
      "        1          0.3496     19.1279     0.1884     18.6515     0.5710      6.2476     0.0325      8.5330\n",
      "        2          0.3451     19.1840     0.2076     19.7104     0.5618      6.4109     0.0317      8.5464\n",
      "        3          0.3604     19.6577     0.2296     21.2601     0.5752      7.9033     0.0349      9.3634\n",
      "        4          0.3413     19.6354     0.1397     15.7311     0.6472     11.7349     0.0351     10.2205\n",
      "     Average       0.3521     19.3772     0.1896     18.6465     0.5896      8.0211     0.0340      9.0230\n"
     ]
    }
   ],
   "source": [
    "# public test Epoch 32\n",
    "print(model_name)\n",
    "display_score(rce_output, ap_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bac626ca-b651-4b4b-a04d-171cd368df6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.06779999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19.3772     +     18.6465     +     8.0211     +    9.0230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d61f9-ee45-4aa8-8588-e07f3c63dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChrisDeotte\tversion_32\t0.3384\t18.6481\t0.1857\t18.5767\t0.6244\t13.2391\t0.0339\t9.1282\t3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2983723-86b8-4587-a649-b0c368607764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.5921"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18.6481\t+\t18.5767\t+\t13.2391\t+\t9.1282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07834482-7b47-4ef3-b847-eb5b52d927ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF_len48_joint_thr25_3weeks\n",
      "Quantile Group|AP Retweet|RCE Retweet|  AP Reply|  RCE Reply|   AP Like|   RCE Like|AP RT comment|RCE RT comment\n",
      "        0          0.3648     19.1185     0.1768     17.4406     0.5983      8.8159     0.0343      8.4536\n",
      "        1          0.3457     18.4016     0.1811     17.8598     0.5753      6.9555     0.0309      8.3305\n",
      "        2          0.3388     17.9507     0.2000     18.7393     0.5646      6.6237     0.0306      8.0775\n",
      "        3          0.3504     17.6180     0.2199     19.9633     0.5772      7.1854     0.0310      8.4171\n",
      "        4          0.3247     16.5028     0.1267     14.6986     0.6501     10.9945     0.0286      8.7294\n",
      "     Average       0.3449     17.9183     0.1809     17.7403     0.5931      8.1150     0.0311      8.4016\n"
     ]
    }
   ],
   "source": [
    "# public test\n",
    "print(model_name)\n",
    "display_score(rce_output, ap_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
