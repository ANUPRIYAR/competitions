{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA CORPORATION\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.0\n",
      "xgb 1.3.3\n",
      "rm: cannot remove 'dask-worker-space': No such file or directory\n",
      "XGB Version 1.3.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import gc\n",
    "import glob\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import os, time\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import cudf, cupy, time, rmm\n",
    "print( cudf.__version__ )\n",
    "\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.utils import parse_bytes\n",
    "import cudf\n",
    "import dask_cudf\n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "import cupy as cp          # CuPy is an implementation of NumPy-compatible multi-dimensional array on GPU\n",
    "import cudf                # cuDF is an implementation of Pandas-like Dataframe on GPU\n",
    "import rmm                 # library for pre-allocating memory on GPU\n",
    "import dask                # dask is an open-source library to nateively scale Python on multiple workers/nodes\n",
    "import dask_cudf           # dask_cudf uses dask to scale cuDF dataframes on multiple workers/nodes\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import xgboost as xgb\n",
    "print( 'xgb', xgb.__version__ )\n",
    "\n",
    "# More dask / dask_cluster related libraries to scale NVTabular\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import wait\n",
    "from dask.utils import parse_bytes\n",
    "from dask.delayed import delayed\n",
    "\n",
    "# NVTabular is the core library, we will use here for feature engineering/preprocessing on GPU\n",
    "#import nvtabular as nvt\n",
    "#from nvtabular.utils import device_mem_size\n",
    "!rm -r dask-worker-space\n",
    "\n",
    "import xgboost as xgb\n",
    "print('XGB Version',xgb.__version__)\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def compute_rce_fast(pred, gt):\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "    yt = np.mean(gt)     \n",
    "    strawman_cross_entropy = -(yt*np.log(yt) + (1 - yt)*np.log(1 - yt))\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_int32(df, feats=[]):\n",
    "    for f in feats:\n",
    "        df[f] = df[f].astype(np.int32)\n",
    "    gc.collect()\n",
    "    \n",
    "def convert_int16(df, feats=[]):\n",
    "    for f in feats:\n",
    "        df[f] = df[f].astype(np.int16)\n",
    "    gc.collect()\n",
    "    \n",
    "def convert_int8(df, feats=[]):\n",
    "    for f in feats:\n",
    "        df[f] = df[f].astype(np.int8)        \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253,\n",
       " ['week3-valid/part.44.parquet',\n",
       "  'week3-valid/part.233.parquet',\n",
       "  'week3-valid/part.119.parquet',\n",
       "  'week3-valid/part.176.parquet',\n",
       "  'week3-valid/part.198.parquet',\n",
       "  'week3-valid/part.159.parquet',\n",
       "  'week3-valid/part.60.parquet',\n",
       "  'week3-valid/part.219.parquet',\n",
       "  'week3-valid/part.69.parquet',\n",
       "  'week3-valid/part.224.parquet',\n",
       "  'week3-valid/part.20.parquet',\n",
       "  'week3-valid/part.118.parquet',\n",
       "  'week3-valid/part.154.parquet',\n",
       "  'week3-valid/part.6.parquet',\n",
       "  'week3-valid/part.54.parquet',\n",
       "  'week3-valid/part.169.parquet',\n",
       "  'week3-valid/part.65.parquet',\n",
       "  'week3-valid/part.151.parquet',\n",
       "  'week3-valid/part.79.parquet',\n",
       "  'week3-valid/part.37.parquet',\n",
       "  'week3-valid/part.197.parquet',\n",
       "  'week3-valid/part.172.parquet',\n",
       "  'week3-valid/part.41.parquet',\n",
       "  'week3-valid/part.81.parquet',\n",
       "  'week3-valid/part.155.parquet',\n",
       "  'week3-valid/part.62.parquet',\n",
       "  'week3-valid/part.82.parquet',\n",
       "  'week3-valid/part.134.parquet',\n",
       "  'week3-valid/part.143.parquet',\n",
       "  'week3-valid/part.161.parquet',\n",
       "  'week3-valid/part.236.parquet',\n",
       "  'week3-valid/part.89.parquet',\n",
       "  'week3-valid/part.76.parquet',\n",
       "  'week3-valid/part.235.parquet',\n",
       "  'week3-valid/part.193.parquet',\n",
       "  'week3-valid/part.216.parquet',\n",
       "  'week3-valid/part.184.parquet',\n",
       "  'week3-valid/part.43.parquet',\n",
       "  'week3-valid/part.249.parquet',\n",
       "  'week3-valid/part.128.parquet',\n",
       "  'week3-valid/part.244.parquet',\n",
       "  'week3-valid/part.187.parquet',\n",
       "  'week3-valid/part.47.parquet',\n",
       "  'week3-valid/part.192.parquet',\n",
       "  'week3-valid/part.204.parquet',\n",
       "  'week3-valid/part.109.parquet',\n",
       "  'week3-valid/part.252.parquet',\n",
       "  'week3-valid/part.58.parquet',\n",
       "  'week3-valid/part.245.parquet',\n",
       "  'week3-valid/part.167.parquet',\n",
       "  'week3-valid/part.135.parquet',\n",
       "  'week3-valid/part.88.parquet',\n",
       "  'week3-valid/part.77.parquet',\n",
       "  'week3-valid/part.106.parquet',\n",
       "  'week3-valid/part.218.parquet',\n",
       "  'week3-valid/part.32.parquet',\n",
       "  'week3-valid/part.201.parquet',\n",
       "  'week3-valid/part.36.parquet',\n",
       "  'week3-valid/part.56.parquet',\n",
       "  'week3-valid/part.49.parquet',\n",
       "  'week3-valid/part.162.parquet',\n",
       "  'week3-valid/part.243.parquet',\n",
       "  'week3-valid/part.39.parquet',\n",
       "  'week3-valid/part.142.parquet',\n",
       "  'week3-valid/part.141.parquet',\n",
       "  'week3-valid/part.248.parquet',\n",
       "  'week3-valid/part.110.parquet',\n",
       "  'week3-valid/part.24.parquet',\n",
       "  'week3-valid/part.53.parquet',\n",
       "  'week3-valid/part.75.parquet',\n",
       "  'week3-valid/part.97.parquet',\n",
       "  'week3-valid/part.206.parquet',\n",
       "  'week3-valid/part.205.parquet',\n",
       "  'week3-valid/part.104.parquet',\n",
       "  'week3-valid/part.50.parquet',\n",
       "  'week3-valid/part.123.parquet',\n",
       "  'week3-valid/part.67.parquet',\n",
       "  'week3-valid/part.107.parquet',\n",
       "  'week3-valid/part.238.parquet',\n",
       "  'week3-valid/part.15.parquet',\n",
       "  'week3-valid/part.229.parquet',\n",
       "  'week3-valid/part.116.parquet',\n",
       "  'week3-valid/part.74.parquet',\n",
       "  'week3-valid/part.42.parquet',\n",
       "  'week3-valid/part.0.parquet',\n",
       "  'week3-valid/part.145.parquet',\n",
       "  'week3-valid/part.212.parquet',\n",
       "  'week3-valid/part.130.parquet',\n",
       "  'week3-valid/part.108.parquet',\n",
       "  'week3-valid/part.7.parquet',\n",
       "  'week3-valid/part.23.parquet',\n",
       "  'week3-valid/part.189.parquet',\n",
       "  'week3-valid/part.99.parquet',\n",
       "  'week3-valid/part.64.parquet',\n",
       "  'week3-valid/part.178.parquet',\n",
       "  'week3-valid/part.144.parquet',\n",
       "  'week3-valid/part.177.parquet',\n",
       "  'week3-valid/part.209.parquet',\n",
       "  'week3-valid/part.33.parquet',\n",
       "  'week3-valid/part.92.parquet',\n",
       "  'week3-valid/part.195.parquet',\n",
       "  'week3-valid/part.188.parquet',\n",
       "  'week3-valid/part.84.parquet',\n",
       "  'week3-valid/part.78.parquet',\n",
       "  'week3-valid/part.200.parquet',\n",
       "  'week3-valid/part.9.parquet',\n",
       "  'week3-valid/part.246.parquet',\n",
       "  'week3-valid/part.21.parquet',\n",
       "  'week3-valid/part.150.parquet',\n",
       "  'week3-valid/part.86.parquet',\n",
       "  'week3-valid/part.113.parquet',\n",
       "  'week3-valid/part.140.parquet',\n",
       "  'week3-valid/part.66.parquet',\n",
       "  'week3-valid/part.228.parquet',\n",
       "  'week3-valid/part.105.parquet',\n",
       "  'week3-valid/part.72.parquet',\n",
       "  'week3-valid/part.137.parquet',\n",
       "  'week3-valid/part.55.parquet',\n",
       "  'week3-valid/part.34.parquet',\n",
       "  'week3-valid/part.182.parquet',\n",
       "  'week3-valid/part.83.parquet',\n",
       "  'week3-valid/part.51.parquet',\n",
       "  'week3-valid/part.181.parquet',\n",
       "  'week3-valid/part.240.parquet',\n",
       "  'week3-valid/part.239.parquet',\n",
       "  'week3-valid/part.101.parquet',\n",
       "  'week3-valid/part.241.parquet',\n",
       "  'week3-valid/part.202.parquet',\n",
       "  'week3-valid/part.226.parquet',\n",
       "  'week3-valid/part.1.parquet',\n",
       "  'week3-valid/part.38.parquet',\n",
       "  'week3-valid/part.232.parquet',\n",
       "  'week3-valid/part.14.parquet',\n",
       "  'week3-valid/part.30.parquet',\n",
       "  'week3-valid/part.230.parquet',\n",
       "  'week3-valid/part.129.parquet',\n",
       "  'week3-valid/part.125.parquet',\n",
       "  'week3-valid/part.115.parquet',\n",
       "  'week3-valid/part.16.parquet',\n",
       "  'week3-valid/part.4.parquet',\n",
       "  'week3-valid/part.227.parquet',\n",
       "  'week3-valid/part.80.parquet',\n",
       "  'week3-valid/part.250.parquet',\n",
       "  'week3-valid/part.111.parquet',\n",
       "  'week3-valid/part.31.parquet',\n",
       "  'week3-valid/part.94.parquet',\n",
       "  'week3-valid/part.17.parquet',\n",
       "  'week3-valid/part.103.parquet',\n",
       "  'week3-valid/part.11.parquet',\n",
       "  'week3-valid/part.26.parquet',\n",
       "  'week3-valid/part.179.parquet',\n",
       "  'week3-valid/part.171.parquet',\n",
       "  'week3-valid/part.147.parquet',\n",
       "  'week3-valid/part.163.parquet',\n",
       "  'week3-valid/part.131.parquet',\n",
       "  'week3-valid/part.175.parquet',\n",
       "  'week3-valid/part.213.parquet',\n",
       "  'week3-valid/part.220.parquet',\n",
       "  'week3-valid/part.136.parquet',\n",
       "  'week3-valid/part.61.parquet',\n",
       "  'week3-valid/part.117.parquet',\n",
       "  'week3-valid/part.45.parquet',\n",
       "  'week3-valid/part.85.parquet',\n",
       "  'week3-valid/part.196.parquet',\n",
       "  'week3-valid/part.13.parquet',\n",
       "  'week3-valid/part.211.parquet',\n",
       "  'week3-valid/part.114.parquet',\n",
       "  'week3-valid/part.3.parquet',\n",
       "  'week3-valid/part.194.parquet',\n",
       "  'week3-valid/part.133.parquet',\n",
       "  'week3-valid/part.22.parquet',\n",
       "  'week3-valid/part.68.parquet',\n",
       "  'week3-valid/part.126.parquet',\n",
       "  'week3-valid/part.91.parquet',\n",
       "  'week3-valid/part.40.parquet',\n",
       "  'week3-valid/part.208.parquet',\n",
       "  'week3-valid/part.199.parquet',\n",
       "  'week3-valid/part.70.parquet',\n",
       "  'week3-valid/part.152.parquet',\n",
       "  'week3-valid/part.63.parquet',\n",
       "  'week3-valid/part.8.parquet',\n",
       "  'week3-valid/part.148.parquet',\n",
       "  'week3-valid/part.18.parquet',\n",
       "  'week3-valid/part.164.parquet',\n",
       "  'week3-valid/part.247.parquet',\n",
       "  'week3-valid/part.29.parquet',\n",
       "  'week3-valid/part.166.parquet',\n",
       "  'week3-valid/part.25.parquet',\n",
       "  'week3-valid/part.165.parquet',\n",
       "  'week3-valid/part.190.parquet',\n",
       "  'week3-valid/part.210.parquet',\n",
       "  'week3-valid/part.71.parquet',\n",
       "  'week3-valid/part.242.parquet',\n",
       "  'week3-valid/part.225.parquet',\n",
       "  'week3-valid/part.139.parquet',\n",
       "  'week3-valid/part.231.parquet',\n",
       "  'week3-valid/part.87.parquet',\n",
       "  'week3-valid/part.183.parquet',\n",
       "  'week3-valid/part.237.parquet',\n",
       "  'week3-valid/part.112.parquet',\n",
       "  'week3-valid/part.173.parquet',\n",
       "  'week3-valid/part.217.parquet',\n",
       "  'week3-valid/part.251.parquet',\n",
       "  'week3-valid/part.46.parquet',\n",
       "  'week3-valid/part.214.parquet',\n",
       "  'week3-valid/part.52.parquet',\n",
       "  'week3-valid/part.73.parquet',\n",
       "  'week3-valid/part.149.parquet',\n",
       "  'week3-valid/part.59.parquet',\n",
       "  'week3-valid/part.168.parquet',\n",
       "  'week3-valid/part.48.parquet',\n",
       "  'week3-valid/part.35.parquet',\n",
       "  'week3-valid/part.121.parquet',\n",
       "  'week3-valid/part.157.parquet',\n",
       "  'week3-valid/part.2.parquet',\n",
       "  'week3-valid/part.98.parquet',\n",
       "  'week3-valid/part.10.parquet',\n",
       "  'week3-valid/part.93.parquet',\n",
       "  'week3-valid/part.170.parquet',\n",
       "  'week3-valid/part.138.parquet',\n",
       "  'week3-valid/part.203.parquet',\n",
       "  'week3-valid/part.28.parquet',\n",
       "  'week3-valid/part.120.parquet',\n",
       "  'week3-valid/part.207.parquet',\n",
       "  'week3-valid/part.180.parquet',\n",
       "  'week3-valid/part.156.parquet',\n",
       "  'week3-valid/part.146.parquet',\n",
       "  'week3-valid/part.96.parquet',\n",
       "  'week3-valid/part.185.parquet',\n",
       "  'week3-valid/part.222.parquet',\n",
       "  'week3-valid/part.27.parquet',\n",
       "  'week3-valid/part.186.parquet',\n",
       "  'week3-valid/part.19.parquet',\n",
       "  'week3-valid/part.234.parquet',\n",
       "  'week3-valid/part.100.parquet',\n",
       "  'week3-valid/part.102.parquet',\n",
       "  'week3-valid/part.90.parquet',\n",
       "  'week3-valid/part.122.parquet',\n",
       "  'week3-valid/part.5.parquet',\n",
       "  'week3-valid/part.127.parquet',\n",
       "  'week3-valid/part.223.parquet',\n",
       "  'week3-valid/part.124.parquet',\n",
       "  'week3-valid/part.158.parquet',\n",
       "  'week3-valid/part.95.parquet',\n",
       "  'week3-valid/part.153.parquet',\n",
       "  'week3-valid/part.132.parquet',\n",
       "  'week3-valid/part.160.parquet',\n",
       "  'week3-valid/part.191.parquet',\n",
       "  'week3-valid/part.221.parquet',\n",
       "  'week3-valid/part.174.parquet',\n",
       "  'week3-valid/part.57.parquet',\n",
       "  'week3-valid/part.215.parquet',\n",
       "  'week3-valid/part.12.parquet'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfiles = glob.glob('week3-valid/*.parquet' )\n",
    "len(trainfiles), trainfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hashtags', 'tweet_id', 'media', 'links', 'domains', 'tweet_type',\n",
       "       'language', 'timestamp', 'a_user_id', 'a_follower_count',\n",
       "       'a_following_count', 'a_is_verified', 'a_account_creation', 'b_user_id',\n",
       "       'b_follower_count', 'b_following_count', 'b_is_verified',\n",
       "       'b_account_creation', 'b_follows_a', 'reply', 'retweet',\n",
       "       'retweet_comment', 'like', 'tw_len_token', 'tw_len_media',\n",
       "       'tw_len_photo', 'tw_len_video', 'tw_len_gif', 'tw_len_quest',\n",
       "       'tw_count_capital_words', 'tw_count_excl_quest_marks',\n",
       "       'tw_count_special1', 'tw_count_hash', 'tw_last_quest', 'tw_len_retweet',\n",
       "       'tw_len_rt', 'tw_count_at', 'tw_count_words', 'tw_count_char',\n",
       "       'tw_rt_count_words', 'tw_rt_count_char', 'tw_original_user0',\n",
       "       'tw_original_user1', 'tw_original_user2', 'tw_rt_user0', 'tw_word0',\n",
       "       'tw_word1', 'tw_tweet', 'group', 'dt_day', 'dt_dow', 'dt_minute',\n",
       "       'len_hashtags', 'len_links', 'len_domains', 'decline'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(trainfiles[0]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 s, sys: 24.3 s, total: 59.8 s\n",
      "Wall time: 47.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(47815171, 56)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train = pd.concat([pd.read_parquet(fn) for fn in trainfiles]).reset_index(drop=True)\n",
    "train['decline'] = train['decline']//7.19\n",
    "train['a_follower_count'] = train['a_follower_count'] // 819\n",
    "train['a_following_count'] = train['a_following_count'] // 712\n",
    "train['b_follower_count'] = train['b_follower_count'] // 819\n",
    "train['b_following_count'] = train['b_following_count'] // 712\n",
    "gc.collect()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hashtags', 'tweet_id', 'media', 'links', 'domains', 'tweet_type',\n",
       "       'language', 'timestamp', 'a_user_id', 'a_follower_count',\n",
       "       'a_following_count', 'a_is_verified', 'a_account_creation', 'b_user_id',\n",
       "       'b_follower_count', 'b_following_count', 'b_is_verified',\n",
       "       'b_account_creation', 'b_follows_a', 'reply', 'retweet',\n",
       "       'retweet_comment', 'like', 'tw_len_token', 'tw_len_media',\n",
       "       'tw_len_photo', 'tw_len_video', 'tw_len_gif', 'tw_len_quest',\n",
       "       'tw_count_capital_words', 'tw_count_excl_quest_marks',\n",
       "       'tw_count_special1', 'tw_count_hash', 'tw_last_quest', 'tw_len_retweet',\n",
       "       'tw_len_rt', 'tw_count_at', 'tw_count_words', 'tw_count_char',\n",
       "       'tw_rt_count_words', 'tw_rt_count_char', 'tw_original_user0',\n",
       "       'tw_original_user1', 'tw_original_user2', 'tw_rt_user0', 'tw_word0',\n",
       "       'tw_word1', 'tw_tweet', 'group', 'dt_day', 'dt_dow', 'dt_minute',\n",
       "       'len_hashtags', 'len_links', 'len_domains', 'decline'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47815171, 61)\n",
      "(47815171, 66)\n",
      "(47815171, 71)\n",
      "(47815171, 76)\n",
      "(47815171, 81)\n",
      "(47815171, 86)\n",
      "(47815171, 91)\n",
      "(47815171, 96)\n",
      "(47815171, 101)\n",
      "CPU times: user 3min 41s, sys: 45.9 s, total: 4min 27s\n",
      "Wall time: 4min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/a_user_id-tweet_type.parquet')\n",
    "features = list(dt.index.names)\n",
    "train = train.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(train.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/b_user_id-tweet_type.parquet')\n",
    "features = list(dt.index.names)\n",
    "train = train.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(train.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/media-language-tweet_type-a_is_verified-b_is_verified-b_follows_a-tw_last_quest-decline-group.parquet')\n",
    "features = list(dt.index.names)\n",
    "train = train.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(train.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/tw_original_user0-tweet_type.parquet')\n",
    "features = list(dt.index.names)\n",
    "train = train.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(train.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/tw_original_user1-tweet_type.parquet')\n",
    "features = list(dt.index.names)\n",
    "train = train.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(train.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/tw_word0-tweet_type.parquet')\n",
    "features = list(dt.index.names)\n",
    "train = train.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(train.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/tw_rt_user0.parquet')\n",
    "features = list(dt.index.names)\n",
    "train = train.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(train.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/a_follower_count-a_following_count-b_follower_count-b_following_count-tweet_type-language-b_follows_a.parquet')\n",
    "features = list(dt.index.names)\n",
    "train = train.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(train.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/b_user_id.parquet')\n",
    "features = list(dt.index.names)\n",
    "train = train.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 s, sys: 7.69 s, total: 26.7 s\n",
      "Wall time: 22.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14461760, 61)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid = pd.read_parquet('/raid/kaggle/2021/recsys/input/validation.parquet')\n",
    "valid['decline'] = valid['decline']//7.19\n",
    "valid['a_follower_count'] = valid['a_follower_count'] // 819\n",
    "valid['a_following_count'] = valid['a_following_count'] // 712\n",
    "valid['b_follower_count'] = valid['b_follower_count'] // 819\n",
    "valid['b_following_count'] = valid['b_following_count'] // 712\n",
    "gc.collect()\n",
    "valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14461760, 66)\n",
      "(14461760, 71)\n",
      "(14461760, 76)\n",
      "(14461760, 81)\n",
      "(14461760, 86)\n",
      "(14461760, 91)\n",
      "(14461760, 96)\n",
      "(14461760, 101)\n",
      "(14461760, 106)\n",
      "CPU times: user 2min 18s, sys: 29.7 s, total: 2min 48s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/a_user_id-tweet_type.parquet')\n",
    "features = list(dt.index.names)\n",
    "valid = valid.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(valid.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/b_user_id-tweet_type.parquet')\n",
    "features = list(dt.index.names)\n",
    "valid = valid.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(valid.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/media-language-tweet_type-a_is_verified-b_is_verified-b_follows_a-tw_last_quest-decline-group.parquet')\n",
    "features = list(dt.index.names)\n",
    "valid = valid.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(valid.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/tw_original_user0-tweet_type.parquet')\n",
    "features = list(dt.index.names)\n",
    "valid = valid.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(valid.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/tw_original_user1-tweet_type.parquet')\n",
    "features = list(dt.index.names)\n",
    "valid = valid.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(valid.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/tw_word0-tweet_type.parquet')\n",
    "features = list(dt.index.names)\n",
    "valid = valid.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(valid.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/tw_rt_user0.parquet')\n",
    "features = list(dt.index.names)\n",
    "valid = valid.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(valid.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/a_follower_count-a_following_count-b_follower_count-b_following_count-tweet_type-language-b_follows_a.parquet')\n",
    "features = list(dt.index.names)\n",
    "valid = valid.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(valid.shape)\n",
    "\n",
    "dt = pd.read_parquet('TEMAPS_LOCAL/b_user_id.parquet')\n",
    "features = list(dt.index.names)\n",
    "valid = valid.merge(dt, left_on=features, right_index=True, how='left')\n",
    "del dt; gc.collect()\n",
    "print(valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for f in [\n",
    "'sums_te_reply-a_user_id-tweet_type',\n",
    "       'counts_te_reply-a_user_id-tweet_type',\n",
    "       'sums_te_retweet-a_user_id-tweet_type',\n",
    "       'sums_te_retweet_comment-a_user_id-tweet_type',\n",
    "       'sums_te_like-a_user_id-tweet_type',\n",
    "       'sums_te_reply-b_user_id-tweet_type',\n",
    "       'counts_te_reply-b_user_id-tweet_type',\n",
    "       'sums_te_retweet-b_user_id-tweet_type',\n",
    "       'sums_te_retweet_comment-b_user_id-tweet_type',\n",
    "       'sums_te_like-b_user_id-tweet_type', 'multi_reply', 'multi_retweet',\n",
    "       'multi_retweet_comment', 'multi_like', 'multi_counts', 'ouser0_reply',\n",
    "       'ouser0_retweet', 'ouser0_retweet_comment', 'ouser0_like',\n",
    "       'ouser0_counts', 'ouser1_reply', 'ouser1_retweet',\n",
    "       'ouser1_retweet_comment', 'ouser1_like', 'ouser1_counts', 'word_reply',\n",
    "       'word_retweet', 'word_retweet_comment', 'word_like', 'word_counts',\n",
    "       'rtuser0_reply', 'rtuser0_retweet', 'rtuser0_retweet_comment',\n",
    "       'rtuser0_like', 'rtuser0_counts', 'follow_reply', 'follow_retweet',\n",
    "       'follow_retweet_comment', 'follow_like', 'follow_counts',\n",
    "       'sums_b_user_reply', 'sums_b_user_retweet',\n",
    "       'sums_b_user_retweet_comment', 'sums_b_user_like', 'counts_b_user_id'      \n",
    "]:\n",
    "    train[f] = train[f].astype(np.float32)\n",
    "    valid[f] = valid[f].astype(np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>media</th>\n",
       "      <th>links</th>\n",
       "      <th>domains</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>language</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>a_user_id</th>\n",
       "      <th>a_follower_count</th>\n",
       "      <th>...</th>\n",
       "      <th>follow_reply</th>\n",
       "      <th>follow_retweet</th>\n",
       "      <th>follow_retweet_comment</th>\n",
       "      <th>follow_like</th>\n",
       "      <th>follow_counts</th>\n",
       "      <th>sums_b_user_reply</th>\n",
       "      <th>sums_b_user_retweet</th>\n",
       "      <th>sums_b_user_retweet_comment</th>\n",
       "      <th>sums_b_user_like</th>\n",
       "      <th>counts_b_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2872051519089231643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1613609666</td>\n",
       "      <td>3264529006259093641</td>\n",
       "      <td>1882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5452922862876665862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1613939869</td>\n",
       "      <td>958129457003958467</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>445.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6021.0</td>\n",
       "      <td>8905.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4871374771923015139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1613871462</td>\n",
       "      <td>-6936296245275888793</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>4538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5187395191713456404</td>\n",
       "      <td>0</td>\n",
       "      <td>2031127319</td>\n",
       "      <td>495726603</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1614152397</td>\n",
       "      <td>5433276069498045353</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138641100</td>\n",
       "      <td>815427420061189949</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1613940199</td>\n",
       "      <td>309709089998636133</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8082.0</td>\n",
       "      <td>7714.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>69799.0</td>\n",
       "      <td>150246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hashtags             tweet_id  media       links    domains  tweet_type  \\\n",
       "0          0 -2872051519089231643      0           0          0           0   \n",
       "1          0  5452922862876665862      0           0          0           0   \n",
       "2          0  4871374771923015139      0           0          0           1   \n",
       "3          0  5187395191713456404      0  2031127319  495726603           1   \n",
       "4  138641100   815427420061189949      1           0          0           0   \n",
       "\n",
       "   language   timestamp            a_user_id  a_follower_count  ...  \\\n",
       "0         0  1613609666  3264529006259093641              1882  ...   \n",
       "1         0  1613939869   958129457003958467               145  ...   \n",
       "2         3  1613871462 -6936296245275888793                 4  ...   \n",
       "3        13  1614152397  5433276069498045353                43  ...   \n",
       "4         0  1613940199   309709089998636133                 0  ...   \n",
       "\n",
       "   follow_reply  follow_retweet  follow_retweet_comment  follow_like  \\\n",
       "0           0.0             0.0                     0.0          0.0   \n",
       "1         445.0           738.0                    97.0       6021.0   \n",
       "2          41.0           427.0                    46.0       1533.0   \n",
       "3           4.0            49.0                     0.0        115.0   \n",
       "4        8082.0          7714.0                   710.0      69799.0   \n",
       "\n",
       "   follow_counts  sums_b_user_reply  sums_b_user_retweet  \\\n",
       "0           41.0                1.0                  0.0   \n",
       "1         8905.0                0.0                  1.0   \n",
       "2         4538.0                0.0                  6.0   \n",
       "3          667.0                0.0                  1.0   \n",
       "4       150246.0                0.0                  0.0   \n",
       "\n",
       "   sums_b_user_retweet_comment  sums_b_user_like  counts_b_user_id  \n",
       "0                          0.0               4.0              14.0  \n",
       "1                          0.0               1.0              10.0  \n",
       "2                          0.0              12.0              40.0  \n",
       "3                          0.0              39.0              69.0  \n",
       "4                          0.0               3.0               6.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['reply', 'retweet', 'retweet_comment', 'like']\n",
    "\n",
    "features_base = [\n",
    "    'media', 'tweet_type', 'language', \n",
    "    'a_follower_count', 'a_following_count', 'a_is_verified', 'a_account_creation',\n",
    "    'b_follower_count', 'b_following_count', 'b_is_verified', 'b_account_creation', 'b_follows_a',\n",
    "    'tw_len_token', 'tw_len_media', 'tw_len_photo', 'tw_len_video', 'tw_len_gif',\n",
    "    'tw_len_quest', 'tw_count_capital_words', 'tw_count_excl_quest_marks', 'tw_count_special1',\n",
    "    'tw_count_hash', 'tw_last_quest', 'tw_len_retweet', 'tw_len_rt', 'tw_count_at',\n",
    "    'tw_count_words', 'tw_count_char',  'tw_rt_count_words', 'tw_rt_count_char',\n",
    "    #'group',\n",
    "    'dt_dow',\n",
    "    #'dt_minute',\n",
    "    'len_hashtags', 'len_links', 'len_domains', 'decline'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sums_te_reply-a_user_id-tweet_type',\n",
       " 'counts_te_reply-a_user_id-tweet_type',\n",
       " 'sums_te_reply-b_user_id-tweet_type',\n",
       " 'counts_te_reply-b_user_id-tweet_type',\n",
       " 'multi_reply',\n",
       " 'multi_retweet',\n",
       " 'multi_retweet_comment',\n",
       " 'multi_like',\n",
       " 'multi_counts',\n",
       " 'ouser0_reply',\n",
       " 'ouser0_retweet',\n",
       " 'ouser0_retweet_comment',\n",
       " 'ouser0_like',\n",
       " 'ouser0_counts',\n",
       " 'ouser1_reply',\n",
       " 'ouser1_retweet',\n",
       " 'ouser1_retweet_comment',\n",
       " 'ouser1_like',\n",
       " 'ouser1_counts',\n",
       " 'word_reply',\n",
       " 'word_retweet',\n",
       " 'word_retweet_comment',\n",
       " 'word_like',\n",
       " 'word_counts',\n",
       " 'rtuser0_reply',\n",
       " 'rtuser0_retweet',\n",
       " 'rtuser0_retweet_comment',\n",
       " 'rtuser0_like',\n",
       " 'rtuser0_counts',\n",
       " 'follow_reply',\n",
       " 'follow_retweet',\n",
       " 'follow_retweet_comment',\n",
       " 'follow_like',\n",
       " 'follow_counts',\n",
       " 'sums_b_user_reply',\n",
       " 'sums_b_user_retweet',\n",
       " 'sums_b_user_retweet_comment',\n",
       " 'sums_b_user_like',\n",
       " 'counts_b_user_id']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_reply = [\n",
    "    \n",
    "'sums_te_reply-a_user_id-tweet_type',\n",
    "#'sums_te_retweet-a_user_id-tweet_type',\n",
    "#'sums_te_retweet_comment-a_user_id-tweet_type',\n",
    "#'sums_te_like-a_user_id-tweet_type',\n",
    "'counts_te_reply-a_user_id-tweet_type',\n",
    "    \n",
    "'sums_te_reply-b_user_id-tweet_type',\n",
    "#'sums_te_retweet-b_user_id-tweet_type',\n",
    "#'sums_te_retweet_comment-b_user_id-tweet_type',\n",
    "#'sums_te_like-b_user_id-tweet_type',\n",
    "'counts_te_reply-b_user_id-tweet_type',\n",
    "    \n",
    "'multi_reply',\n",
    "'multi_retweet',\n",
    "'multi_retweet_comment',\n",
    "'multi_like',\n",
    "'multi_counts', \n",
    "\n",
    "'ouser0_reply',\n",
    "'ouser0_retweet',\n",
    "'ouser0_retweet_comment', \n",
    "'ouser0_like',\n",
    "'ouser0_counts',\n",
    "\n",
    "'ouser1_reply',\n",
    "#'ouser1_retweet',\n",
    "#'ouser1_retweet_comment', \n",
    "#'ouser1_like',\n",
    "'ouser1_counts',\n",
    "\n",
    "'word_reply',\n",
    "'word_retweet',\n",
    "'word_retweet_comment',\n",
    "'word_like',\n",
    "'word_counts',\n",
    "\n",
    "'rtuser0_reply',\n",
    "#'rtuser0_retweet',\n",
    "#'rtuser0_retweet_comment',\n",
    "#'rtuser0_like',\n",
    "'rtuser0_counts',\n",
    "    \n",
    "'follow_reply',\n",
    "'follow_retweet',\n",
    "'follow_retweet_comment',\n",
    "'follow_like',\n",
    "'follow_counts',\n",
    "    \n",
    "'sums_b_user_reply',\n",
    "'sums_b_user_retweet',\n",
    "'sums_b_user_retweet_comment',\n",
    "'sums_b_user_like',\n",
    "'counts_b_user_id',\n",
    "    \n",
    "]\n",
    "\n",
    "feature_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['media',\n",
       " 'tweet_type',\n",
       " 'language',\n",
       " 'a_follower_count',\n",
       " 'a_following_count',\n",
       " 'a_is_verified',\n",
       " 'a_account_creation',\n",
       " 'b_follower_count',\n",
       " 'b_following_count',\n",
       " 'b_is_verified',\n",
       " 'b_account_creation',\n",
       " 'b_follows_a',\n",
       " 'tw_len_token',\n",
       " 'tw_len_media',\n",
       " 'tw_len_photo',\n",
       " 'tw_len_video',\n",
       " 'tw_len_gif',\n",
       " 'tw_len_quest',\n",
       " 'tw_count_capital_words',\n",
       " 'tw_count_excl_quest_marks',\n",
       " 'tw_count_special1',\n",
       " 'tw_count_hash',\n",
       " 'tw_last_quest',\n",
       " 'tw_len_retweet',\n",
       " 'tw_len_rt',\n",
       " 'tw_count_at',\n",
       " 'tw_count_words',\n",
       " 'tw_count_char',\n",
       " 'tw_rt_count_words',\n",
       " 'tw_rt_count_char',\n",
       " 'dt_dow',\n",
       " 'len_hashtags',\n",
       " 'len_links',\n",
       " 'len_domains',\n",
       " 'decline',\n",
       " 'sums_te_reply-a_user_id-tweet_type',\n",
       " 'counts_te_reply-a_user_id-tweet_type',\n",
       " 'sums_te_reply-b_user_id-tweet_type',\n",
       " 'counts_te_reply-b_user_id-tweet_type',\n",
       " 'multi_reply',\n",
       " 'multi_retweet',\n",
       " 'multi_retweet_comment',\n",
       " 'multi_like',\n",
       " 'multi_counts',\n",
       " 'ouser0_reply',\n",
       " 'ouser0_retweet',\n",
       " 'ouser0_retweet_comment',\n",
       " 'ouser0_like',\n",
       " 'ouser0_counts',\n",
       " 'ouser1_reply',\n",
       " 'ouser1_retweet',\n",
       " 'ouser1_retweet_comment',\n",
       " 'ouser1_like',\n",
       " 'ouser1_counts',\n",
       " 'word_reply',\n",
       " 'word_retweet',\n",
       " 'word_retweet_comment',\n",
       " 'word_like',\n",
       " 'word_counts',\n",
       " 'rtuser0_reply',\n",
       " 'rtuser0_retweet',\n",
       " 'rtuser0_retweet_comment',\n",
       " 'rtuser0_like',\n",
       " 'rtuser0_counts',\n",
       " 'follow_reply',\n",
       " 'follow_retweet',\n",
       " 'follow_retweet_comment',\n",
       " 'follow_like',\n",
       " 'follow_counts',\n",
       " 'sums_b_user_reply',\n",
       " 'sums_b_user_retweet',\n",
       " 'sums_b_user_retweet_comment',\n",
       " 'sums_b_user_like',\n",
       " 'counts_b_user_id']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features_base+feature_reply\n",
    "pickle.dump(features, open('xgbmodels-features-reply.pickle', 'wb'))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>language</th>\n",
       "      <th>a_follower_count</th>\n",
       "      <th>a_following_count</th>\n",
       "      <th>a_is_verified</th>\n",
       "      <th>a_account_creation</th>\n",
       "      <th>b_follower_count</th>\n",
       "      <th>b_following_count</th>\n",
       "      <th>b_is_verified</th>\n",
       "      <th>...</th>\n",
       "      <th>follow_reply</th>\n",
       "      <th>follow_retweet</th>\n",
       "      <th>follow_retweet_comment</th>\n",
       "      <th>follow_like</th>\n",
       "      <th>follow_counts</th>\n",
       "      <th>sums_b_user_reply</th>\n",
       "      <th>sums_b_user_retweet</th>\n",
       "      <th>sums_b_user_retweet_comment</th>\n",
       "      <th>sums_b_user_like</th>\n",
       "      <th>counts_b_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1882</td>\n",
       "      <td>808</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>445.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6021.0</td>\n",
       "      <td>8905.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>4538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8082.0</td>\n",
       "      <td>7714.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>69799.0</td>\n",
       "      <td>150246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   media  tweet_type  language  a_follower_count  a_following_count  \\\n",
       "0      0           0         0              1882                808   \n",
       "1      0           0         0               145                  4   \n",
       "2      0           1         3                 4                  6   \n",
       "3      0           1        13                43                  0   \n",
       "4      1           0         0                 0                  1   \n",
       "\n",
       "   a_is_verified  a_account_creation  b_follower_count  b_following_count  \\\n",
       "0              1                  15                 0                  2   \n",
       "1              1                 -64                 0                  0   \n",
       "2              0                -123                 0                  1   \n",
       "3              0                 -38                 0                  0   \n",
       "4              0                 -71                 0                  0   \n",
       "\n",
       "   b_is_verified  ...  follow_reply  follow_retweet  follow_retweet_comment  \\\n",
       "0              0  ...           0.0             0.0                     0.0   \n",
       "1              0  ...         445.0           738.0                    97.0   \n",
       "2              0  ...          41.0           427.0                    46.0   \n",
       "3              0  ...           4.0            49.0                     0.0   \n",
       "4              0  ...        8082.0          7714.0                   710.0   \n",
       "\n",
       "   follow_like  follow_counts  sums_b_user_reply  sums_b_user_retweet  \\\n",
       "0          0.0           41.0                1.0                  0.0   \n",
       "1       6021.0         8905.0                0.0                  1.0   \n",
       "2       1533.0         4538.0                0.0                  6.0   \n",
       "3        115.0          667.0                0.0                  1.0   \n",
       "4      69799.0       150246.0                0.0                  0.0   \n",
       "\n",
       "   sums_b_user_retweet_comment  sums_b_user_like  counts_b_user_id  \n",
       "0                          0.0               4.0              14.0  \n",
       "1                          0.0               1.0              10.0  \n",
       "2                          0.0              12.0              40.0  \n",
       "3                          0.0              39.0              69.0  \n",
       "4                          0.0               3.0               6.0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold\n",
      "0    9563035\n",
      "1    9563034\n",
      "2    9563034\n",
      "3    9563034\n",
      "4    9563034\n",
      "Name: media, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train['fold'] = np.arange(train.shape[0]) % 5  #TRAIN['tweet_id'] % 5\n",
    "print(train.groupby('fold')['media'].agg('count'))\n",
    "gc.collect();gc.collect();gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    24114352\n",
      "1    23700819\n",
      "Name: positive, dtype: int64\n",
      "1    7323312\n",
      "0    7138448\n",
      "Name: positive, dtype: int64\n",
      "0    24114352\n",
      "1    22337228\n",
      "2     1363591\n",
      "Name: target, dtype: int64\n",
      "0    7138448\n",
      "1    7018751\n",
      "2     304561\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train['positive'] = 0\n",
    "train.loc[(train['reply']>0)|(train['retweet']>0)|(train['retweet_comment']>0)|(train['like']>0), 'positive'] = 1\n",
    "print(train['positive'].value_counts())\n",
    "\n",
    "train['target'] = 0\n",
    "train.loc[train['positive']==1,'target'] = 1\n",
    "train.loc[train['reply']==1,'target'] = 2\n",
    "print( train['target'].value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'learning_rate': 0.04, 'subsample': 0.5, 'sampling_method': 'gradient_based', 'colsample_bytree': 0.8, 'grow_policy ': 'lossguide', 'eval_metric': 'auc', 'objective': 'binary:logistic', 'nthread': 1, 'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor'}\n",
      "TARGET: reply\n",
      "10.439348697662354 s\n",
      "Training...\n",
      "[18:20:38] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "549 RCE: 0 20.810878816579226 0 0.20378615952476595 32 s\n",
      "\n",
      "10.280435800552368 s\n",
      "Training...\n",
      "[18:21:22] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "549 RCE: 0 21.498391820806784 0 0.20928824577390492 81 s\n",
      "\n",
      "11.504206895828247 s\n",
      "Training...\n",
      "[18:22:56] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "549 RCE: 0 22.82040361713047 0 0.23135279172754336 92 s\n",
      "\n",
      "14.742304801940918 s\n",
      "Training...\n",
      "[18:24:43] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "549 RCE: 0 24.651270577529317 0 0.2587604524159719 115 s\n",
      "\n",
      "50.1555335521698 s\n",
      "Training...\n",
      "[18:27:29] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "549 RCE: 0 19.86114530652476 0 0.1631649744958484 482 s\n",
      "\n",
      "RCE: 21.92841802771411 0.2132705247876069 549.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!rm -r giba_xgbmodels\n",
    "#!mkdir giba_xgbmodels\n",
    "xgb_parms = { \n",
    "    'max_depth': 8, \n",
    "    'learning_rate':0.04, \n",
    "    'subsample':0.50,\n",
    "    'sampling_method': 'gradient_based',\n",
    "    'colsample_bytree':0.80, \n",
    "    'grow_policy ': 'lossguide', #'depthwise', 'lossguide'\n",
    "    'eval_metric':'auc',\n",
    "    'objective':'binary:logistic',\n",
    "    'nthread': 1,\n",
    "    'tree_method':'gpu_hist',\n",
    "    'predictor' : 'gpu_predictor'\n",
    "}\n",
    "print(xgb_parms)\n",
    "\n",
    "target = 'reply'\n",
    "\n",
    "feature_reply = [\n",
    "    \n",
    "'sums_te_reply-a_user_id-tweet_type',\n",
    "#'sums_te_retweet-a_user_id-tweet_type',\n",
    "#'sums_te_retweet_comment-a_user_id-tweet_type',\n",
    "#'sums_te_like-a_user_id-tweet_type',\n",
    "'counts_te_reply-a_user_id-tweet_type',\n",
    "    \n",
    "'sums_te_reply-b_user_id-tweet_type',\n",
    "#'sums_te_retweet-b_user_id-tweet_type',\n",
    "#'sums_te_retweet_comment-b_user_id-tweet_type',\n",
    "#'sums_te_like-b_user_id-tweet_type',\n",
    "'counts_te_reply-b_user_id-tweet_type',\n",
    "    \n",
    "'multi_reply',\n",
    "'multi_retweet',\n",
    "'multi_retweet_comment',\n",
    "'multi_like',\n",
    "'multi_counts', \n",
    "\n",
    "'ouser0_reply',\n",
    "'ouser0_retweet',\n",
    "'ouser0_retweet_comment', \n",
    "'ouser0_like',\n",
    "'ouser0_counts',\n",
    "\n",
    "'ouser1_reply',\n",
    "#'ouser1_retweet',\n",
    "#'ouser1_retweet_comment', \n",
    "#'ouser1_like',\n",
    "'ouser1_counts',\n",
    "\n",
    "'word_reply',\n",
    "'word_retweet',\n",
    "'word_retweet_comment',\n",
    "'word_like',\n",
    "'word_counts',\n",
    "\n",
    "'rtuser0_reply',\n",
    "#'rtuser0_retweet',\n",
    "#'rtuser0_retweet_comment',\n",
    "#'rtuser0_like',\n",
    "'rtuser0_counts',\n",
    "    \n",
    "'follow_reply',\n",
    "'follow_retweet',\n",
    "'follow_retweet_comment',\n",
    "'follow_like',\n",
    "'follow_counts',\n",
    "    \n",
    "'sums_b_user_reply',\n",
    "'sums_b_user_retweet',\n",
    "'sums_b_user_retweet_comment',\n",
    "'sums_b_user_like',\n",
    "'counts_b_user_id',\n",
    "    \n",
    "]\n",
    "features = features_base+feature_reply\n",
    "pickle.dump(features, open('xgbmodels-features-reply.pickle', 'wb'))\n",
    "\n",
    "print('TARGET:', target )\n",
    "for group in range(5):\n",
    "    start = time.time();\n",
    "    dtrain = xgb.DMatrix(data=train.loc[(train.group==group), features], label=train.loc[(train.group==group), target] ) )\n",
    "    gc.collect();gc.collect();gc.collect();\n",
    "    print( time.time() - start, 's' )\n",
    "\n",
    "    start = time.time(); print('Training...')\n",
    "    model = xgb.train(\n",
    "        xgb_parms, \n",
    "        dtrain=dtrain,\n",
    "        #evals=[(dvalid2,'valid2')],\n",
    "        num_boost_round=550,\n",
    "        #early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "    pickle.dump(model, open('giba_xgbmodels/model_' + str(target) + '_' + str(group) + '.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET: retweet\n",
      "9.789488077163696 s\n",
      "Training...\n",
      "[17:54:24] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "614 RCE: 0 21.439275914227473 0 0.37303359671381164 36 s\n",
      "\n",
      "10.148358583450317 s\n",
      "Training...\n",
      "[17:55:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "614 RCE: 0 21.266120489837228 0 0.3596788321632822 92 s\n",
      "\n",
      "11.381099700927734 s\n",
      "Training...\n",
      "[17:56:56] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "614 RCE: 0 21.594030346784933 0 0.35907946692885684 98 s\n",
      "\n",
      "14.545337677001953 s\n",
      "Training...\n",
      "[17:58:49] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "614 RCE: 0 22.323317121809318 0 0.3766895578918916 128 s\n",
      "\n",
      "49.684568881988525 s\n",
      "Training...\n",
      "[18:01:48] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "614 RCE: 0 22.715292863976998 0 0.35718867700128215 449 s\n",
      "\n",
      "RCE: 21.86760734732719 0.36513402613982493 614.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_parms = { \n",
    "    'max_depth': 8, \n",
    "    'learning_rate':0.04, \n",
    "    'subsample':0.50,\n",
    "    'sampling_method': 'gradient_based',\n",
    "    'colsample_bytree':0.80, \n",
    "    'grow_policy ': 'lossguide', #'depthwise', 'lossguide'\n",
    "    'eval_metric':'auc',\n",
    "    'objective':'binary:logistic',\n",
    "    'nthread': 1,\n",
    "    'tree_method':'gpu_hist',\n",
    "    'predictor' : 'gpu_predictor'\n",
    "}\n",
    "\n",
    "target = 'retweet'\n",
    "\n",
    "feature_retweet = [\n",
    "    \n",
    "#'sums_te_reply-a_user_id-tweet_type',\n",
    "'sums_te_retweet-a_user_id-tweet_type',\n",
    "#'sums_te_retweet_comment-a_user_id-tweet_type',\n",
    "#'sums_te_like-a_user_id-tweet_type',\n",
    "'counts_te_reply-a_user_id-tweet_type',\n",
    "    \n",
    "#'sums_te_reply-b_user_id-tweet_type',\n",
    "'sums_te_retweet-b_user_id-tweet_type',\n",
    "#'sums_te_retweet_comment-b_user_id-tweet_type',\n",
    "#'sums_te_like-b_user_id-tweet_type',\n",
    "'counts_te_reply-b_user_id-tweet_type',\n",
    "    \n",
    "'multi_reply',\n",
    "'multi_retweet',\n",
    "'multi_retweet_comment',\n",
    "'multi_like',\n",
    "'multi_counts', \n",
    "\n",
    "'ouser0_reply',\n",
    "'ouser0_retweet',\n",
    "'ouser0_retweet_comment', \n",
    "'ouser0_like',\n",
    "'ouser0_counts',\n",
    "\n",
    "#'ouser1_reply',\n",
    "'ouser1_retweet',\n",
    "#'ouser1_retweet_comment', \n",
    "#'ouser1_like',\n",
    "'ouser1_counts',\n",
    "\n",
    "'word_reply',\n",
    "'word_retweet',\n",
    "'word_retweet_comment',\n",
    "'word_like',\n",
    "'word_counts',\n",
    "\n",
    "#'rtuser0_reply',\n",
    "'rtuser0_retweet',\n",
    "#'rtuser0_retweet_comment',\n",
    "#'rtuser0_like',\n",
    "'rtuser0_counts',\n",
    "    \n",
    "'follow_reply',\n",
    "'follow_retweet',\n",
    "'follow_retweet_comment',\n",
    "'follow_like',\n",
    "'follow_counts',\n",
    "    \n",
    "'sums_b_user_reply',\n",
    "'sums_b_user_retweet',\n",
    "'sums_b_user_retweet_comment',\n",
    "'sums_b_user_like',\n",
    "'counts_b_user_id',\n",
    "    \n",
    "]\n",
    "features = features_base+feature_retweet\n",
    "pickle.dump(features, open('xgbmodels-features-retweet.pickle', 'wb'))\n",
    "\n",
    "print('TARGET:', target )\n",
    "for group in range(5):\n",
    "    start = time.time();\n",
    "    dtrain = xgb.DMatrix(data=train.loc[(train.group==group), features], label=train.loc[(train.group==group), target] ) )\n",
    "    gc.collect();gc.collect();gc.collect();\n",
    "    print( time.time() - start, 's' )\n",
    "\n",
    "    start = time.time(); print('Training...')\n",
    "    model = xgb.train(\n",
    "        xgb_parms, \n",
    "        dtrain=dtrain,\n",
    "        #evals=[(dvalid2,'valid2')],\n",
    "        num_boost_round=615,\n",
    "        #early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "    pickle.dump(model, open('giba_xgbmodels/model_' + str(target) + '_' + str(group) + '.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET: retweet_comment\n",
      "9.903303861618042 s\n",
      "Training...\n",
      "[18:35:43] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "799 RCE: 0 12.932292869020445 0 0.05382582526608513 46 s\n",
      "\n",
      "10.25521993637085 s\n",
      "Training...\n",
      "[18:36:41] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "799 RCE: 0 11.963718880482688 0 0.04623983074268029 50 s\n",
      "\n",
      "11.473490953445435 s\n",
      "Training...\n",
      "[18:37:44] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "799 RCE: 0 12.41780311299946 0 0.04674384379704724 145 s\n",
      "\n",
      "14.74394679069519 s\n",
      "Training...\n",
      "[18:40:25] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "799 RCE: 0 13.711419339793052 0 0.050696448183175584 172 s\n",
      "\n",
      "50.15479254722595 s\n",
      "Training...\n",
      "[18:44:08] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "799 RCE: 0 14.029400551593396 0 0.049548153847410126 730 s\n",
      "\n",
      "RCE: 13.010926950777806 0.04941082036727967 799.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_parms = { \n",
    "    'max_depth': 8, \n",
    "    'learning_rate':0.02, \n",
    "    'subsample':0.50,\n",
    "    'sampling_method': 'gradient_based',\n",
    "    'colsample_bytree':0.80, \n",
    "    'grow_policy ': 'lossguide', #'depthwise', 'lossguide'\n",
    "    'eval_metric':'auc',\n",
    "    'objective':'binary:logistic',\n",
    "    'nthread': 1,\n",
    "    'tree_method':'gpu_hist',\n",
    "    'predictor' : 'gpu_predictor'\n",
    "}\n",
    "\n",
    "target = 'retweet_comment'\n",
    "\n",
    "feature_retweet_comment = [\n",
    "    \n",
    "#'sums_te_reply-a_user_id-tweet_type',\n",
    "#'sums_te_retweet-a_user_id-tweet_type',\n",
    "'sums_te_retweet_comment-a_user_id-tweet_type',\n",
    "#'sums_te_like-a_user_id-tweet_type',\n",
    "'counts_te_reply-a_user_id-tweet_type',\n",
    "    \n",
    "#'sums_te_reply-b_user_id-tweet_type',\n",
    "#'sums_te_retweet-b_user_id-tweet_type',\n",
    "'sums_te_retweet_comment-b_user_id-tweet_type',\n",
    "#'sums_te_like-b_user_id-tweet_type',\n",
    "'counts_te_reply-b_user_id-tweet_type',\n",
    "    \n",
    "'multi_reply',\n",
    "'multi_retweet',\n",
    "'multi_retweet_comment',\n",
    "'multi_like',\n",
    "'multi_counts', \n",
    "\n",
    "'ouser0_reply',\n",
    "'ouser0_retweet',\n",
    "'ouser0_retweet_comment', \n",
    "'ouser0_like',\n",
    "'ouser0_counts',\n",
    "\n",
    "#'ouser1_reply',\n",
    "#'ouser1_retweet',\n",
    "'ouser1_retweet_comment', \n",
    "#'ouser1_like',\n",
    "'ouser1_counts',\n",
    "\n",
    "'word_reply',\n",
    "'word_retweet',\n",
    "'word_retweet_comment',\n",
    "'word_like',\n",
    "'word_counts',\n",
    "\n",
    "#'rtuser0_reply',\n",
    "#'rtuser0_retweet',\n",
    "'rtuser0_retweet_comment',\n",
    "#'rtuser0_like',\n",
    "'rtuser0_counts',\n",
    "    \n",
    "'follow_reply',\n",
    "'follow_retweet',\n",
    "'follow_retweet_comment',\n",
    "'follow_like',\n",
    "'follow_counts',\n",
    "    \n",
    "'sums_b_user_reply',\n",
    "'sums_b_user_retweet',\n",
    "'sums_b_user_retweet_comment',\n",
    "'sums_b_user_like',\n",
    "'counts_b_user_id',\n",
    "    \n",
    "]\n",
    "features = features_base+feature_retweet_comment\n",
    "pickle.dump(features, open('xgbmodels-features-retweet_comment.pickle', 'wb'))\n",
    "\n",
    "print('TARGET:', target )\n",
    "for group in range(5):\n",
    "    start = time.time();\n",
    "    dtrain = xgb.DMatrix(data=train.loc[(train.group==group), features], label=train.loc[(train.group==group), target] ) )\n",
    "    gc.collect();gc.collect();gc.collect();\n",
    "    print( time.time() - start, 's' )\n",
    "\n",
    "    start = time.time(); print('Training...')\n",
    "    model = xgb.train(\n",
    "        xgb_parms, \n",
    "        dtrain=dtrain,\n",
    "        #evals=[(dvalid2,'valid2')],\n",
    "        num_boost_round=800,\n",
    "        #early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "    pickle.dump(model, open('giba_xgbmodels/model_' + str(target) + '_' + str(group) + '.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET: like\n",
      "9.91366696357727 s\n",
      "Training...\n",
      "[18:56:30] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "693 RCE: 0 11.246404484904705 0 0.6075175594082944 40 s\n",
      "\n",
      "10.262964010238647 s\n",
      "Training...\n",
      "[18:57:22] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "693 RCE: 0 9.25918961254254 0 0.5904451382824741 98 s\n",
      "\n",
      "11.477341413497925 s\n",
      "Training...\n",
      "[18:59:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "693 RCE: 0 9.300840288754275 0 0.5840504015256742 112 s\n",
      "\n",
      "14.750423192977905 s\n",
      "Training...\n",
      "[19:01:20] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "693 RCE: 0 10.474479475837384 0 0.5954105486011759 132 s\n",
      "\n",
      "49.63736033439636 s\n",
      "Training...\n",
      "[19:04:23] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1614189954438/work/src/learner.cc:541: \n",
      "Parameters: { grow_policy  } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "693 RCE: 0 9.212025634132559 0 0.607191897389124 565 s\n",
      "\n",
      "RCE: 9.898587899234291 0.5969231090413486 693.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_parms = { \n",
    "    'max_depth': 8, \n",
    "    'learning_rate':0.04, \n",
    "    'subsample':0.50,\n",
    "    'sampling_method': 'gradient_based',\n",
    "    'colsample_bytree':0.80, \n",
    "    'grow_policy ': 'lossguide', #'depthwise', 'lossguide'\n",
    "    'eval_metric':'auc',\n",
    "    'objective':'binary:logistic',\n",
    "    'nthread': 1,\n",
    "    'tree_method':'gpu_hist',\n",
    "    'predictor' : 'gpu_predictor'\n",
    "}\n",
    "\n",
    "target = 'like'\n",
    "\n",
    "feature_like = [\n",
    "    \n",
    "#'sums_te_reply-a_user_id-tweet_type',\n",
    "#'sums_te_retweet-a_user_id-tweet_type',\n",
    "#'sums_te_retweet_comment-a_user_id-tweet_type',\n",
    "'sums_te_like-a_user_id-tweet_type',\n",
    "'counts_te_reply-a_user_id-tweet_type',\n",
    "    \n",
    "#'sums_te_reply-b_user_id-tweet_type',\n",
    "#'sums_te_retweet-b_user_id-tweet_type',\n",
    "#'sums_te_retweet_comment-b_user_id-tweet_type',\n",
    "'sums_te_like-b_user_id-tweet_type',\n",
    "'counts_te_reply-b_user_id-tweet_type',\n",
    "    \n",
    "'multi_reply',\n",
    "'multi_retweet',\n",
    "'multi_retweet_comment',\n",
    "'multi_like',\n",
    "'multi_counts', \n",
    "\n",
    "'ouser0_reply',\n",
    "'ouser0_retweet',\n",
    "'ouser0_retweet_comment', \n",
    "'ouser0_like',\n",
    "'ouser0_counts',\n",
    "\n",
    "#'ouser1_reply',\n",
    "#'ouser1_retweet',\n",
    "#'ouser1_retweet_comment', \n",
    "'ouser1_like',\n",
    "'ouser1_counts',\n",
    "\n",
    "'word_reply',\n",
    "'word_retweet',\n",
    "'word_retweet_comment',\n",
    "'word_like',\n",
    "'word_counts',\n",
    "\n",
    "#'rtuser0_reply',\n",
    "#'rtuser0_retweet',\n",
    "#'rtuser0_retweet_comment',\n",
    "'rtuser0_like',\n",
    "'rtuser0_counts',\n",
    "    \n",
    "'follow_reply',\n",
    "'follow_retweet',\n",
    "'follow_retweet_comment',\n",
    "'follow_like',\n",
    "'follow_counts',\n",
    "    \n",
    "'sums_b_user_reply',\n",
    "'sums_b_user_retweet',\n",
    "'sums_b_user_retweet_comment',\n",
    "'sums_b_user_like',\n",
    "'counts_b_user_id',\n",
    "    \n",
    "]\n",
    "features = features_base+feature_like\n",
    "pickle.dump(features, open('xgbmodels-features-like.pickle', 'wb'))\n",
    "\n",
    "print('TARGET:', target )\n",
    "for group in range(5):\n",
    "    start = time.time();\n",
    "    dtrain = xgb.DMatrix(data=train.loc[(train.group==group), features], label=train.loc[(train.group==group), target] ) )\n",
    "    gc.collect();gc.collect();gc.collect();\n",
    "    print( time.time() - start, 's' )\n",
    "\n",
    "    start = time.time(); print('Training...')\n",
    "    model = xgb.train(\n",
    "        xgb_parms, \n",
    "        dtrain=dtrain,\n",
    "        #evals=[(dvalid2,'valid2')],\n",
    "        num_boost_round=694,\n",
    "        #early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "    pickle.dump(model, open('giba_xgbmodels/model_' + str(target) + '_' + str(group) + '.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: giba_xgbmodels/model_like_0.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_like_1.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_like_2.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_like_3.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_like_4.pickle (deflated 74%)\n",
      "  adding: giba_xgbmodels/model_reply_0.pickle (deflated 72%)\n",
      "  adding: giba_xgbmodels/model_reply_1.pickle (deflated 72%)\n",
      "  adding: giba_xgbmodels/model_reply_2.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_reply_3.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_reply_4.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_retweet_0.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_retweet_1.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_retweet_2.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_retweet_3.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_retweet_4.pickle (deflated 74%)\n",
      "  adding: giba_xgbmodels/model_retweet_comment_0.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_retweet_comment_1.pickle (deflated 72%)\n",
      "  adding: giba_xgbmodels/model_retweet_comment_2.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_retweet_comment_3.pickle (deflated 73%)\n",
      "  adding: giba_xgbmodels/model_retweet_comment_4.pickle (deflated 73%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r xgb.zip giba_xgbmodels/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['media',\n",
       " 'tweet_type',\n",
       " 'language',\n",
       " 'a_follower_count',\n",
       " 'a_following_count',\n",
       " 'a_is_verified',\n",
       " 'a_account_creation',\n",
       " 'b_follower_count',\n",
       " 'b_following_count',\n",
       " 'b_is_verified',\n",
       " 'b_account_creation',\n",
       " 'b_follows_a',\n",
       " 'tw_len_token',\n",
       " 'tw_len_media',\n",
       " 'tw_len_photo',\n",
       " 'tw_len_video',\n",
       " 'tw_len_gif',\n",
       " 'tw_len_quest',\n",
       " 'tw_count_capital_words',\n",
       " 'tw_count_excl_quest_marks',\n",
       " 'tw_count_special1',\n",
       " 'tw_count_hash',\n",
       " 'tw_last_quest',\n",
       " 'tw_len_retweet',\n",
       " 'tw_len_rt',\n",
       " 'tw_count_at',\n",
       " 'tw_count_words',\n",
       " 'tw_count_char',\n",
       " 'tw_rt_count_words',\n",
       " 'tw_rt_count_char',\n",
       " 'dt_dow',\n",
       " 'len_hashtags',\n",
       " 'len_links',\n",
       " 'len_domains',\n",
       " 'decline',\n",
       " 'sums_te_like-a_user_id-tweet_type',\n",
       " 'counts_te_reply-a_user_id-tweet_type',\n",
       " 'sums_te_like-b_user_id-tweet_type',\n",
       " 'counts_te_reply-b_user_id-tweet_type',\n",
       " 'multi_reply',\n",
       " 'multi_retweet',\n",
       " 'multi_retweet_comment',\n",
       " 'multi_like',\n",
       " 'multi_counts',\n",
       " 'ouser0_reply',\n",
       " 'ouser0_retweet',\n",
       " 'ouser0_retweet_comment',\n",
       " 'ouser0_like',\n",
       " 'ouser0_counts',\n",
       " 'ouser1_like',\n",
       " 'ouser1_counts',\n",
       " 'word_reply',\n",
       " 'word_retweet',\n",
       " 'word_retweet_comment',\n",
       " 'word_like',\n",
       " 'word_counts',\n",
       " 'rtuser0_like',\n",
       " 'rtuser0_counts',\n",
       " 'follow_reply',\n",
       " 'follow_retweet',\n",
       " 'follow_retweet_comment',\n",
       " 'follow_like',\n",
       " 'follow_counts',\n",
       " 'sums_b_user_reply',\n",
       " 'sums_b_user_retweet',\n",
       " 'sums_b_user_retweet_comment',\n",
       " 'sums_b_user_like',\n",
       " 'counts_b_user_id']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.load(open('xgbmodels-features-like.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
