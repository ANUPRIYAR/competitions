{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca444c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA CORPORATION\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-twist",
   "metadata": {},
   "source": [
    "# Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "retired-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "residential-shannon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/raid/TE_submission_opt/a_user_id.parquet',\n",
       " '/raid/TE_submission_opt/b_is_verified_tweet_type.parquet',\n",
       " '/raid/TE_submission_opt/b_user_id.parquet',\n",
       " '/raid/TE_submission_opt/b_user_id_a_user_id.parquet',\n",
       " '/raid/TE_submission_opt/b_user_id_tweet_type_language.parquet',\n",
       " '/raid/TE_submission_opt/domains_language_b_follows_a_tweet_type_media_a_is_verified.parquet',\n",
       " '/raid/TE_submission_opt/media_tweet_type_language.parquet',\n",
       " '/raid/TE_submission_opt/media_tweet_type_language_a_is_verified_b_is_verified_b_follows_a.parquet',\n",
       " '/raid/TE_submission_opt/tw_original_user0_tweet_type_language.parquet',\n",
       " '/raid/TE_submission_opt/tw_original_user1_tweet_type_language.parquet',\n",
       " '/raid/TE_submission_opt/tweet_type.parquet']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TE_files = sorted(glob.glob('/raid/TE_submission_opt/*.parquet'))\n",
    "TE_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "basic-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_files = [\n",
    "    '/raid/TE_submission_opt/b_user_id_tweet_type_language.parquet',\n",
    "    '/raid/TE_submission_opt/b_user_id_a_user_id.parquet',\n",
    "    '/raid/TE_submission_opt/a_user_id.parquet',\n",
    "    '/raid/TE_submission_opt/b_is_verified_tweet_type.parquet',\n",
    "    '/raid/TE_submission_opt/b_user_id.parquet',\n",
    "    '/raid/TE_submission_opt/domains_language_b_follows_a_tweet_type_media_a_is_verified.parquet',\n",
    "    '/raid/TE_submission_opt/media_tweet_type_language.parquet',\n",
    "    '/raid/TE_submission_opt/media_tweet_type_language_a_is_verified_b_is_verified_b_follows_a.parquet',\n",
    "    '/raid/TE_submission_opt/tw_original_user0_tweet_type_language.parquet',\n",
    "    '/raid/TE_submission_opt/tw_original_user1_tweet_type_language.parquet',\n",
    "    '/raid/TE_submission_opt/tweet_type.parquet'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sunset-filename",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "rm: cannot remove '/raid/recsys2021_pre_TE_submission/': No such file or directory\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "!rm -r /raid/recsys2021_pre_TE_submission/\n",
    "!mkdir /raid/recsys2021_pre_TE_submission/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comic-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "DONT_USE = ['a_account_creation','b_account_creation','engage_time',\n",
    "            'fold','b_user_id','a_user_id', 'dt_dow', 'a_account_creation', \n",
    "            'b_account_creation', 'elapsed_time', 'links','domains','hashtags','id', 'date', 'is_train', \n",
    "            'tw_original_http0', 'tw_original_user0', 'tw_original_user1', 'tw_original_user2',\n",
    "            'tw_rt_count_char', 'tw_rt_count_words', 'tw_rt_user0', 'tw_tweet', 'tw_word0', 'a_user_id_x', 'b_user_id_x',\n",
    "            'tw_word1', 'tw_word2', 'tw_word3', 'tw_word4', 'tw_count_hash', 'dt_minute', 'dt_second', 'dt_day', 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "digital-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DOW = ''\n",
    "psmooth=20\n",
    "means = {}\n",
    "means['reply'] = 0.02846728456689906\n",
    "means['like'] = 0.3968895210408169\n",
    "means['retweet'] = 0.08769760903336701\n",
    "means['retweet_comment'] = 0.006918407917391091\n",
    "\n",
    "def add_TE(fn):\n",
    "    df = cudf.read_parquet(fn)\n",
    "    gc.collect()\n",
    "    df['date'] = cudf.to_datetime(df['timestamp'], unit='s')\n",
    "    df['dt_dow']  = df['date'].dt.weekday\n",
    "    df['dt_hour'] = df['date'].dt.hour\n",
    "    df['dt_minute'] = df['date'].dt.minute\n",
    "    df['dt_second'] = df['date'].dt.second\n",
    "    if VALID_DOW!='':\n",
    "        df['is_train'] = (df['date']<cudf.to_datetime(VALID_DOW)).astype(np.int8)\n",
    "    else:\n",
    "        df['is_train'] = 1\n",
    "    for i, file in enumerate(TE_files):\n",
    "        df_tmp = cudf.read_parquet(file)\n",
    "        col = [x for x in df_tmp.columns if not('reply' in x or 'retweet' in x or 'like' in x)]\n",
    "        col_rest = [x for x in df_tmp.columns if x not in col]\n",
    "        df = df.merge(df_tmp, on=col, how='left')\n",
    "        for key in means.keys():\n",
    "            if df_tmp.shape[0]>1000:\n",
    "                df['TE_' + '_'.join(col) + '_' + key] = (((df[key + '_sum']-df[key]*df['is_train'])+means[key]*psmooth)/(df['reply_count']-df['is_train']+psmooth))\n",
    "            else:\n",
    "                df['TE_' + '_'.join(col) + '_' + key] = (((df[key + '_sum'])+means[key]*psmooth)/(df['reply_count']+psmooth))\n",
    "            if col[0]=='a_user_id' and key=='like':\n",
    "                df.loc[df['reply_count']<=1000, 'TE_' + '_'.join(col) + '_' + key] = None\n",
    "            df['TE_' + '_'.join(col) + '_' + key] = df['TE_' + '_'.join(col) + '_' + key].fillna(np.float32(means[key])).round(3)\n",
    "        df.drop(col_rest, inplace=True, axis=1)\n",
    "        gc.collect()\n",
    "        col = [x for x in df_tmp.columns if not('reply' in x or ('retweet' in x and 'tw_len_retweet' not in x) or '_retweet_comment' in x or 'like' in x)]\n",
    "        if 'b_user_id' not in col and 'a_user_id' in col:\n",
    "            print(col)\n",
    "            dfcols = list(df_tmp.columns)\n",
    "            dfcolsnew = []\n",
    "            for col in dfcols:\n",
    "                if col == 'b_user_id':\n",
    "                    dfcolsnew.append('a_user_id')\n",
    "                elif col == 'a_user_id':\n",
    "                    dfcolsnew.append('b_user_id')\n",
    "                else:\n",
    "                    dfcolsnew.append(col)\n",
    "            df_tmp.columns = dfcolsnew\n",
    "            col = [x for x in df_tmp.columns if not('reply' in x or ('retweet' in x and 'tw_len_retweet' not in x) or '_retweet_comment' in x or 'like' in x)]\n",
    "            col_rest = [x for x in df_tmp.columns if x not in col]\n",
    "            df = df.merge(df_tmp, on=col, how='left')\n",
    "            for key in means.keys():\n",
    "                df['TE_switch_' + '_'.join(col) + '_' + key] = (((df[key + '_sum'])+means[key]*psmooth)/(df['reply_count']+psmooth))\n",
    "                df['TE_switch_' + '_'.join(col) + '_' + key] = df['TE_switch_' + '_'.join(col) + '_' + key].fillna(np.float32(means[key])).round(3)\n",
    "            df.drop(col_rest, inplace=True, axis=1)\n",
    "        del df_tmp\n",
    "        gc.collect()\n",
    "    df['a_ff_rate'] = (df['a_following_count'] / (1+df['a_follower_count'])).astype('float32')\n",
    "    df['b_ff_rate'] = (df['b_follower_count']  / (1+df['b_following_count'])).astype('float32')\n",
    "    df['ab_fing_rate'] = (df['a_following_count'] / (1+df['b_following_count'])).astype('float32')\n",
    "    df['ab_fer_rate'] = (df['a_follower_count'] / (1+df['b_follower_count'])).astype('float32')\n",
    "    df['ab_age_dff'] = (df['a_account_creation']-df['b_account_creation'])\n",
    "    df['ab_age_rate'] = (df['a_account_creation']+129)/(df['b_account_creation']+129)\n",
    "    final_cols = [x for x in sorted(list(df.columns)) if x not in DONT_USE]\n",
    "    df[final_cols].to_parquet( '/raid/recsys2021_pre_TE_submission/' + fn.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "phantom-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('/raid/recsys2021_pre/*'))[0:(n_files//2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "heard-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid/recsys2021_pre/part-00000.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00001.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00002.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00003.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00004.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00005.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00006.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00007.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00008.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00009.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00010.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00011.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00012.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00013.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00014.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00015.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00016.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00017.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00018.parquet\n",
      "['a_user_id']\n",
      "/raid/recsys2021_pre/part-00019.parquet\n",
      "['a_user_id']\n",
      "CPU times: user 1min 16s, sys: 1min 16s, total: 2min 33s\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    add_TE(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-hometown",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
